{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
   "metadata": {
    "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:35.207984Z",
     "start_time": "2024-05-21T22:44:34.801978Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import timm\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import utils.semi_hard_mining as shm\n",
    "\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
   "metadata": {
    "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:35.647981Z",
     "start_time": "2024-05-21T22:44:35.215985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# serve per ricaricare automaticamente il codice modificato\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f02ae726-f601-4b51-a949-71a5464ec779",
   "metadata": {
    "id": "f02ae726-f601-4b51-a949-71a5464ec779",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:35.979992Z",
     "start_time": "2024-05-21T22:44:35.654979Z"
    }
   },
   "outputs": [],
   "source": [
    "# directory da dove vengono prelevate le immagini\n",
    "path = Path(os.getcwd()).parent.parent\n",
    "real_data_dir = os.path.join(path, \"artifact\", \"coco\")\n",
    "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
    "\n",
    "# per far funzionare il modello su immagini rgb o in scala di grigi (per usare fourier)\n",
    "mode=\"rgb\"\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "LR = 0.001\n",
    "\n",
    "EPOCHS = 30\n",
    "\n",
    "DEVICE = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6c035a79-a777-4fb4-83fc-c71f1f4d37a7",
   "metadata": {
    "id": "6c035a79-a777-4fb4-83fc-c71f1f4d37a7",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:36.456030Z",
     "start_time": "2024-05-21T22:44:35.983979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train dataset size: 16000\n",
      "val dataset size: 4000\n"
     ]
    }
   ],
   "source": [
    "csv_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "df = df.sample(frac=1)\n",
    "\n",
    "df.head()\n",
    "\n",
    "train_df, valid_df = train_test_split(df, test_size=0.20, random_state=42)\n",
    "\n",
    "print(f\"train dataset size: {len(train_df)}\")\n",
    "print(f\"val dataset size: {len(valid_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
   "metadata": {
    "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:36.722739Z",
     "start_time": "2024-05-21T22:44:36.462032Z"
    }
   },
   "outputs": [],
   "source": [
    "# carica le immagini nel dataset\n",
    "class APN_Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, df):\n",
    "    self.df = df\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.df)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    row = self.df.iloc[idx]\n",
    "    \n",
    "    if mode == \"rgb\":\n",
    "      # le immagini Anchor sono memorizzate in due dataset diversi\n",
    "      if str(row.Anchor).startswith(\"coco\"):\n",
    "        A_img = io.imread(os.path.join(real_data_dir, row.Anchor))\n",
    "        P_img = io.imread(os.path.join(real_data_dir, row.Positive))\n",
    "        N_img = io.imread(os.path.join(fake_data_dir, row.Negative))\n",
    "\n",
    "      else:\n",
    "        A_img = io.imread(os.path.join(fake_data_dir, row.Anchor))\n",
    "        P_img = io.imread(os.path.join(fake_data_dir, row.Positive))\n",
    "        N_img = io.imread(os.path.join(real_data_dir, row.Negative))\n",
    "\n",
    "      # normalizzazione per immagini in rgb \n",
    "      A_img = torch.from_numpy(A_img).permute(2, 0, 1) / 255.0\n",
    "      P_img = torch.from_numpy(P_img).permute(2, 0, 1) / 255.0\n",
    "      N_img = torch.from_numpy(N_img).permute(2, 0, 1) / 255.0\n",
    "\n",
    "    if mode == \"grey_scale\":\n",
    "      A_img = np.expand_dims(A_img, 0)\n",
    "      P_img = np.expand_dims(P_img, 0)\n",
    "      N_img = np.expand_dims(N_img, 0)\n",
    "      \n",
    "      A_img = torch.from_numpy(A_img) / 255.0\n",
    "      P_img = torch.from_numpy(P_img) / 255.0\n",
    "      N_img = torch.from_numpy(N_img) / 255.0\n",
    "\n",
    "    # A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
    "    # P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
    "    # N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
    "\n",
    "    return A_img, P_img, N_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8203b726-6dcc-41fc-ac33-d98f58e61ac7",
   "metadata": {
    "id": "8203b726-6dcc-41fc-ac33-d98f58e61ac7",
    "outputId": "60287971-91ea-41f4-e564-ec8524cb8d3d",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:36.941739Z",
     "start_time": "2024-05-21T22:44:36.725737Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainset size: 16000\n",
      "validset size: 4000\n"
     ]
    }
   ],
   "source": [
    "trainset = APN_Dataset(train_df)\n",
    "validset = APN_Dataset(valid_df)\n",
    "dataset = APN_Dataset(df)\n",
    "print(f\"trainset size: {len(trainset)}\")\n",
    "print(f\"validset size: {len(validset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4fae8215-4694-4710-b55a-e9c10bf42690",
   "metadata": {
    "id": "4fae8215-4694-4710-b55a-e9c10bf42690",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:37.133734Z",
     "start_time": "2024-05-21T22:44:36.944738Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
    "validloader = DataLoader(validset, batch_size = BATCH_SIZE)\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9b9c0301-e6a8-47cb-91f8-9850b78e39d5",
   "metadata": {
    "id": "9b9c0301-e6a8-47cb-91f8-9850b78e39d5",
    "outputId": "0be94549-1119-4856-dce2-a7df0229a36d",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:37.309840Z",
     "start_time": "2024-05-21T22:44:37.135736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#batches in trainloader : 500\n",
      "#batches in validloader : 125\n"
     ]
    }
   ],
   "source": [
    "print(f\"#batches in trainloader : {len(trainloader)}\")\n",
    "print(f\"#batches in validloader : {len(validloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d1022fe9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:37.511735Z",
     "start_time": "2024-05-21T22:44:37.312779Z"
    }
   },
   "outputs": [],
   "source": [
    "# funzione per caricare il modello di rete neurale direttamente dalle repository online\n",
    "class APN_Model_Pretrained(nn.Module):\n",
    "\n",
    "  # size del vettore di embedding\n",
    "  def __init__(self, emb_size = 512):\n",
    "    super(APN_Model_Pretrained, self).__init__()\n",
    "\n",
    "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
    "    self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=True)\n",
    "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
    "\n",
    "  def forward(self, images):\n",
    "    embeddings = self.efficientnet(images)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
   "metadata": {
    "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:37.730748Z",
     "start_time": "2024-05-21T22:44:37.518735Z"
    }
   },
   "outputs": [],
   "source": [
    "# funzione per caricare il modello di rete neurale direttamente dalle repository online\n",
    "class APN_Model(nn.Module):\n",
    "\n",
    "  # size del vettore di embedding\n",
    "  def __init__(self, emb_size = 512):\n",
    "    super(APN_Model, self).__init__()\n",
    "\n",
    "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
    "    self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=False)\n",
    "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
    "\n",
    "  def forward(self, images):\n",
    "    embeddings = self.efficientnet(images)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a64f5032-dc37-4858-a901-d17b2eaed4db",
   "metadata": {
    "id": "a64f5032-dc37-4858-a901-d17b2eaed4db",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:39.197466Z",
     "start_time": "2024-05-21T22:44:37.733734Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "APN_Model_Pretrained(\n  (efficientnet): EfficientNet(\n    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn1): BatchNormAct2d(\n      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (blocks): Sequential(\n      (0): Sequential(\n        (0): ConvBnAct(\n          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (drop_path): Identity()\n        )\n      )\n      (1): Sequential(\n        (0): EdgeResidual(\n          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn1): BatchNormAct2d(\n            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): EdgeResidual(\n          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (2): Sequential(\n        (0): EdgeResidual(\n          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n          (bn1): BatchNormAct2d(\n            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): EdgeResidual(\n          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): Identity()\n          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn2): BatchNormAct2d(\n            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (3): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n          (bn2): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (bn2): BatchNormAct2d(\n            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n          (bn2): BatchNormAct2d(\n            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (4): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n          (bn2): BatchNormAct2d(\n            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n          (bn2): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n          (bn2): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n          (bn2): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n          (bn2): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n      (5): Sequential(\n        (0): InvertedResidual(\n          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n          (bn2): BatchNormAct2d(\n            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (1): InvertedResidual(\n          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (bn2): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (2): InvertedResidual(\n          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (bn2): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (3): InvertedResidual(\n          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (bn2): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (4): InvertedResidual(\n          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (bn2): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (5): InvertedResidual(\n          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (bn2): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (6): InvertedResidual(\n          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (bn2): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n        (7): InvertedResidual(\n          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn1): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n          (bn2): BatchNormAct2d(\n            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): SiLU(inplace=True)\n          )\n          (se): SqueezeExcite(\n            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n            (act1): SiLU(inplace=True)\n            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n            (gate): Sigmoid()\n          )\n          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n          (bn3): BatchNormAct2d(\n            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n            (drop): Identity()\n            (act): Identity()\n          )\n          (drop_path): Identity()\n        )\n      )\n    )\n    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn2): BatchNormAct2d(\n      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n      (drop): Identity()\n      (act): SiLU(inplace=True)\n    )\n    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n  )\n)"
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = APN_Model_Pretrained()\n",
    "\n",
    "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
    "if mode == \"grey_scale\":\n",
    "    model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
    "\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b7f5eb0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:39.420451Z",
     "start_time": "2024-05-21T22:44:39.200450Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_embeddings(model, dataloader, batch_size, ds) :\n",
    "    model.eval()\n",
    "    out = pd.DataFrame(columns=[\"Anchor\", \"Positive\", \"Negative\", \"A_emb\", \"P_emb\", \"N_emb\"])\n",
    "    i=0\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for A, P, N in tqdm(dataloader, desc=\"create embeddings...\"):\n",
    "            A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
    "\n",
    "            # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
    "            A_embs = model(A)\n",
    "            P_embs = model(P)\n",
    "            N_embs = model(N)\n",
    "            \n",
    "            for j in range (batch_size):\n",
    "                out.loc[i] = [\n",
    "                ds.iloc[i][\"Anchor\"], \n",
    "                ds.iloc[i][\"Positive\"], \n",
    "                ds.iloc[i][\"Negative\"],\n",
    "                A_embs[j].cpu(),\n",
    "                P_embs[j].cpu(),\n",
    "                N_embs[j].cpu()\n",
    "                ] \n",
    "            i = i+1\n",
    "                \n",
    "    out.to_csv(\"prova.csv\",index=False)\n",
    "    return out\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
   "metadata": {
    "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:39.690452Z",
     "start_time": "2024-05-21T22:44:39.424452Z"
    }
   },
   "outputs": [],
   "source": [
    "# funzione di train\n",
    "def train_fn(model, dataloader, optimizer, criterion):\n",
    "  model.train()\n",
    "  # on dropout \n",
    "  total_loss = 0.0\n",
    "\n",
    "  for A, P, N in tqdm(dataloader, desc=\"model training...\"):\n",
    "    A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
    "\n",
    "    # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
    "    A_embs = model(A)\n",
    "    P_embs = model(P)\n",
    "    N_embs = model(N)\n",
    "\n",
    "    # criterion è la funzione di loss triplet\n",
    "    loss = criterion(A_embs, P_embs, N_embs)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "19ec6d56-9168-4980-9164-62660537f1ff",
   "metadata": {
    "id": "19ec6d56-9168-4980-9164-62660537f1ff",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:39.958465Z",
     "start_time": "2024-05-21T22:44:39.695454Z"
    }
   },
   "outputs": [],
   "source": [
    "# funzione di evaluation\n",
    "def eval_fn(model, dataloader, criterion):\n",
    "  model.eval() \n",
    "  # off dropout\n",
    "  total_loss = 0.0\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for A, P, N in tqdm(dataloader, desc=\"model validating...\"):\n",
    "      A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
    "\n",
    "      A_embs = model(A)\n",
    "      P_embs = model(P)\n",
    "      N_embs = model(N)\n",
    "\n",
    "      loss = criterion(A_embs, P_embs, N_embs)\n",
    "\n",
    "      total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
   "metadata": {
    "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:44:40.211465Z",
     "start_time": "2024-05-21T22:44:39.962452Z"
    }
   },
   "outputs": [],
   "source": [
    "# triplet loss e adam\n",
    "criterion = nn.TripletMarginLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
   "metadata": {
    "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:53:51.812528Z",
     "start_time": "2024-05-21T22:44:40.215453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "create embeddings...: 100%|██████████| 625/625 [07:28<00:00,  1.39it/s]\n",
      "model training...:   0%|          | 0/3 [00:06<?, ?it/s]\n",
      "model validating...:   0%|          | 0/1 [00:00<?, ?it/s]C:\\Users\\acali\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\timm\\layers\\conv2d_same.py:27: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
      "  return F.conv2d(x, weight, bias, stride, (0, 0), dilation, groups)\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 1, train_loss: 0.29336581627527875, valid_loss: 0.8145073056221008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 2, train_loss: 0.12821856141090393, valid_loss: 0.6183963418006897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 3, train_loss: 0.029028385877609253, valid_loss: 0.45308172702789307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 4, train_loss: 0.07442168891429901, valid_loss: 0.36684244871139526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 5, train_loss: 0.013680517673492432, valid_loss: 0.3356759250164032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 6, train_loss: 0.0, valid_loss: 0.3203246593475342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 7, train_loss: 0.0, valid_loss: 0.3016757369041443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 8, train_loss: 0.0021736820538838706, valid_loss: 0.30319318175315857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successful weights saving...\n",
      "epochs: 9, train_loss: 0.020282859603563946, valid_loss: 0.2999272346496582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 10, train_loss: 0.0016105820735295613, valid_loss: 0.3396192789077759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 11, train_loss: 0.019648894667625427, valid_loss: 0.38075530529022217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 12, train_loss: 0.0, valid_loss: 0.4323481619358063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 13, train_loss: 0.025095919768015545, valid_loss: 0.4850235879421234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 14, train_loss: 0.039650494853655495, valid_loss: 0.48923903703689575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 15, train_loss: 0.0, valid_loss: 0.5104127526283264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 16, train_loss: 0.0, valid_loss: 0.5781770944595337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 17, train_loss: 0.0, valid_loss: 0.6626811027526855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 18, train_loss: 0.008379379908243815, valid_loss: 0.6318261027336121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 19, train_loss: 0.0031534135341644287, valid_loss: 0.652799129486084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  3.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 20, train_loss: 0.0, valid_loss: 0.6705072522163391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 21, train_loss: 0.0, valid_loss: 0.667233943939209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 22, train_loss: 0.005643710494041443, valid_loss: 0.6692485809326172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 23, train_loss: 0.0, valid_loss: 0.6728543639183044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 24, train_loss: 0.007667164007822673, valid_loss: 0.7045180797576904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 25, train_loss: 0.01069470246632894, valid_loss: 0.6937628388404846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 26, train_loss: 0.0, valid_loss: 0.7144288420677185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 27, train_loss: 0.014383897185325623, valid_loss: 0.6775565147399902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 28, train_loss: 0.014985496799151102, valid_loss: 0.6589036583900452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 29, train_loss: 0.014364764094352722, valid_loss: 0.6102191209793091\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model training...:   0%|          | 0/3 [00:02<?, ?it/s]\n",
      "model validating...: 100%|██████████| 1/1 [00:00<00:00,  2.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 30, train_loss: 0.028653437892595928, valid_loss: 0.6057796478271484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "best_valid_loss = np.Inf\n",
    "\n",
    "training_epoch_loss = []\n",
    "validation_epoch_loss = []\n",
    "\n",
    "\n",
    "train_df1, valid_df1 = train_test_split(create_embeddings(model,dataloader, BATCH_SIZE,df), test_size=0.20, random_state=42)\n",
    "train_df2 = shm.semi_hard_mining(train_df1,model,0.2) \n",
    "\n",
    "valid_df2 = shm.semi_hard_mining(valid_df1,model,0.2)\n",
    "\n",
    "trainset1 = APN_Dataset(train_df2)\n",
    "validset1 = APN_Dataset(valid_df2)\n",
    "\n",
    "\n",
    "trainloader_semi_hard= DataLoader(trainset1, batch_size = BATCH_SIZE, shuffle = True)\n",
    "validloader_semi_hard = DataLoader(validset1, batch_size = BATCH_SIZE)\n",
    "for i in range(EPOCHS):\n",
    "  train_loss = train_fn(model, trainloader_semi_hard, optimizer, criterion)\n",
    "  valid_loss = eval_fn(model, validloader_semi_hard, criterion)\n",
    "\n",
    "  training_epoch_loss.append(train_loss)\n",
    "  validation_epoch_loss.append(valid_loss)\n",
    "\n",
    "  if valid_loss < best_valid_loss:\n",
    "    torch.save(model.state_dict(), \"best_model.pt\")\n",
    "    best_valid_loss = valid_loss\n",
    "    print(\"successful weights saving...\")\n",
    "\n",
    "  print(f\"epochs: {i+1}, train_loss: {train_loss}, valid_loss: {valid_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ca40d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T22:53:52.949203Z",
     "start_time": "2024-05-21T22:53:51.813529Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<function matplotlib.pyplot.show(close=None, block=None)>"
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot della training e validation loss\n",
    "plt.plot(training_epoch_loss, label=\"train_loss\")\n",
    "plt.plot(validation_epoch_loss, label=\"val_loss\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
   "metadata": {
    "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:01:33.855808Z",
     "start_time": "2024-05-21T23:01:33.757793Z"
    }
   },
   "outputs": [],
   "source": [
    "# funzione per generare i vettori di encoding\n",
    "def get_encoding_csv(model, anc_img_names, dirFolder):\n",
    "  anc_img_names_arr = np.array(anc_img_names)\n",
    "  encodings = []\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for i in tqdm(anc_img_names_arr):\n",
    "\n",
    "      if mode == \"rgb\":\n",
    "        # serve per trovare correttamente l'immagine\n",
    "        if str(i).startswith(\"coco\"):\n",
    "          dirFolder = real_data_dir\n",
    "          A = io.imread(os.path.join(dirFolder,i))\n",
    "        else: \n",
    "          dirFolder = fake_data_dir\n",
    "          A = io.imread(os.path.join(dirFolder,i))\n",
    "\n",
    "        A = torch.from_numpy(A).permute(2, 0, 1) / 255.0\n",
    "      \n",
    "      if mode == \"grey_scale\":\n",
    "        A = io.imread(os.path.join(dirFolder,i))\n",
    "\n",
    "        A = np.expand_dims(A, 0)\n",
    "        A = torch.from_numpy(A.astype(np.int32)) / 255.0\n",
    "        \n",
    "      A = A.to(DEVICE)\n",
    "      A_enc = model(A.unsqueeze(0))\n",
    "      encodings.append(A_enc.squeeze().cpu().detach().numpy())\n",
    "\n",
    "    encodings = np.array(encodings)\n",
    "    encodings = pd.DataFrame(encodings)\n",
    "    df_enc = pd.concat([anc_img_names, encodings], axis = 1)\n",
    "\n",
    "    return df_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
   "metadata": {
    "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
    "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:11:29.398956Z",
     "start_time": "2024-05-21T23:01:40.127010Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20000/20000 [09:42<00:00, 34.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# per ricaricare il modello una volta allenato\n",
    "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
    "\n",
    "# si creano gli embeddings che vengono memorizzati per non rifarlo ad ogni allenamento\n",
    "df_enc = get_encoding_csv(model, df[\"Anchor\"], real_data_dir)\n",
    "\n",
    "df_enc.to_csv(\"database.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
   "metadata": {
    "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
    "outputId": "171dab62-2058-470c-9abf-5ea9495da9b0",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:11:38.370622Z",
     "start_time": "2024-05-21T23:11:36.267627Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                        Anchor         0         1         2  \\\n0        coco/coco2017/train2017/img077313.jpg -0.204685 -0.191130  0.098484   \n1        coco/coco2017/train2017/img081457.jpg -0.142372 -0.118361  0.101852   \n2  tt-ffhq/ffhq_k300_p1.0_fid9.6/img025149.jpg -0.063383  0.106869 -0.230683   \n3        coco/coco2017/train2017/img062087.jpg  0.082885  0.237379 -0.328033   \n4  tt-ffhq/ffhq_k300_p1.0_fid9.6/img003641.jpg -0.109068  0.011639 -0.016269   \n\n          3         4         5         6         7         8  ...       502  \\\n0 -0.204370  0.065292  0.363037  0.083017 -0.032329 -0.031222  ...  0.006152   \n1  0.042731 -0.135906  0.285048  0.117334  0.144155 -0.004581  ... -0.031505   \n2 -0.165608 -0.281022 -0.114101 -0.163643 -0.212839  0.321815  ... -0.000032   \n3 -0.143369 -0.323850  0.184616  0.141662 -0.247401 -0.182348  ... -0.149945   \n4  0.125619 -0.250014  0.163737  0.085684 -0.109934  0.249093  ...  0.015115   \n\n        503       504       505       506       507       508       509  \\\n0  0.147181 -0.429884 -0.011791  0.346403  0.123832 -0.070861  0.091341   \n1 -0.075820  0.138407 -0.316204 -0.157027  0.168813  0.051183  0.230990   \n2  0.237489 -0.263898 -0.220716  0.020770  0.211617 -0.097189  0.195398   \n3  0.270419  0.439697  0.538683 -0.534097 -0.419789  0.240917 -0.153351   \n4 -0.192301  0.160720 -0.035872  0.112956  0.038147  0.155821  0.325280   \n\n        510       511  \n0 -0.247292  0.134676  \n1 -0.035936  0.170828  \n2  0.077921 -0.196372  \n3  0.095007 -0.098537  \n4 -0.059061  0.114510  \n\n[5 rows x 513 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Anchor</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>...</th>\n      <th>502</th>\n      <th>503</th>\n      <th>504</th>\n      <th>505</th>\n      <th>506</th>\n      <th>507</th>\n      <th>508</th>\n      <th>509</th>\n      <th>510</th>\n      <th>511</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>coco/coco2017/train2017/img077313.jpg</td>\n      <td>-0.204685</td>\n      <td>-0.191130</td>\n      <td>0.098484</td>\n      <td>-0.204370</td>\n      <td>0.065292</td>\n      <td>0.363037</td>\n      <td>0.083017</td>\n      <td>-0.032329</td>\n      <td>-0.031222</td>\n      <td>...</td>\n      <td>0.006152</td>\n      <td>0.147181</td>\n      <td>-0.429884</td>\n      <td>-0.011791</td>\n      <td>0.346403</td>\n      <td>0.123832</td>\n      <td>-0.070861</td>\n      <td>0.091341</td>\n      <td>-0.247292</td>\n      <td>0.134676</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>coco/coco2017/train2017/img081457.jpg</td>\n      <td>-0.142372</td>\n      <td>-0.118361</td>\n      <td>0.101852</td>\n      <td>0.042731</td>\n      <td>-0.135906</td>\n      <td>0.285048</td>\n      <td>0.117334</td>\n      <td>0.144155</td>\n      <td>-0.004581</td>\n      <td>...</td>\n      <td>-0.031505</td>\n      <td>-0.075820</td>\n      <td>0.138407</td>\n      <td>-0.316204</td>\n      <td>-0.157027</td>\n      <td>0.168813</td>\n      <td>0.051183</td>\n      <td>0.230990</td>\n      <td>-0.035936</td>\n      <td>0.170828</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img025149.jpg</td>\n      <td>-0.063383</td>\n      <td>0.106869</td>\n      <td>-0.230683</td>\n      <td>-0.165608</td>\n      <td>-0.281022</td>\n      <td>-0.114101</td>\n      <td>-0.163643</td>\n      <td>-0.212839</td>\n      <td>0.321815</td>\n      <td>...</td>\n      <td>-0.000032</td>\n      <td>0.237489</td>\n      <td>-0.263898</td>\n      <td>-0.220716</td>\n      <td>0.020770</td>\n      <td>0.211617</td>\n      <td>-0.097189</td>\n      <td>0.195398</td>\n      <td>0.077921</td>\n      <td>-0.196372</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>coco/coco2017/train2017/img062087.jpg</td>\n      <td>0.082885</td>\n      <td>0.237379</td>\n      <td>-0.328033</td>\n      <td>-0.143369</td>\n      <td>-0.323850</td>\n      <td>0.184616</td>\n      <td>0.141662</td>\n      <td>-0.247401</td>\n      <td>-0.182348</td>\n      <td>...</td>\n      <td>-0.149945</td>\n      <td>0.270419</td>\n      <td>0.439697</td>\n      <td>0.538683</td>\n      <td>-0.534097</td>\n      <td>-0.419789</td>\n      <td>0.240917</td>\n      <td>-0.153351</td>\n      <td>0.095007</td>\n      <td>-0.098537</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img003641.jpg</td>\n      <td>-0.109068</td>\n      <td>0.011639</td>\n      <td>-0.016269</td>\n      <td>0.125619</td>\n      <td>-0.250014</td>\n      <td>0.163737</td>\n      <td>0.085684</td>\n      <td>-0.109934</td>\n      <td>0.249093</td>\n      <td>...</td>\n      <td>0.015115</td>\n      <td>-0.192301</td>\n      <td>0.160720</td>\n      <td>-0.035872</td>\n      <td>0.112956</td>\n      <td>0.038147</td>\n      <td>0.155821</td>\n      <td>0.325280</td>\n      <td>-0.059061</td>\n      <td>0.114510</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 513 columns</p>\n</div>"
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_enc = pd.read_csv('database.csv')\n",
    "df_enc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
   "metadata": {
    "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:11:42.778622Z",
     "start_time": "2024-05-21T23:11:42.668623Z"
    }
   },
   "outputs": [],
   "source": [
    "# approssimazione della distanza, senza la radice quadrata, per fare i primi allenamenti velocemente\n",
    "def euclidean_dist(img_enc, anc_enc_arr):\n",
    "    # dist = np.sqrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
    "    dist = np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T)\n",
    "    # dist = np.sqrt(dist)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
   "metadata": {
    "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
    "outputId": "7ff19abf-6ff7-4f31-bd3e-a07d07ca90dd",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:53:55.340108Z",
     "start_time": "2024-05-21T22:53:55.340108Z"
    }
   },
   "outputs": [],
   "source": [
    "path = os.path.join(Path(os.getcwd()).parent, \"datasets\", \"testList.csv\")\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "print(df[\"real\"])\n",
    "print(df.size)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
   "metadata": {
    "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:11:46.037805Z",
     "start_time": "2024-05-21T23:11:45.935853Z"
    }
   },
   "outputs": [],
   "source": [
    "def getImageEmbeddings(img, model):\n",
    "    if mode == \"rgb\":\n",
    "        img = torch.from_numpy(img).permute(2, 0, 1) / 255.0\n",
    "      \n",
    "    if mode == \"grey_scale\":\n",
    "        img = np.expand_dims(img, 0)\n",
    "        img = torch.from_numpy(img) / 255\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img = img.to(DEVICE)\n",
    "        img_enc = model(img.unsqueeze(0))\n",
    "        img_enc = img_enc.detach().cpu().numpy()\n",
    "        img_enc = np.array(img_enc)\n",
    "\n",
    "    return img_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
   "metadata": {
    "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:53:55.342107Z",
     "start_time": "2024-05-21T22:53:55.342107Z"
    }
   },
   "outputs": [],
   "source": [
    "def searchInDatabase(img_enc, database):\n",
    "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
    "    anc_img_names = database[\"Anchor\"]\n",
    "\n",
    "    distance = []\n",
    "    for i in range(anc_enc_arr.shape[0]):\n",
    "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
    "        distance = np.append(distance, dist)\n",
    "\n",
    "    closest_idx = np.argsort(distance)\n",
    "\n",
    "    return database[\"Anchor\"][closest_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
   "metadata": {
    "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
    "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:14:36.578591Z",
     "start_time": "2024-05-21T23:14:36.483558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(20000, 3)"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DataTestReal = 'C:/Users/polsi/Desktop/Lavori/DeepFake/Datasets/Artifact/cycle_gan/st/test/'\n",
    "path = Path(os.getcwd()).parent.parent\n",
    "real_data_dir = os.path.join(path, \"artifact\", \"coco\")\n",
    "fake_data_dir = os.path.join(path, \"artifact\", \"timing_transformer\")\n",
    "\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "tempDf = df\n",
    "tempDf.head()\n",
    "tempDf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
   "metadata": {
    "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:14:39.310778Z",
     "start_time": "2024-05-21T23:14:39.152811Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing on fake images...: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'fake'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'fake'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[82], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# prendo i primi 500 Fake\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, row \u001B[38;5;129;01min\u001B[39;00m tqdm(tempDf\u001B[38;5;241m.\u001B[39miterrows(), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtesting on fake images...\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m----> 7\u001B[0m     path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(fake_data_dir, \u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcurrentTest\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m      8\u001B[0m     img_name \u001B[38;5;241m=\u001B[39m path\n\u001B[0;32m     10\u001B[0m     img \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mimread(img_name)\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1121\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m-> 1121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;66;03m# Convert generator to list before going through hashable part\u001B[39;00m\n\u001B[0;32m   1124\u001B[0m \u001B[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1237\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[0;32m   1236\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[1;32m-> 1237\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(loc):\n\u001B[0;32m   1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[loc]\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'fake'"
     ]
    }
   ],
   "source": [
    "# testo i fake\n",
    "currentTest = \"fake\"\n",
    "database = df_enc\n",
    "\n",
    "# prendo i primi 500 Fake\n",
    "for index, row in tqdm(tempDf.iterrows(), desc=\"testing on fake images...\"):\n",
    "    path = os.path.join(fake_data_dir, row[currentTest])\n",
    "    img_name = path\n",
    "\n",
    "    img = io.imread(img_name)\n",
    "\n",
    "    img_enc = getImageEmbeddings(img, model)\n",
    "\n",
    "    closestLabel = searchInDatabase(img_enc, database)\n",
    "\n",
    "    if mode == \"rgb\":\n",
    "        if \"coco\" in closestLabel:\n",
    "            y_pred.append(\"real\")\n",
    "        else:\n",
    "            y_pred.append(\"fake\")\n",
    "\n",
    "    if mode == \"grey_scale\": \n",
    "        if \"coco\" in closestLabel:\n",
    "            y_pred.append(\"real\")\n",
    "        else:\n",
    "            y_pred.append(\"fake\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
   "metadata": {
    "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:53:55.346113Z",
     "start_time": "2024-05-21T22:53:55.346113Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(y_true))\n",
    "print(len(y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
   "metadata": {
    "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T23:14:49.934605Z",
     "start_time": "2024-05-21T23:14:49.775610Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing on real images...: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'real'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'real'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[83], line 7\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# prendo i primi 500 Fake\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m index, row \u001B[38;5;129;01min\u001B[39;00m tqdm(tempDf\u001B[38;5;241m.\u001B[39miterrows(), desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtesting on real images...\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m----> 7\u001B[0m     path \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(real_data_dir, \u001B[43mrow\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcurrentTest\u001B[49m\u001B[43m]\u001B[49m)\n\u001B[0;32m      8\u001B[0m     img_name \u001B[38;5;241m=\u001B[39m path\n\u001B[0;32m     10\u001B[0m     img_enc \u001B[38;5;241m=\u001B[39m getImageEmbeddings(img, model)\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1121\u001B[0m, in \u001B[0;36mSeries.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   1118\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[key]\n\u001B[0;32m   1120\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m key_is_scalar:\n\u001B[1;32m-> 1121\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1123\u001B[0m \u001B[38;5;66;03m# Convert generator to list before going through hashable part\u001B[39;00m\n\u001B[0;32m   1124\u001B[0m \u001B[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001B[39;00m\n\u001B[0;32m   1125\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\series.py:1237\u001B[0m, in \u001B[0;36mSeries._get_value\u001B[1;34m(self, label, takeable)\u001B[0m\n\u001B[0;32m   1234\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[label]\n\u001B[0;32m   1236\u001B[0m \u001B[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001B[39;00m\n\u001B[1;32m-> 1237\u001B[0m loc \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabel\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1239\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(loc):\n\u001B[0;32m   1240\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values[loc]\n",
      "File \u001B[1;32m~\\PycharmProjects\\project-detective\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[0;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[0;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[0;32m   3810\u001B[0m     ):\n\u001B[0;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[1;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'real'"
     ]
    }
   ],
   "source": [
    "# testo i real\n",
    "currentTest = \"real\"\n",
    "database = df_enc\n",
    "\n",
    "# prendo i primi 500 Fake\n",
    "for index, row in tqdm(tempDf.iterrows(), desc=\"testing on real images...\"):\n",
    "    path = os.path.join(real_data_dir, row[currentTest])\n",
    "    img_name = path\n",
    "\n",
    "    img_enc = getImageEmbeddings(img, model)\n",
    "\n",
    "    closestLabel = searchInDatabase(img_enc, database)\n",
    "    \n",
    "    if mode == \"rgb\":\n",
    "        if \"coco\" in closestLabel:\n",
    "            y_pred.append(\"real\")\n",
    "        else:\n",
    "            y_pred.append(\"fake\")\n",
    "\n",
    "    if mode == \"grey_scale\": \n",
    "        if \"real\" in closestLabel:\n",
    "            y_pred.append(\"real\")\n",
    "        else:\n",
    "            y_pred.append(\"fake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c465bfd-18ad-4750-b689-739b712185ab",
   "metadata": {
    "id": "4c465bfd-18ad-4750-b689-739b712185ab",
    "outputId": "e974c712-91fb-4fae-c589-85e08a50fb77",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:53:55.349112Z",
     "start_time": "2024-05-21T22:53:55.348111Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(y_true))\n",
    "print(len(y_pred))\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85706e81-3068-4150-9773-320a8aa98c69",
   "metadata": {
    "id": "85706e81-3068-4150-9773-320a8aa98c69",
    "tags": [],
    "ExecuteTime": {
     "end_time": "2024-05-21T22:53:55.350112Z",
     "start_time": "2024-05-21T22:53:55.350112Z"
    }
   },
   "outputs": [],
   "source": [
    "# creo i vettori di ground truth\n",
    "y_true = np.array([\"fake\"] * len(valid_df))\n",
    "print(y_true.shape)\n",
    "\n",
    "temp = np.array([\"real\"] * len(valid_df))\n",
    "print(temp.shape)\n",
    "\n",
    "y_true = np.concatenate([y_true, temp])\n",
    "print(y_true.shape)\n",
    "\n",
    "# calcolo la matrice di confusione (quella di scikit-learn dispone i risultati come nella cella di sotto)\n",
    "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
   "metadata": {
    "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-05-21T22:53:55.351111Z"
    }
   },
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = cm.ravel()\n",
    "\n",
    "# metriche\n",
    "accuracy = round((TP + TN) / (TP + TN + FP + FN), 4) * 100\n",
    "precision = round((TP) / (TP + FP), 4) * 100\n",
    "recall = round((TP) / (TP + FN), 4) * 100\n",
    "specificity = round((TN) / (TN + FP) * 100, 4)\n",
    "f1_score = round((2 * precision * recall) / (precision + recall), 4)\n",
    "\n",
    "print({\"Accuracy\":accuracy, \"Precision\":precision, \"Recall\":recall, \"Specificity\":specificity, \"F1 Score\":f1_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6aac2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# si salvano i risultati in un file .csv\n",
    "df_results = pd.DataFrame(columns=[\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1 Score\"])\n",
    "df_results.loc[0] = [accuracy, precision, recall, specificity, f1_score]\n",
    "\n",
    "# si differenziano i risultati in base al tipo di immagini e dataset usati\n",
    "dataset = fake_data_dir.split(\"\\\\\")[-1]\n",
    "path = os.path.join(\"..\", \"results\", \"siamese_\" + mode + \"_\" + dataset + \"_results.csv\")\n",
    "\n",
    "df_results.to_csv(path, index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "fvab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
