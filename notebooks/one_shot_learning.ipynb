{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7046cde1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# si aggiunge al path la cartella utils per avere visibilità del module\n",
        "module_path = Path(os.getcwd()).parent.parent\n",
        "module_path = os.path.join(module_path, \"detectwins\")\n",
        "\n",
        "sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import utils.mining as mining\n",
        "import utils.datasets as build\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
      "metadata": {
        "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# classe per caricare il modello di rete neurale direttamente dalle repository online\n",
        "class ApnModel(nn.Module):\n",
        "\n",
        "  # size del vettore di embedding\n",
        "  def __init__(self, emb_size=512):\n",
        "    super(ApnModel, self).__init__()\n",
        "\n",
        "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
        "    self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=False)\n",
        "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "  def forward(self, images):\n",
        "    embeddings = self.efficientnet(images)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d64707d7",
      "metadata": {},
      "outputs": [],
      "source": [
        "# funzione per generare i vettori di encoding\n",
        "def get_encoding_csv(model, anc_img_names, fake_data_dir, real_data_dir, device):\n",
        "  anc_img_names_arr = np.array(anc_img_names)\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in tqdm(anc_img_names_arr, desc=\"creating encodings...\"):\n",
        "      if \"real\" in str(i):\n",
        "        dir_folder = real_data_dir\n",
        "      else: \n",
        "        dir_folder = fake_data_dir\n",
        "\n",
        "      a = io.imread(os.path.join(dir_folder, i))\n",
        "      a = np.expand_dims(a, 0)\n",
        "      a = torch.from_numpy(a.astype(np.int32)) / 255.0\n",
        "      a = a.to(device)\n",
        "      \n",
        "      a_enc = model(a.unsqueeze(0))\n",
        "      encodings.append(a_enc.squeeze().cpu().detach().numpy())\n",
        "\n",
        "    encodings = np.array(encodings)\n",
        "    encodings = pd.DataFrame(encodings)\n",
        "    anc_img_names_df = pd.DataFrame(anc_img_names_arr, columns=['Anchor'])\n",
        "    df_enc = pd.concat([anc_img_names_df, encodings], axis=1)\n",
        "\n",
        "    return df_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
      "metadata": {
        "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_image_embeddings(img, model, device):\n",
        "    img = np.expand_dims(img, 0)\n",
        "    img = torch.from_numpy(img) / 255\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = img.to(device)\n",
        "        img_enc = model(img.unsqueeze(0))\n",
        "        img_enc = img_enc.detach().cpu().numpy()\n",
        "        img_enc = np.array(img_enc)\n",
        "\n",
        "    return img_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
      "metadata": {
        "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def search_in_database(img_enc, database):\n",
        "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
        "    anc_img_names = database[\"Anchor\"]\n",
        "\n",
        "    distance = []\n",
        "    for i in range(anc_enc_arr.shape[0]):\n",
        "        dist = mining.array_distance(img_enc, anc_enc_arr[i : i+1, :])\n",
        "        distance = np.append(distance, dist)\n",
        "\n",
        "    closest_idx = np.argsort(distance)\n",
        "\n",
        "    return database[\"Anchor\"][closest_idx[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
      "metadata": {
        "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# serve per ricaricare il codice modificato\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# configurazione\n",
        "batch_size=32\n",
        "lr=0.001\n",
        "epochs=30\n",
        "device=\"cuda\"\n",
        "fake_dataset = \"big_gan\"\n",
        "real_dataset = \"coco\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18cd52ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# directory da dove vengono prelevate le immagini del dataset di train\n",
        "fake_data_dir = os.path.join(\"..\", \"temp\", \"taming_transformer+coco\", \"train\", \"taming_transformer\")\n",
        "real_data_dir = os.path.join(\"..\", \"temp\", \"taming_transformer+coco\", \"train\", \"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ff345c9",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si ottiene il dataset di train che serve per creare gli encodings\n",
        "df_out_path = os.path.join(\"..\", \"datasets\", \"fourier_out.csv\")\n",
        "df_out = pd.read_csv(df_out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2080916",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = ApnModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
      "metadata": {
        "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
        "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# per ricaricare il modello già allenato\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "# si creano gli embeddings che vengono memorizzati \n",
        "if not os.path.isfile(\"database.csv\"):\n",
        "    df_enc = get_encoding_csv(model, df_out[\"Anchor\"], fake_data_dir, real_data_dir)\n",
        "    df_enc.to_csv(\"database.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
      "metadata": {
        "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
        "outputId": "171dab62-2058-470c-9abf-5ea9495da9b0",
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_enc = pd.read_csv('database.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db591324",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si crea un dataset di test e lo si converte in fourier\n",
        "artifact_path = os.path.join(\"..\", \"..\", \"artifact\")\n",
        "fake_dataset_path = os.path.join(artifact_path, fake_dataset, \"metadata.csv\")\n",
        "real_dataset_path = os.path.join(artifact_path, real_dataset, \"metadata.csv\")\n",
        "\n",
        "temp_path = os.path.join(\"..\", \"temp\")\n",
        "\n",
        "# se non c'è la cartella temp la si crea\n",
        "if not os.path.isdir(temp_path): \n",
        "    os.mkdir(temp_path)\n",
        "\n",
        "path = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset)\n",
        "\n",
        "# se non c'è la cartella della combinazione dei dataset scelti la si crea\n",
        "if not os.path.isdir(path): \n",
        "    os.mkdir(path)\n",
        "    os.mkdir(os.path.join(path, \"test\"))\n",
        "    os.mkdir(os.path.join(path, \"test\", real_dataset))\n",
        "    os.mkdir(os.path.join(path, \"test\", fake_dataset))\n",
        "\n",
        "test_df_path = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", \"test_list.csv\")\n",
        "\n",
        "# creo il dataset di test\n",
        "build.test(fake_dataset_path, real_dataset_path, df_out, test_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d9a72bbf",
      "metadata": {},
      "outputs": [],
      "source": [
        "test_df = pd.read_csv(test_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "218b8ecb",
      "metadata": {},
      "outputs": [],
      "source": [
        "fake_dataset_path = os.path.join(artifact_path, fake_dataset)\n",
        "real_dataset_path = os.path.join(artifact_path, real_dataset)\n",
        "fourier_test_df_path = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", \"fourier_test_list.csv\")\n",
        "\n",
        "# si convertono nello spettro di fourier le immagini del dataset di test\n",
        "build.convert_test(fake_dataset_path, real_dataset_path, test_df, fourier_test_df_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
      "metadata": {
        "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
        "outputId": "7ff19abf-6ff7-4f31-bd3e-a07d07ca90dd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "fourier_test_df = pd.read_csv(fourier_test_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
      "metadata": {
        "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
        "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "temp_df = fourier_test_df\n",
        "temp_df.head()\n",
        "temp_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b3fa3b2",
      "metadata": {},
      "outputs": [],
      "source": [
        "# directory da dove vengono prelevate le immagini del dataset di test\n",
        "fake_data_dir = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", fake_dataset)\n",
        "real_data_dir = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", real_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
      "metadata": {
        "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# testo i fake\n",
        "current_test = \"fake\"\n",
        "database = df_enc\n",
        "\n",
        "fake_images = temp_df[current_test].dropna()\n",
        "print(len(fake_images))\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for i in tqdm(fake_images, desc=\"testing on fake images...\"):\n",
        "    path = os.path.join(fake_data_dir, i)\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "    img_enc = get_image_embeddings(img, model, device)\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "    \n",
        "    if \"real\" in str(closest_label):\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
      "metadata": {
        "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# testo i real\n",
        "current_test = \"real\"\n",
        "database = df_enc\n",
        "\n",
        "real_images = temp_df[current_test]\n",
        "print(len(real_images))\n",
        "\n",
        "for i in tqdm(real_images, desc=\"testing on real images...\"):\n",
        "    path = os.path.join(real_data_dir, i)\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "    img_enc = get_image_embeddings(img, model, device)\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "\n",
        "    if \"real\" in str(closest_label):\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85706e81-3068-4150-9773-320a8aa98c69",
      "metadata": {
        "id": "85706e81-3068-4150-9773-320a8aa98c69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# creo i vettori di ground truth\n",
        "y_true = np.array([\"fake\"] * len(temp_df[\"fake\"].dropna()))\n",
        "temp = np.array([\"real\"] * len(temp_df[\"real\"]))\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "\n",
        "# calcolo la matrice di confusione (quella di scikit-learn dispone i risultati come nella cella di sotto)\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
      "metadata": {
        "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# metriche\n",
        "accuracy = round((tp + tn) / (tp + tn + fp + fn), 4) * 100\n",
        "precision = round((tp) / (tp + fp), 4) * 100\n",
        "recall = round((tp) / (tp + fn), 4) * 100\n",
        "specificity = round((tn) / (tn + fp) * 100, 4)\n",
        "f1_score = round((2 * precision * recall) / (precision + recall), 4)\n",
        "\n",
        "print({\"Accuracy\":accuracy, \"Precision\":precision, \"Recall\":recall, \"Specificity\":specificity, \"F1 Score\":f1_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8fe87718",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si carica il df di test per creare quello di one-shot\n",
        "test_df = pd.read_csv(test_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4026c98d",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"oneshot\")\n",
        "\n",
        "# se non c'è la cartella della combinazione dei dataset scelti la si crea\n",
        "if not os.path.isdir(path): \n",
        "    os.mkdir(path)\n",
        "    os.mkdir(os.path.join(path, real_dataset))\n",
        "    os.mkdir(os.path.join(path, fake_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a95d47f8",
      "metadata": {},
      "outputs": [],
      "source": [
        "# size è il numero di immagini da aggiungere al df degli encodings per fare one-shot\n",
        "size = 1000\n",
        "oneshot_df_path = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"oneshot\", \"oneshot.csv\")\n",
        "\n",
        "fake_dataset_path = os.path.join(\"..\", \"..\", \"artifact\", fake_dataset, \"metadata.csv\")\n",
        "\n",
        "# si crea il dataset per il one-shot (n.b. df_test deve essere quello non convertito in fourier)\n",
        "build.oneshot(fake_dataset_path, test_df, size, oneshot_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa1d7810",
      "metadata": {},
      "outputs": [],
      "source": [
        "oneshot_df = pd.read_csv(oneshot_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b733e7a9",
      "metadata": {},
      "outputs": [],
      "source": [
        "fourier_oneshot_df_path = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"oneshot\", \"fourier_oneshot.csv\")\n",
        "\n",
        "fake_dataset_path = os.path.join(\"..\", \"..\", \"artifact\", fake_dataset)\n",
        "\n",
        "# si converte il dataframe di oneshot in fourier\n",
        "build.convert_oneshot(fake_dataset_path, oneshot_df, fourier_oneshot_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb88a484",
      "metadata": {},
      "outputs": [],
      "source": [
        "fourier_oneshot_df = pd.read_csv(fourier_oneshot_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b209ee97",
      "metadata": {},
      "outputs": [],
      "source": [
        "# per ricaricare il modello\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "fake_data_dir = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"oneshot\", fake_dataset)\n",
        "real_data_dir = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"oneshot\", real_dataset)\n",
        "\n",
        "# si creano gli embeddings delle immagini da aggiungere per il one-shot learning\n",
        "df_enc_oneshot = get_encoding_csv(model, fourier_oneshot_df[\"Anchor\"], fake_data_dir, real_data_dir, device)\n",
        "df_enc_oneshot.to_csv(\"database_oneshot.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "269d0fc9",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_enc = pd.read_csv(\"database.csv\")\n",
        "df_enc_oneshot = pd.read_csv(\"database_oneshot.csv\")\n",
        "\n",
        "# concateno i due dataframe di encoding \n",
        "df_enc = pd.concat([df_enc, df_enc_oneshot], axis=0).reset_index(drop=True)\n",
        "print(len(df_enc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c538ecfc",
      "metadata": {},
      "outputs": [],
      "source": [
        "fake_data_dir = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", fake_dataset)\n",
        "real_data_dir = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", real_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b6e7c1",
      "metadata": {},
      "outputs": [],
      "source": [
        "fourier_test_df_path = os.path.join(\"..\", \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", \"fourier_test_list.csv\")\n",
        "# si rifanno i test per vedere quanto siano migliorate le metriche\n",
        "fourier_test_df = pd.read_csv(fourier_test_df_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bfb877d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "temp_df = fourier_test_df\n",
        "temp_df.head()\n",
        "temp_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87a4b754",
      "metadata": {},
      "outputs": [],
      "source": [
        "# testo i fake\n",
        "current_test = \"fake\"\n",
        "database = df_enc\n",
        "\n",
        "fake_images = temp_df[current_test].dropna()\n",
        "print(len(fake_images))\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for i in tqdm(fake_images, desc=\"testing on fake images...\"):\n",
        "    path = os.path.join(fake_data_dir, i)\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "    img_enc = get_image_embeddings(img, model, device)\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "    \n",
        "    if \"real\" in str(closest_label):\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f00daff3",
      "metadata": {},
      "outputs": [],
      "source": [
        "# testo i real\n",
        "current_test = \"real\"\n",
        "database = df_enc\n",
        "\n",
        "real_images = temp_df[current_test]\n",
        "print(len(real_images))\n",
        "\n",
        "for i in tqdm(real_images, desc=\"testing on real images...\"):\n",
        "    path = os.path.join(real_data_dir, i)\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "    img_enc = get_image_embeddings(img, model, device)\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "\n",
        "    if \"real\" in str(closest_label):\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0d06711",
      "metadata": {},
      "outputs": [],
      "source": [
        "# creo i vettori di ground truth\n",
        "y_true = np.array([\"fake\"] * len(temp_df[\"fake\"].dropna()))\n",
        "temp = np.array([\"real\"] * len(temp_df[\"real\"]))\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "\n",
        "# calcolo la matrice di confusione (quella di scikit-learn dispone i risultati come nella cella di sotto)\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0444a82",
      "metadata": {},
      "outputs": [],
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# metriche\n",
        "accuracy_oneshot = round((tp + tn) / (tp + tn + fp + fn), 4) * 100\n",
        "precision_oneshot = round((tp) / (tp + fp), 4) * 100\n",
        "recall_oneshot = round((tp) / (tp + fn), 4) * 100\n",
        "specificity_oneshot = round((tn) / (tn + fp) * 100, 4)\n",
        "f1_score_oneshot = round((2 * precision * recall) / (precision + recall), 4)\n",
        "\n",
        "print({\"Accuracy\":accuracy_oneshot, \"Precision\":precision_oneshot, \"Recall\":recall_oneshot, \"Specificity\":specificity_oneshot, \"F1 Score\":f1_score_oneshot})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6aac2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si salvano i risultati in un file .csv\n",
        "data = {\n",
        "    \"Metrica\": [\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1 Score\"],\n",
        "    \"Prima\": [accuracy, precision, recall, specificity, f1_score],\n",
        "    \"Dopo\": [accuracy_oneshot, precision_oneshot, recall_oneshot, specificity_oneshot, f1_score_oneshot]\n",
        "}\n",
        "\n",
        "df_results = pd.DataFrame(data)\n",
        "\n",
        "# si differenziano i risultati in base al tipo di dataset usato\n",
        "path = os.path.join(\"..\", \"results\", \"oneshot\", \"siamese_\" + fake_dataset + \"_results.csv\")\n",
        "\n",
        "df_results.to_csv(path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "697038b1",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_melted = df_results.melt(id_vars=\"Metrica\", var_name=\"Differenza\", value_name=\"Valore\")\n",
        "\n",
        "sns.barplot(data=df_melted, x=\"Metrica\", y=\"Valore\", hue=\"Differenza\")\n",
        "\n",
        "plt.title('Confronto delle Metriche tra le Categorie')\n",
        "plt.xlabel('Metriche')\n",
        "plt.ylabel('Valore')\n",
        "plt.legend(title='Categoria')\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60b166d3",
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "y_pred_nd = np.array(y_pred)\n",
        "\n",
        "y_true_binary = np.where(y_true == \"real\", 0, 1)\n",
        "y_pred_binary = np.where(y_pred_nd == \"real\", 0, 1)\n",
        "\n",
        "ConfusionMatrixDisplay.from_predictions(y_true, y_pred)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fvab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
