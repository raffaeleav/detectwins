{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a907622a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# si aggiunge al path la cartella utils per avere visibilità del module\n",
        "module_path = Path(os.getcwd()).parent.parent\n",
        "module_path = os.path.join(module_path, \"project-detective\")\n",
        "\n",
        "sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import timm\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import utils.build_dataset as bd\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
      "metadata": {
        "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# serve per ricaricare automaticamente il codice modificato\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# directory da dove vengono prelevate le immagini\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "\n",
        "# per far funzionare il modello su immagini rgb o in scala di grigi (per usare fourier)\n",
        "mode=\"rgb\"\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "LR = 0.001\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "DEVICE = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c035a79-a777-4fb4-83fc-c71f1f4d37a7",
      "metadata": {
        "id": "6c035a79-a777-4fb4-83fc-c71f1f4d37a7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# costruisco un csv da 10000 righe casuali su cui allenare il modello per creare gli embeddings\n",
        "bd.main(10000)\n",
        "\n",
        "csv_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
        "df = pd.read_csv(csv_path)\n",
        "\n",
        "df = df.sample(frac=1)\n",
        "\n",
        "df.head()\n",
        "\n",
        "train_df, valid_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "\n",
        "print(f\"train dataset size: {len(train_df)}\")\n",
        "print(f\"val dataset size: {len(valid_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
      "metadata": {
        "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# carica le immagini nel dataset\n",
        "class APN_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "      # le immagini Anchor sono memorizzate in due dataset diversi\n",
        "      if str(row.Anchor).startswith(\"coco\"):\n",
        "        A_img = io.imread(os.path.join(real_data_dir, row.Anchor))\n",
        "        P_img = io.imread(os.path.join(real_data_dir, row.Positive))\n",
        "        N_img = io.imread(os.path.join(fake_data_dir, row.Negative))\n",
        "\n",
        "      else:\n",
        "        A_img = io.imread(os.path.join(fake_data_dir, row.Anchor))\n",
        "        P_img = io.imread(os.path.join(fake_data_dir, row.Positive))\n",
        "        N_img = io.imread(os.path.join(real_data_dir, row.Negative))\n",
        "\n",
        "      # normalizzazione per immagini in rgb \n",
        "      A_img = torch.from_numpy(A_img).permute(2, 0, 1) / 255.0\n",
        "      P_img = torch.from_numpy(P_img).permute(2, 0, 1) / 255.0\n",
        "      N_img = torch.from_numpy(N_img).permute(2, 0, 1) / 255.0\n",
        "\n",
        "    if mode == \"grey_scale\":\n",
        "      A_img = np.expand_dims(A_img, 0)\n",
        "      P_img = np.expand_dims(P_img, 0)\n",
        "      N_img = np.expand_dims(N_img, 0)\n",
        "      \n",
        "      A_img = torch.from_numpy(A_img) / 255.0\n",
        "      P_img = torch.from_numpy(P_img) / 255.0\n",
        "      N_img = torch.from_numpy(N_img) / 255.0\n",
        "\n",
        "    # A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
        "    # P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
        "    # N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
        "\n",
        "    return A_img, P_img, N_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8203b726-6dcc-41fc-ac33-d98f58e61ac7",
      "metadata": {
        "id": "8203b726-6dcc-41fc-ac33-d98f58e61ac7",
        "outputId": "60287971-91ea-41f4-e564-ec8524cb8d3d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainset = APN_Dataset(train_df)\n",
        "validset = APN_Dataset(valid_df)\n",
        "\n",
        "print(f\"trainset size: {len(trainset)}\")\n",
        "print(f\"validset size: {len(validset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4fae8215-4694-4710-b55a-e9c10bf42690",
      "metadata": {
        "id": "4fae8215-4694-4710-b55a-e9c10bf42690",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "validloader = DataLoader(validset, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b9c0301-e6a8-47cb-91f8-9850b78e39d5",
      "metadata": {
        "id": "9b9c0301-e6a8-47cb-91f8-9850b78e39d5",
        "outputId": "0be94549-1119-4856-dce2-a7df0229a36d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(f\"#batches in trainloader : {len(trainloader)}\")\n",
        "print(f\"#batches in validloader : {len(validloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
      "metadata": {
        "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione per caricare il modello di rete neurale direttamente dalle repository online\n",
        "class APN_Model(nn.Module):\n",
        "\n",
        "  # size del vettore di embedding\n",
        "  def __init__(self, emb_size = 512):\n",
        "    super(APN_Model, self).__init__()\n",
        "\n",
        "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
        "    self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=False)\n",
        "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "  def forward(self, images):\n",
        "    embeddings = self.efficientnet(images)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a64f5032-dc37-4858-a901-d17b2eaed4db",
      "metadata": {
        "id": "a64f5032-dc37-4858-a901-d17b2eaed4db",
        "tags": []
      },
      "outputs": [],
      "source": [
        "model = APN_Model()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"grey_scale\":\n",
        "    model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "try:\n",
        "  model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "except:\n",
        "  print(\"no embedding models found, starting training...\") \n",
        "  pass\n",
        "\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
      "metadata": {
        "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di train\n",
        "def train_fn(model, dataloader, optimizer, criterion):\n",
        "  model.train()\n",
        "  # on dropout \n",
        "  total_loss = 0.0\n",
        "\n",
        "  for A, P, N in tqdm(dataloader, desc=\"model training...\"):\n",
        "    A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
        "    A_embs = model(A)\n",
        "    P_embs = model(P)\n",
        "    N_embs = model(N)\n",
        "\n",
        "    # criterion è la funzione di loss triplet\n",
        "    loss = criterion(A_embs, P_embs, N_embs)\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19ec6d56-9168-4980-9164-62660537f1ff",
      "metadata": {
        "id": "19ec6d56-9168-4980-9164-62660537f1ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di evaluation\n",
        "def eval_fn(model, dataloader, criterion):\n",
        "  model.eval() \n",
        "  # off dropout\n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for A, P, N in tqdm(dataloader, desc=\"model validating...\"):\n",
        "      A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
        "\n",
        "      A_embs = model(A)\n",
        "      P_embs = model(P)\n",
        "      N_embs = model(N)\n",
        "\n",
        "      loss = criterion(A_embs, P_embs, N_embs)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
      "metadata": {
        "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# triplet loss e adam\n",
        "criterion = nn.TripletMarginLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
      "metadata": {
        "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
        "tags": []
      },
      "outputs": [],
      "source": [
        "valid_csv_path = os.path.join(\"..\", \"results\", \"emb_model_results.csv\")\n",
        "\n",
        "# se il df esiste si può prendere la precedente val loss \n",
        "try: \n",
        "  df = pd.read_csv(valid_csv_path)\n",
        "  best_valid_loss = df.iloc[0][\"valid_loss\"]\n",
        "except:\n",
        "  best_valid_loss = np.inf\n",
        "\n",
        "  df = pd.DataFrame(columns=[\"valid_loss\", \"iteration\"])\n",
        "  df.loc[0] = [\n",
        "    best_valid_loss,\n",
        "    0\n",
        "  ]\n",
        "  pass\n",
        "\n",
        "# training\n",
        "training_epoch_loss = []\n",
        "validation_epoch_loss = []\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  train_loss = train_fn(model, trainloader, optimizer, criterion)\n",
        "  valid_loss = eval_fn(model, validloader, criterion)\n",
        "\n",
        "  training_epoch_loss.append(train_loss)\n",
        "  validation_epoch_loss.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), \"emb_model.pt\")\n",
        "    best_valid_loss = valid_loss\n",
        "\n",
        "    i = int(df.iloc[0][\"iteration\"])\n",
        "    df.loc[0] = [\n",
        "      best_valid_loss, \n",
        "      i +1\n",
        "    ]\n",
        "    df.to_csv(valid_csv_path, index=False)\n",
        "\n",
        "    print(\"successful weights saving...\")\n",
        "\n",
        "  print(f\"epochs: {i+1}, train_loss: {train_loss}, valid_loss: {valid_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ca40d35",
      "metadata": {},
      "outputs": [],
      "source": [
        "# plot della training e validation loss\n",
        "plt.plot(training_epoch_loss, label=\"train_loss\")\n",
        "plt.plot(validation_epoch_loss, label=\"val_loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fvab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
