{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "dccf7dfb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# si aggiunge al path la cartella utils per avere visibilità del module\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "module_path = os.path.join(path, \"detectwins\")\n",
        "\n",
        "sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import utils\n",
        "import utils.datasets as datasets\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from random import sample\n",
        "from sklearn.metrics import confusion_matrix, average_precision_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "18cd52ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "artifact_path = os.path.join(path, \"artifact\")\n",
        "project_path = os.path.join(path, \"detectwins\")\n",
        "\n",
        "fake_dataset = \"taming_transformer\"\n",
        "real_dataset = \"coco\"\n",
        "\n",
        "# directory da dove vengono prelevate le immagini per il testing (devono essere nello spettro di fourier)\n",
        "fake_data_dir = os.path.join(project_path, \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", fake_dataset)\n",
        "real_data_dir = os.path.join(project_path, \"temp\", fake_dataset + \"+\" + real_dataset, \"test\", real_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# config\n",
        "device=\"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c2080916",
      "metadata": {},
      "outputs": [],
      "source": [
        "model = utils.ApnModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
      "metadata": {
        "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
        "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# per ricaricare il modello già allenato e il dataset di encoding (che servirà per il testing)\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f6d62dd1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# su quante immagini deve essere condotto il test\n",
        "test_size = 1000\n",
        "\n",
        "# si prelevano le immagini per fare il test\n",
        "fake_images_paths = utils.get_file_paths(fake_data_dir)\n",
        "real_images_paths = utils.get_file_paths(real_data_dir)\n",
        "\n",
        "fake_images = sample(fake_images_paths, test_size)\n",
        "real_images = sample(real_images_paths, test_size * 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "6ea1ebfd",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.isdir(os.path.join(\"..\", \"temp\")):\n",
        "    datasets.fourier(fake_dataset, real_dataset, artifact_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "7882cc74",
      "metadata": {},
      "outputs": [],
      "source": [
        "# cartelle dove prelevare le immagini del dataset di training \n",
        "fake_df_out_dir = os.path.join(\"..\", \"temp\", \"taming_transformer+coco\", \"train\", \"taming_transformer\")\n",
        "real_df_out_dir = os.path.join(\"..\", \"temp\", \"taming_transformer+coco\", \"train\", \"coco\")\n",
        "\n",
        "# si usa il dataset di training per creare il dataset di encodings che serve per il testing\n",
        "df_out_path = os.path.join(\"..\", \"datasets\", \"fourier_out.csv\")\n",
        "df_out = pd.read_csv(df_out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "73d6a250",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si creano gli embeddings che vengono memorizzati \n",
        "if not os.path.isfile(\"database.csv\"):\n",
        "    df_enc = utils.get_encoding_csv(model, df_out[\"Anchor\"], fake_df_out_dir, real_df_out_dir, device)\n",
        "    df_enc.to_csv(\"database.csv\", index=False)\n",
        "\n",
        "else: \n",
        "    df_enc = pd.read_csv(\"database.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
      "metadata": {
        "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
        "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "y_true = []\n",
        "y_pred = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
      "metadata": {
        "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# testo i fake\n",
        "for i in tqdm(fake_images, desc=\"testing on fake images...\"):\n",
        "    path = i\n",
        "\n",
        "    # si legge l'immagine\n",
        "    img = io.imread(path)\n",
        "    # si ottiene il vettore di embeddings dell'immagine\n",
        "    img_enc = utils.get_image_embeddings(img, model, device)\n",
        "    # si cerca nel dataset con gli encodings un'immagine simile \n",
        "    closest_label = utils.search_in_database(img_enc, df_enc)\n",
        "    \n",
        "    # se nel path dell'immagine c'è il nome del dataset real è real\n",
        "    if real_dataset in str(closest_label):\n",
        "        y_pred.append(\"real\")\n",
        "    # viceversa\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
      "metadata": {
        "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# testo i real\n",
        "for i in tqdm(real_images, desc=\"testing on real images...\"):\n",
        "    path = i\n",
        "\n",
        "    img = io.imread(path)\n",
        "    img_enc = utils.get_image_embeddings(img, model, device)\n",
        "    closest_label = utils.search_in_database(img_enc, df_enc)\n",
        "\n",
        "    if real_dataset in str(closest_label):\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85706e81-3068-4150-9773-320a8aa98c69",
      "metadata": {
        "id": "85706e81-3068-4150-9773-320a8aa98c69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# creo i vettori di ground truth\n",
        "y_true = np.array([\"fake\"] * len(fake_images))\n",
        "temp = np.array([\"real\"] * len(real_images))\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "\n",
        "# calcolo la matrice di confusione \n",
        "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
      "metadata": {
        "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# metriche\n",
        "accuracy = round((tp + tn) / (tp + tn + fp + fn), 4) * 100\n",
        "precision = round((tp) / (tp + fp), 4) * 100\n",
        "recall = round((tp) / (tp + fn), 4) * 100\n",
        "specificity = round((tn) / (tn + fp) * 100, 4)\n",
        "f1_score = round((2 * precision * recall) / (precision + recall), 4)\n",
        "\n",
        "print({\"Accuracy\":accuracy, \"Precision\":precision, \"Recall\":recall, \"Specificity\":specificity, \"F1 Score\":f1_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b246eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "bin_y_true = []\n",
        "bin_y_pred = []\n",
        "\n",
        "for t in y_true:\n",
        "    if t == \"fake\":\n",
        "        bin_y_true.append(1)\n",
        "    else:\n",
        "        bin_y_true.append(0)\n",
        "\n",
        "\n",
        "for p in y_pred:\n",
        "    if p == \"fake\":\n",
        "        bin_y_pred.append(1)\n",
        "    else:\n",
        "        bin_y_pred.append(0)\n",
        "\n",
        "aps = average_precision_score(bin_y_true, bin_y_pred)\n",
        "\n",
        "print(\"Average precision score: \" + aps)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "detectwins",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
