{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import sys\n",
        "import timm\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
      "metadata": {
        "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# serve per ricaricare automaticamente il codice modificato\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# directory principale di training, perche' nel file .csv ci sono solo i nomi dei file (immagini), da modificare per \n",
        "path = Path(os.getcwd()).parent.parent\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"cycle_gan\")\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "LR = 0.001\n",
        "\n",
        "EPOCHS = 30\n",
        "\n",
        "DEVICE = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6c035a79-a777-4fb4-83fc-c71f1f4d37a7",
      "metadata": {
        "id": "6c035a79-a777-4fb4-83fc-c71f1f4d37a7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2400\n",
            "600\n"
          ]
        }
      ],
      "source": [
        "# df che devo creare\n",
        "csv_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
        "df = pd.read_csv(csv_path)\n",
        "df.head()\n",
        "train_df, valid_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "\n",
        "print(train_df.size)\n",
        "print(valid_df.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
      "metadata": {
        "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# carica le immagini nel dataset\n",
        "class APN_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    \n",
        "    A_img = io.imread(os.path.join(real_data_dir, row.Anchor))\n",
        "    P_img = io.imread(os.path.join(real_data_dir, row.Positive))\n",
        "    N_img = io.imread(os.path.join(fake_data_dir, row.Negative))\n",
        "\n",
        "    # permute because the third channel has to be in first channel in torch\n",
        "\n",
        "    A_img = torch.from_numpy(A_img).permute(2, 0, 1) / 255.0\n",
        "    P_img = torch.from_numpy(P_img).permute(2, 0, 1) / 255.0\n",
        "    N_img = torch.from_numpy(N_img).permute(2, 0, 1) / 255.0\n",
        "    \n",
        "    #A_img = np.expand_dims(A_img, 0)\n",
        "    #P_img = np.expand_dims(P_img, 0)\n",
        "    #N_img = np.expand_dims(N_img, 0)\n",
        "    \n",
        "    # normalizzazione per non far divergere il comportamento della rete\n",
        "    # il valore dell'immagine sarà compreso tra 0 e 1\n",
        "    #A_img = torch.from_numpy(A_img) / 255.0\n",
        "    #P_img = torch.from_numpy(P_img) / 255.0\n",
        "    #N_img = torch.from_numpy(N_img) / 255.0\n",
        "\n",
        "    #A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
        "    #P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
        "    #N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
        "\n",
        "    return A_img, P_img, N_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8203b726-6dcc-41fc-ac33-d98f58e61ac7",
      "metadata": {
        "id": "8203b726-6dcc-41fc-ac33-d98f58e61ac7",
        "outputId": "60287971-91ea-41f4-e564-ec8524cb8d3d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of trainset: 800\n",
            "Size of validset: 200\n"
          ]
        }
      ],
      "source": [
        "trainset = APN_Dataset(train_df)\n",
        "validset = APN_Dataset(valid_df)\n",
        "\n",
        "print(f\"Size of trainset: {len(trainset)}\")\n",
        "print(f\"Size of validset: {len(validset)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "4fae8215-4694-4710-b55a-e9c10bf42690",
      "metadata": {
        "id": "4fae8215-4694-4710-b55a-e9c10bf42690",
        "tags": []
      },
      "outputs": [],
      "source": [
        "trainloader = DataLoader(trainset, batch_size = BATCH_SIZE, shuffle = True)\n",
        "validloader = DataLoader(validset, batch_size = BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "9b9c0301-e6a8-47cb-91f8-9850b78e39d5",
      "metadata": {
        "id": "9b9c0301-e6a8-47cb-91f8-9850b78e39d5",
        "outputId": "0be94549-1119-4856-dce2-a7df0229a36d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No. of batches in trainloader : 25\n",
            "No. of batches in validloader : 7\n"
          ]
        }
      ],
      "source": [
        "print(f\"No. of batches in trainloader : {len(trainloader)}\")\n",
        "print(f\"No. of batches in validloader : {len(validloader)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
      "metadata": {
        "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# FUNZIONE PER CARICARE IL MODELLO DI RETE NEURALE DIRETTAMENTE DALLE REPOSITORY ONLINE\n",
        "class APN_Model(nn.Module):\n",
        "\n",
        "  # QUI DEFINISCO LA SIZE DEL VETTORE DI EMBEDDING\n",
        "  def __init__(self, emb_size = 512):\n",
        "    super(APN_Model, self).__init__()\n",
        "\n",
        "    # QUI CAIRCATE IL MODELLO, IN QUESTO CASO EFFICIENTNET VERSIONE B0 (LA PIù LEGGERA DELLA FAMIGLIA)\n",
        "    self.efficientnet = timm.create_model('tf_efficientnetv2_b0', pretrained=False)\n",
        "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "  def forward(self, images):\n",
        "    embeddings = self.efficientnet(images)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a64f5032-dc37-4858-a901-d17b2eaed4db",
      "metadata": {
        "id": "a64f5032-dc37-4858-a901-d17b2eaed4db",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APN_Model(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# QUI FATE UNA PICCOLA MODIFICA ALLA RETE PER FARLE AVERE IN INPUT IMMAGINI IN SCALA DI GRIGIO DELLO SPETTRO DI FOURIER\n",
        "model = APN_Model()\n",
        "#model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
      "metadata": {
        "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di train\n",
        "def train_fn(model, dataloader, optimizer, criterion):\n",
        "  model.train() #ON Dropout\n",
        "  total_loss = 0.0\n",
        "\n",
        "  for A, P, N in tqdm(dataloader):\n",
        "    A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
        "\n",
        "    print(\"debug, A shape: \" + str(A.shape), file=sys.stderr)\n",
        "    print(\"debug, P shape: \" + str(P.shape), file=sys.stderr)\n",
        "    print(\"debug, N shape: \" + str(N.shape), file=sys.stderr)\n",
        "\n",
        "    # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
        "    A_embs = model(A)\n",
        "    P_embs = model(P)\n",
        "    N_embs = model(N)\n",
        "\n",
        "    # criterion è la funzione di loss triplet\n",
        "    loss = criterion(A_embs, P_embs, N_embs)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "19ec6d56-9168-4980-9164-62660537f1ff",
      "metadata": {
        "id": "19ec6d56-9168-4980-9164-62660537f1ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di evaluation\n",
        "def eval_fn(model, dataloader, criterion):\n",
        "  model.eval() #OFF Dropout\n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for A, P, N in tqdm(dataloader):\n",
        "      A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
        "\n",
        "      A_embs = model(A)\n",
        "      P_embs = model(P)\n",
        "      N_embs = model(N)\n",
        "\n",
        "      loss = criterion(A_embs, P_embs, N_embs)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
      "metadata": {
        "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# triplet loss e adam\n",
        "criterion = nn.TripletMarginLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
      "metadata": {
        "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:10<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:40<00:00,  5.82s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SAVED_WEIGHTS_SUCCESS\n",
            "EPOCHS : 1 train_loss : 0.07709242343902588 valid_loss : 1.0001568964549474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:09<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 2 train_loss : 0.06895400047302246 valid_loss : 1.0003060443060738\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:09<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.76s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 3 train_loss : 0.05280905723571777 valid_loss : 1.0005918911525182\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:09<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 4 train_loss : 0.0444902753829956 valid_loss : 1.0013280085154943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:09<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 5 train_loss : 0.05393794059753418 valid_loss : 1.003398861203875\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 6 train_loss : 0.056596899032592775 valid_loss : 1.0082073041370936\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:09<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.68s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 7 train_loss : 0.05148090362548828 valid_loss : 1.012553266116551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.73s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 8 train_loss : 0.06835996627807617 valid_loss : 1.0197183915546961\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 9 train_loss : 0.04040017127990723 valid_loss : 1.0401767577443803\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 10 train_loss : 0.04566202163696289 valid_loss : 1.1001971874918257\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.71s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 11 train_loss : 0.05119499683380127 valid_loss : 1.0479861753327506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 12 train_loss : 0.028104445934295653 valid_loss : 1.143664538860321\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:09<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.72s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 13 train_loss : 0.0542191219329834 valid_loss : 1.2192083256585258\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:09<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 14 train_loss : 0.0281227445602417 valid_loss : 1.180212378501892\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 15 train_loss : 0.040870652198791504 valid_loss : 1.334888253893171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 16 train_loss : 0.031151649951934816 valid_loss : 1.498217523097992\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.60s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 17 train_loss : 0.04952632427215576 valid_loss : 1.3368771842547826\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 18 train_loss : 0.04272560596466064 valid_loss : 1.4253429344722204\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 19 train_loss : 0.0333695650100708 valid_loss : 1.3541754484176636\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 20 train_loss : 0.04326772689819336 valid_loss : 1.2618822370256697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 21 train_loss : 0.02914364814758301 valid_loss : 1.2168090173176356\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:08<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.61s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 22 train_loss : 0.03709047794342041 valid_loss : 1.3374554514884949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.63s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 23 train_loss : 0.06832792282104493 valid_loss : 1.4894698091915675\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.62s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 24 train_loss : 0.04843719959259033 valid_loss : 1.457037023135594\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:06<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.64s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 25 train_loss : 0.03777040481567383 valid_loss : 1.318374752998352\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:06<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.65s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 26 train_loss : 0.025347955226898193 valid_loss : 1.2495335681097848\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:06<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 27 train_loss : 0.03032496452331543 valid_loss : 1.3109953488622392\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.74s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 28 train_loss : 0.03428994655609131 valid_loss : 1.392177769115993\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.69s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 29 train_loss : 0.04349386692047119 valid_loss : 1.2390277556010656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/25 [00:00<?, ?it/s]debug, A shape: torch.Size([32, 3, 200, 200])\n",
            "debug, P shape: torch.Size([32, 3, 200, 200])\n",
            "debug, N shape: torch.Size([32, 3, 200, 200])\n",
            "  0%|          | 0/25 [00:07<?, ?it/s]\n",
            "100%|██████████| 7/7 [00:11<00:00,  1.68s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCHS : 30 train_loss : 0.039689018726348876 valid_loss : 1.4396389382226127\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "best_valid_loss = np.Inf\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  train_loss = train_fn(model, trainloader, optimizer, criterion)\n",
        "  valid_loss = eval_fn(model, validloader, criterion)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), 'best_model.pt')\n",
        "    best_valid_loss = valid_loss\n",
        "    print(\"SAVED_WEIGHTS_SUCCESS\")\n",
        "\n",
        "  print(f\"EPOCHS : {i+1} train_loss : {train_loss} valid_loss : {valid_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
      "metadata": {
        "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# QUESTA E' LA FUNZIONE PER GENERARE I VETTORI DI ENCODING o embeddings\n",
        "def get_encoding_csv(model, anc_img_names, dirFolder):\n",
        "  anc_img_names_arr = np.array(anc_img_names)\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in tqdm(anc_img_names_arr):\n",
        "      A = io.imread(os.path.join(dirFolder,i))\n",
        "      A = torch.from_numpy(A).permute(2, 0, 1) / 255.0\n",
        "      #A = np.expand_dims(A, 0)\n",
        "      #A = torch.from_numpy(A.astype(np.int32)) / 255.0\n",
        "      A = A.to(DEVICE)\n",
        "      A_enc = model(A.unsqueeze(0))\n",
        "      encodings.append(A_enc.squeeze().cpu().detach().numpy())\n",
        "\n",
        "    encodings = np.array(encodings)\n",
        "    encodings = pd.DataFrame(encodings)\n",
        "    df_enc = pd.concat([anc_img_names, encodings], axis = 1)\n",
        "\n",
        "    return df_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
      "metadata": {
        "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
        "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1000/1000 [00:53<00:00, 18.84it/s]\n"
          ]
        }
      ],
      "source": [
        "# QUI RICARICO IL MODELLO UNA VOLTA TRAINATO\n",
        "model.load_state_dict(torch.load('best_model.pt'))\n",
        "\n",
        "# QUI CREO IL DATABASE DI FEATURE VECTORS DEL TRAINING SET\n",
        "# gli embeddings vengono aggiunti nel file csv per non rifarlo ad ogni allenamento\n",
        "df_enc = get_encoding_csv(model, df['Anchor'], real_data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
      "metadata": {
        "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
        "outputId": "171dab62-2058-470c-9abf-5ea9495da9b0",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anchor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/test2017/img001490.jpg</td>\n",
              "      <td>-0.001477</td>\n",
              "      <td>-0.042075</td>\n",
              "      <td>0.060224</td>\n",
              "      <td>-0.009346</td>\n",
              "      <td>-0.055168</td>\n",
              "      <td>-0.069095</td>\n",
              "      <td>-0.011967</td>\n",
              "      <td>0.002012</td>\n",
              "      <td>-0.000162</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002250</td>\n",
              "      <td>-0.039156</td>\n",
              "      <td>0.002711</td>\n",
              "      <td>0.015507</td>\n",
              "      <td>0.090329</td>\n",
              "      <td>-0.029148</td>\n",
              "      <td>0.055215</td>\n",
              "      <td>-0.002322</td>\n",
              "      <td>0.015787</td>\n",
              "      <td>0.027064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img108618.jpg</td>\n",
              "      <td>-0.001517</td>\n",
              "      <td>-0.041955</td>\n",
              "      <td>0.060197</td>\n",
              "      <td>-0.009314</td>\n",
              "      <td>-0.055062</td>\n",
              "      <td>-0.068977</td>\n",
              "      <td>-0.012157</td>\n",
              "      <td>0.001882</td>\n",
              "      <td>-0.000054</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002544</td>\n",
              "      <td>-0.039001</td>\n",
              "      <td>0.002708</td>\n",
              "      <td>0.015838</td>\n",
              "      <td>0.090361</td>\n",
              "      <td>-0.028957</td>\n",
              "      <td>0.055266</td>\n",
              "      <td>-0.002278</td>\n",
              "      <td>0.015625</td>\n",
              "      <td>0.026686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/test2017/img000671.jpg</td>\n",
              "      <td>-0.001449</td>\n",
              "      <td>-0.041882</td>\n",
              "      <td>0.060361</td>\n",
              "      <td>-0.009177</td>\n",
              "      <td>-0.054836</td>\n",
              "      <td>-0.069053</td>\n",
              "      <td>-0.012113</td>\n",
              "      <td>0.001896</td>\n",
              "      <td>-0.000160</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002107</td>\n",
              "      <td>-0.039140</td>\n",
              "      <td>0.002775</td>\n",
              "      <td>0.015819</td>\n",
              "      <td>0.090263</td>\n",
              "      <td>-0.029035</td>\n",
              "      <td>0.055281</td>\n",
              "      <td>-0.002281</td>\n",
              "      <td>0.015615</td>\n",
              "      <td>0.026913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/test2017/img001694.jpg</td>\n",
              "      <td>-0.001467</td>\n",
              "      <td>-0.042130</td>\n",
              "      <td>0.060123</td>\n",
              "      <td>-0.009203</td>\n",
              "      <td>-0.055130</td>\n",
              "      <td>-0.069195</td>\n",
              "      <td>-0.012029</td>\n",
              "      <td>0.002117</td>\n",
              "      <td>-0.000144</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002058</td>\n",
              "      <td>-0.039334</td>\n",
              "      <td>0.002682</td>\n",
              "      <td>0.015469</td>\n",
              "      <td>0.090379</td>\n",
              "      <td>-0.029213</td>\n",
              "      <td>0.055229</td>\n",
              "      <td>-0.002355</td>\n",
              "      <td>0.015830</td>\n",
              "      <td>0.027185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/test2017/img030759.jpg</td>\n",
              "      <td>-0.001396</td>\n",
              "      <td>-0.042091</td>\n",
              "      <td>0.060217</td>\n",
              "      <td>-0.009294</td>\n",
              "      <td>-0.055204</td>\n",
              "      <td>-0.069004</td>\n",
              "      <td>-0.012066</td>\n",
              "      <td>0.002020</td>\n",
              "      <td>-0.000075</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002389</td>\n",
              "      <td>-0.039104</td>\n",
              "      <td>0.002778</td>\n",
              "      <td>0.015493</td>\n",
              "      <td>0.090327</td>\n",
              "      <td>-0.029045</td>\n",
              "      <td>0.055220</td>\n",
              "      <td>-0.002149</td>\n",
              "      <td>0.015690</td>\n",
              "      <td>0.026920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 513 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Anchor         0         1         2  \\\n",
              "0   coco/coco2017/test2017/img001490.jpg -0.001477 -0.042075  0.060224   \n",
              "1  coco/coco2017/train2017/img108618.jpg -0.001517 -0.041955  0.060197   \n",
              "2   coco/coco2017/test2017/img000671.jpg -0.001449 -0.041882  0.060361   \n",
              "3   coco/coco2017/test2017/img001694.jpg -0.001467 -0.042130  0.060123   \n",
              "4   coco/coco2017/test2017/img030759.jpg -0.001396 -0.042091  0.060217   \n",
              "\n",
              "          3         4         5         6         7         8  ...       502  \\\n",
              "0 -0.009346 -0.055168 -0.069095 -0.011967  0.002012 -0.000162  ...  0.002250   \n",
              "1 -0.009314 -0.055062 -0.068977 -0.012157  0.001882 -0.000054  ...  0.002544   \n",
              "2 -0.009177 -0.054836 -0.069053 -0.012113  0.001896 -0.000160  ...  0.002107   \n",
              "3 -0.009203 -0.055130 -0.069195 -0.012029  0.002117 -0.000144  ...  0.002058   \n",
              "4 -0.009294 -0.055204 -0.069004 -0.012066  0.002020 -0.000075  ...  0.002389   \n",
              "\n",
              "        503       504       505       506       507       508       509  \\\n",
              "0 -0.039156  0.002711  0.015507  0.090329 -0.029148  0.055215 -0.002322   \n",
              "1 -0.039001  0.002708  0.015838  0.090361 -0.028957  0.055266 -0.002278   \n",
              "2 -0.039140  0.002775  0.015819  0.090263 -0.029035  0.055281 -0.002281   \n",
              "3 -0.039334  0.002682  0.015469  0.090379 -0.029213  0.055229 -0.002355   \n",
              "4 -0.039104  0.002778  0.015493  0.090327 -0.029045  0.055220 -0.002149   \n",
              "\n",
              "        510       511  \n",
              "0  0.015787  0.027064  \n",
              "1  0.015625  0.026686  \n",
              "2  0.015615  0.026913  \n",
              "3  0.015830  0.027185  \n",
              "4  0.015690  0.026920  \n",
              "\n",
              "[5 rows x 513 columns]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# QUI IL DATABASE COME CSV IN MODO TALE DA NON DOVER FARE QUESTA OPERAZIONE OGNI VOLTA\n",
        "# OVVIAMENTE, SE DEVO FARE UN NUOVO TRAINING DEVO ANCHE RICREARE GLI ENCODINGS\n",
        "df_enc.to_csv('database.csv', index = False)\n",
        "\n",
        "df_enc = pd.read_csv('database.csv')\n",
        "df_enc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
      "metadata": {
        "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# approssimazione della distanza, senza la radice quadrata, per fare i primi\n",
        "# allenamenti velocemente\n",
        "def euclidean_dist(img_enc, anc_enc_arr):\n",
        "    #dist = np.sqrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
        "    dist = np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T)\n",
        "    #dist = np.sqrt(dist)\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
      "metadata": {
        "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
        "outputId": "7ff19abf-6ff7-4f31-bd3e-a07d07ca90dd",
        "tags": []
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'testList.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtestList.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreal\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39msize)\n",
            "File \u001b[1;32mc:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
            "File \u001b[1;32mc:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
            "File \u001b[1;32mc:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'testList.csv'"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('testList.csv')\n",
        "\n",
        "print(df['real'])\n",
        "print(df.size)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
      "metadata": {
        "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def getImageEmbeddings(img, model):\n",
        "\n",
        "    img = np.expand_dims(img, 0)\n",
        "    img = torch.from_numpy(img) / 255\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        img = img.to(DEVICE)\n",
        "        img_enc = model(img.unsqueeze(0))\n",
        "        img_enc = img_enc.detach().cpu().numpy()\n",
        "        img_enc = np.array(img_enc)\n",
        "\n",
        "    return img_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
      "metadata": {
        "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def searchInDatabase(img_enc, database):\n",
        "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
        "    anc_img_names = database['Anchor']\n",
        "\n",
        "    distance = []\n",
        "    for i in range(anc_enc_arr.shape[0]):\n",
        "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
        "        distance = np.append(distance, dist)\n",
        "\n",
        "    closest_idx = np.argsort(distance)\n",
        "\n",
        "    return database['Anchor'][closest_idx[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
      "metadata": {
        "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
        "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "DataTestReal = 'C:/Users/polsi/Desktop/Lavori/DeepFake/Datasets/Artifact/cycle_gan/st/test/'\n",
        "y_true = []\n",
        "y_pred = []\n",
        "tempDf = df\n",
        "tempDf.head()\n",
        "tempDf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
      "metadata": {
        "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Testo i fake\n",
        "currentTest = 'fake'\n",
        "database = df_enc\n",
        "# Prendo i primi 500 Fake\n",
        "for index, row in tqdm(tempDf.iterrows()):\n",
        "    img_name = DataTestReal + row[currentTest]\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = getImageEmbeddings(img, model)\n",
        "\n",
        "    closestLabel = searchInDatabase(img_enc, database)\n",
        "\n",
        "    if \"real\" in closestLabel:\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
      "metadata": {
        "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0e5e4b6e-82f4-4d4f-b797-d8e24be8ec3e",
      "metadata": {
        "id": "0e5e4b6e-82f4-4d4f-b797-d8e24be8ec3e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "database = df_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
      "metadata": {
        "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Testo i real\n",
        "currentTest = 'real'\n",
        "# Prendo i primi 500 Fake\n",
        "for index, row in tqdm(tempDf.iterrows()):\n",
        "    img_name = DataTestReal + row[currentTest]\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = getImageEmbeddings(img, model)\n",
        "\n",
        "    closestLabel = searchInDatabase(img_enc, database)\n",
        "    if \"real\" in closestLabel:\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c465bfd-18ad-4750-b689-739b712185ab",
      "metadata": {
        "id": "4c465bfd-18ad-4750-b689-739b712185ab",
        "outputId": "e974c712-91fb-4fae-c589-85e08a50fb77",
        "tags": []
      },
      "outputs": [],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85706e81-3068-4150-9773-320a8aa98c69",
      "metadata": {
        "id": "85706e81-3068-4150-9773-320a8aa98c69",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Creo i vettori di ground truth\n",
        "y_true = np.array(['fake'] * 1523)\n",
        "print(y_true.shape)\n",
        "\n",
        "temp = np.array(['real'] * 1523)\n",
        "print(temp.shape)\n",
        "\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "print(y_true.shape)\n",
        "\n",
        "# Calcolo la matrice di confusione\n",
        "confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86e1ec24-b7d3-4264-9c89-fa882343fa19",
      "metadata": {
        "id": "86e1ec24-b7d3-4264-9c89-fa882343fa19",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Estraggo dalla matrice di confusione i True Negative, False Positive, False Negative, True Positive\n",
        "TN, FP, FN, TP = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"]).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
      "metadata": {
        "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Calcolo alcune metriche per vedere come si comporta\n",
        "accuracy = round((TP + TN) /(TP + TN + FP + FN), 4) * 100\n",
        "precision = round((TP) / (TP + FP), 4) * 100\n",
        "sensitivy_recall = round((TP) / (TP + FN), 4) * 100\n",
        "specificity = round((TN) / (TN + FP) * 100, 4)\n",
        "F1_score = round((2* precision * sensitivy_recall) / (precision + sensitivy_recall), 2)\n",
        "\n",
        "print({\"Accuracy\":accuracy,\"Precision\":precision,\"Sensitivity_recall\":sensitivy_recall, \"Specificity\": specificity, \"F1_score\":F1_score})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fvab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
