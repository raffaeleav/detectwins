{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7046cde1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# si aggiunge al path la cartella utils per avere visibilità del module\n",
        "module_path = Path(os.getcwd()).parent.parent\n",
        "module_path = os.path.join(module_path, \"project-detective\")\n",
        "\n",
        "sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import utils.mining as mining\n",
        "import utils.datasets as build\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_metric_learning import miners, losses\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
      "metadata": {
        "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# serve per ricaricare il codice modificato\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# configurazione\n",
        "batch_size=32\n",
        "lr=0.001\n",
        "epochs=30\n",
        "device=\"cuda\"\n",
        "\n",
        "# per far funzionare il modello su immagini rgb o in scala di grigi (per usare fourier)\n",
        "mode=\"rgb\"\n",
        "\n",
        "# margin per semi-hard mining con modello pre-allenato\n",
        "margin=0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "1bd2e0e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# directory da dove vengono prelevate le immagini\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
      "metadata": {
        "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# carica le immagini nel dataset\n",
        "class ApnDataset(Dataset):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "      # le immagini Anchor sono memorizzate in due dataset diversi\n",
        "      if str(row.Anchor).startswith(\"coco\"):\n",
        "        a_img = io.imread(os.path.join(real_data_dir, row.Anchor))\n",
        "        p_img = io.imread(os.path.join(real_data_dir, row.Positive))\n",
        "        n_img = io.imread(os.path.join(fake_data_dir, row.Negative))\n",
        "\n",
        "        a_label = 0\n",
        "        p_label = 0\n",
        "        n_label = 1\n",
        "\n",
        "      else:\n",
        "        a_img = io.imread(os.path.join(fake_data_dir, row.Anchor))\n",
        "        p_img = io.imread(os.path.join(fake_data_dir, row.Positive))\n",
        "        n_img = io.imread(os.path.join(real_data_dir, row.Negative))\n",
        "\n",
        "        a_label = 1\n",
        "        p_label = 1\n",
        "        n_label = 0\n",
        "\n",
        "      # normalizzazione per immagini in rgb \n",
        "      a_img = torch.from_numpy(a_img).permute(2, 0, 1) / 255.0\n",
        "      p_img = torch.from_numpy(p_img).permute(2, 0, 1) / 255.0\n",
        "      n_img = torch.from_numpy(n_img).permute(2, 0, 1) / 255.0\n",
        "\n",
        "      a_label = torch.tensor(a_label)\n",
        "      p_label = torch.tensor(p_label)\n",
        "      n_label = torch.tensor(n_label)\n",
        "\n",
        "    if mode == \"grey_scale\":\n",
        "      a_img = np.expand_dims(a_img, 0)\n",
        "      p_img = np.expand_dims(p_img, 0)\n",
        "      n_img = np.expand_dims(n_img, 0)\n",
        "      \n",
        "      a_img = torch.from_numpy(a_img) / 255.0\n",
        "      p_img = torch.from_numpy(p_img) / 255.0\n",
        "      n_img = torch.from_numpy(n_img) / 255.0\n",
        "\n",
        "    # A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
        "    # P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
        "    # N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
        "\n",
        "    return a_img, p_img, n_img, a_label, p_label, n_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
      "metadata": {
        "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# classe per caricare il modello di rete neurale direttamente dalle repository online\n",
        "class ApnModel(nn.Module):\n",
        "\n",
        "  # size del vettore di embedding\n",
        "  def __init__(self, emb_size=512):\n",
        "    super(ApnModel, self).__init__()\n",
        "\n",
        "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
        "    self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=False)\n",
        "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "  def forward(self, images):\n",
        "    embeddings = self.efficientnet(images)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "53d21354",
      "metadata": {},
      "outputs": [],
      "source": [
        "# classe del modello che genera gli embedding per applicare il semi-hard mining\n",
        "class EmbModel(nn.Module):\n",
        "\n",
        "    # size del vettore di embedding\n",
        "    def __init__(self, emb_size = 512):\n",
        "        super(EmbModel, self).__init__()\n",
        "\n",
        "        # gli embedding vengono creati con un modello preallenato (risultato più efficace in test precedenti)\n",
        "        self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=True)\n",
        "        self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "    def forward(self, images):\n",
        "        embeddings = self.efficientnet(images)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "3c37a66e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# funzione per creare embeddings che sarranno sottoposti a semi-hard mining\n",
        "def create_embeddings(model, dataloader, device): \n",
        "    # off dropout\n",
        "    model.eval()\n",
        "\n",
        "    list_df = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a, p, n, al, pl, nl in tqdm(dataloader, desc=\"creating embeddings...\"):\n",
        "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "\n",
        "            temp_df_embs = pd.DataFrame(columns=[\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"])\n",
        "\n",
        "            a_embs = model(a)\n",
        "            p_embs = model(p)\n",
        "            n_embs = model(n)\n",
        "            \n",
        "            # la batch size può variare, perciò ci si basa sulla lunghezza del tensore\n",
        "            batch_size = len(a_embs)\n",
        "            \n",
        "            # ad ogni batch corrisponde un dataframe\n",
        "            for i in range(batch_size): \n",
        "                # si serializzano gli array np in stringhe in modo da memorizzarli nelle celle del datagrame\n",
        "                a, p, n = a_embs[i].cpu().numpy(), p_embs[i].cpu().numpy(), n_embs[i].cpu().numpy()\n",
        "                a, p, n = np.array2string(a, separator=','), np.array2string(p, separator=','), np.array2string(n, separator=',')\n",
        "                \n",
        "                temp_df_embs.loc[i] = [\n",
        "                    a, \n",
        "                    p, \n",
        "                    n\n",
        "                ]\n",
        "            \n",
        "            list_df.append(temp_df_embs)\n",
        "\n",
        "    # concatenazione di tutti i dataframe\n",
        "    df_embs = pd.concat(list_df)\n",
        "\n",
        "    return df_embs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4653903a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmbModel(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model = EmbModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"grey_scale\":\n",
        "    emb_model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "emb_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c584653",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_dataset_path = os.path.join(path, \"artifact\", \"taming_transformer\", \"metadata.csv\")\n",
        "real_dataset_path = os.path.join(path, \"artifact\", \"coco\", \"metadata.csv\")\n",
        "\n",
        "# creo il dataset di triplet iniziale (i triplet sono scelti casualmente)\n",
        "df_out_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
        "build.train(fake_dataset_path, real_dataset_path, df_out_path, 50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "012654d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_out_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
        "df_out = pd.read_csv(df_out_path)\n",
        "\n",
        "apn_dataset = ApnDataset(df_out)\n",
        "dataloader = DataLoader(apn_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "22b9da75",
      "metadata": {},
      "outputs": [],
      "source": [
        "emb_csv_path = os.path.join(\"..\", \"notebooks\", \"embeddings.csv\")\n",
        "\n",
        "# si controlla che siano stati già creati gli embeddings\n",
        "if not Path(emb_csv_path).is_file():\n",
        "    df_emb = create_embeddings(emb_model, dataloader, device)\n",
        "    df_emb.to_csv(emb_csv_path, index=False)\n",
        "\n",
        "df_emb = pd.read_csv(emb_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "41b31e13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset size after semi-hard mining: 6770\n"
          ]
        }
      ],
      "source": [
        "# si concatenano i dataframe delle immagini e degli embeddings sulle colonne per poter filtrare le righe in logica di semi-hard mining\n",
        "df = pd.concat([df_out, df_emb], axis=1)\n",
        "\n",
        "# offline semi-hard mining dei triplets\n",
        "df = mining.offline_semi_hard_mining(df, margin)\n",
        "df = df.drop([\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"], axis=1)\n",
        "\n",
        "print(f\"dataset size after semi-hard mining: {len(df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
      "metadata": {
        "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di train\n",
        "# def train_fn(model, dataloader, optimizer, criterion, miner):\n",
        "def train_fn(model, dataloader, optimizer, criterion):\n",
        "  # on dropout \n",
        "  model.train()\n",
        "  \n",
        "  total_loss = 0.0\n",
        "\n",
        "  for a, p, n, al, pl, nl in tqdm(dataloader, desc=\"model training...\"):\n",
        "    a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "    al, pl, nl = al.to(device), pl.to(device), nl.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
        "    a_embs = model(a)\n",
        "    p_embs = model(p)\n",
        "    n_embs = model(n)\n",
        "\n",
        "    # per usare l'ohm si devono concatenare tutti i tipi di immagine, i triplet verranno creati nella funzione di loss\n",
        "    # embeddings = torch.cat((a_embs, p_embs, n_embs), axis=0)\n",
        "    # labels = torch.cat((al, pl, nl), axis=0)\n",
        "\n",
        "    # online hard mining prima del calcolo della loss\n",
        "    # miner_output = miner(embeddings, labels)\n",
        "    # loss = criterion(embeddings, labels, miner_output)\n",
        "    size = len(a_embs)\n",
        "    a_embs, p_embs, n_embs = mining.online_hard_mining(a_embs, p_embs, n_embs, size, device)\n",
        "    loss = criterion(a_embs, p_embs, n_embs)\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "19ec6d56-9168-4980-9164-62660537f1ff",
      "metadata": {
        "id": "19ec6d56-9168-4980-9164-62660537f1ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di evaluation\n",
        "def eval_fn(model, dataloader, criterion):\n",
        "  # off dropout\n",
        "  model.eval() \n",
        "  \n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for a, p, n, al, pl, nl in tqdm(dataloader, desc=\"model validating...\"):\n",
        "      a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "      al, pl, nl = al.to(device), pl.to(device), nl.to(device)\n",
        "\n",
        "      a_embs = model(a)\n",
        "      p_embs = model(p)\n",
        "      n_embs = model(n)\n",
        "\n",
        "      # embeddings = torch.cat((a_embs, p_embs, n_embs), axis=0)\n",
        "      # labels = torch.cat((al, pl, nl), axis=0)\n",
        "\n",
        "      # loss = criterion(embeddings, labels)\n",
        "      loss = criterion(a_embs, p_embs, n_embs)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "c2080916",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ApnModel(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ApnModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"grey_scale\":\n",
        "    model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "311bed90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# split del nuovo dataframe\n",
        "train_df, valid_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "\n",
        "trainset = ApnDataset(train_df)\n",
        "validset = ApnDataset(valid_df)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
      "metadata": {
        "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# triplet loss, miner (per online hard mining) e adam\n",
        "criterion = nn.TripletMarginLoss()\n",
        "# criterion = losses.TripletMarginLoss(triplets_per_anchor=1)\n",
        "# miner = miners.TripletMarginMiner(margin=margin, type_of_triplets=\"hard\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
      "metadata": {
        "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:42<00:00,  1.66s/it]\n",
            "model validating...:  98%|█████████▊| 42/43 [02:32<00:03,  3.54s/it]c:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "model validating...: 100%|██████████| 43/43 [02:33<00:00,  3.57s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 1, train_loss: 1.0, valid_loss: 2.319122468316278\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [08:15<00:00,  2.91s/it]\n",
            "model validating...: 100%|██████████| 43/43 [02:52<00:00,  4.01s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 2, train_loss: 1.0, valid_loss: 2.616478079973265\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [23:45<00:00,  8.38s/it]\n",
            "model validating...: 100%|██████████| 43/43 [01:48<00:00,  2.53s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 3, train_loss: 1.0, valid_loss: 2.5376359792642815\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [19:52<00:00,  7.02s/it]\n",
            "model validating...: 100%|██████████| 43/43 [01:35<00:00,  2.22s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 4, train_loss: 1.0, valid_loss: 2.8666262280109316\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [09:45<00:00,  3.44s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:55<00:00,  1.30s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 5, train_loss: 1.0, valid_loss: 2.777947464654612\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:57<00:00,  1.75s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:21<00:00,  1.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 6, train_loss: 1.0, valid_loss: 2.9774723829225054\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:01<00:00,  1.42s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:24<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 7, train_loss: 1.0, valid_loss: 2.861196170019549\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:25<00:00,  1.56s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:26<00:00,  1.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 8, train_loss: 1.0, valid_loss: 2.1997130388437314\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:56<00:00,  1.75s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:24<00:00,  1.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 9, train_loss: 1.0, valid_loss: 3.2001021046971165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:36<00:00,  1.63s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:24<00:00,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 10, train_loss: 1.0, valid_loss: 2.935169125712195\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:38<00:00,  1.64s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:25<00:00,  1.68it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 11, train_loss: 1.0, valid_loss: 3.0949352189551953\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:31<00:00,  1.59s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:28<00:00,  1.51it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 12, train_loss: 1.0, valid_loss: 2.919119868167611\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:36<00:00,  1.63s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:24<00:00,  1.74it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 13, train_loss: 1.0, valid_loss: 3.38243623944216\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:39<00:00,  1.65s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:31<00:00,  1.37it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 14, train_loss: 1.0, valid_loss: 2.8942590147949927\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [05:16<00:00,  1.86s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:26<00:00,  1.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 15, train_loss: 1.0, valid_loss: 2.500163729800734\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [05:31<00:00,  1.95s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:27<00:00,  1.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 16, train_loss: 1.0, valid_loss: 3.1967819249907206\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:58<00:00,  1.76s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:34<00:00,  1.23it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 17, train_loss: 1.0, valid_loss: 2.7270595999651177\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [05:13<00:00,  1.85s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:23<00:00,  1.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 18, train_loss: 1.0, valid_loss: 2.9790873444357584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [05:17<00:00,  1.87s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:21<00:00,  1.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 19, train_loss: 1.0, valid_loss: 2.660951331604359\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [03:40<00:00,  1.30s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:21<00:00,  2.02it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 20, train_loss: 1.0, valid_loss: 3.2548431158065796\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:49<00:00,  1.70s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:26<00:00,  1.61it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 21, train_loss: 1.0, valid_loss: 2.862832777721937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [05:17<00:00,  1.87s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:30<00:00,  1.41it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 22, train_loss: 1.0, valid_loss: 2.854075846283935\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [05:13<00:00,  1.84s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:23<00:00,  1.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 23, train_loss: 1.0, valid_loss: 2.89062208353087\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:14<00:00,  1.49s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:23<00:00,  1.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 24, train_loss: 1.0, valid_loss: 2.6332969623942706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [08:38<00:00,  3.05s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:56<00:00,  1.32s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 25, train_loss: 1.0, valid_loss: 3.734464864398158\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:15<00:00,  1.50s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:23<00:00,  1.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 26, train_loss: 1.0, valid_loss: 3.04776070284289\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:12<00:00,  1.49s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:23<00:00,  1.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 27, train_loss: 1.0, valid_loss: 2.7872743592705835\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:12<00:00,  1.48s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:33<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 28, train_loss: 1.0, valid_loss: 2.933988609979319\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:13<00:00,  1.49s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:23<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 29, train_loss: 1.0, valid_loss: 2.327922072521476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 170/170 [04:13<00:00,  1.49s/it]\n",
            "model validating...: 100%|██████████| 43/43 [00:23<00:00,  1.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 30, train_loss: 1.0, valid_loss: 3.009561438893163\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "best_valid_loss = np.Inf\n",
        "\n",
        "training_epoch_loss = []\n",
        "validation_epoch_loss = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  # train_loss = train_fn(model, trainloader, optimizer, criterion, miner)\n",
        "  train_loss = train_fn(model, trainloader, optimizer, criterion)\n",
        "  valid_loss = eval_fn(model, validloader, criterion)\n",
        "\n",
        "  training_epoch_loss.append(train_loss)\n",
        "  validation_epoch_loss.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    best_valid_loss = valid_loss\n",
        "    print(\"successful weights saving...\")\n",
        "\n",
        "  print(f\"epochs: {i+1}, train_loss: {train_loss}, valid_loss: {valid_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "9ca40d35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot della training e validation loss\n",
        "plt.plot(training_epoch_loss, label=\"train_loss\")\n",
        "plt.plot(validation_epoch_loss, label=\"val_loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "97cb5008",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building (real column) test dataframe...: 100%|██████████| 1354/1354 [00:01<00:00, 1013.85it/s]\n",
            "building (fake column) test dataframe...: 100%|██████████| 1354/1354 [00:00<00:00, 1473.80it/s]\n"
          ]
        }
      ],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_dataset_path = os.path.join(path, \"artifact\", \"taming_transformer\", \"metadata.csv\")\n",
        "real_dataset_path = os.path.join(path, \"artifact\", \"coco\", \"metadata.csv\")\n",
        "\n",
        "# creo il dataset di test\n",
        "testList_df_path = os.path.join(\"..\", \"datasets\", \"testList.csv\")\n",
        "build.test(fake_dataset_path, real_dataset_path, testList_df_path, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
      "metadata": {
        "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione per generare i vettori di encoding\n",
        "def get_encoding_csv(model, anc_img_names, dirFolder):\n",
        "  anc_img_names_arr = np.array(anc_img_names)\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in tqdm(anc_img_names_arr, desc=\"creating encodings...\"):\n",
        "\n",
        "      if mode == \"rgb\":\n",
        "        # serve per trovare correttamente l'immagine\n",
        "        if str(i).startswith(\"coco\"):\n",
        "          dir_folder = real_data_dir\n",
        "          a = io.imread(os.path.join(dir_folder, i))\n",
        "\n",
        "        else: \n",
        "          dir_folder = fake_data_dir\n",
        "          a = io.imread(os.path.join(dir_folder, i))\n",
        "\n",
        "        a = torch.from_numpy(a).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "      if mode == \"grey_scale\":\n",
        "        a = io.imread(os.path.join(dir_folder,i))\n",
        "        a = np.expand_dims(a, 0)\n",
        "        a = torch.from_numpy(a.astype(np.int32)) / 255.0\n",
        "        \n",
        "      a = a.to(device)\n",
        "      a_enc = model(a.unsqueeze(0))\n",
        "      encodings.append(a_enc.squeeze().cpu().detach().numpy())\n",
        "\n",
        "    encodings = np.array(encodings)\n",
        "    encodings = pd.DataFrame(encodings)\n",
        "    df_enc = pd.concat([anc_img_names, encodings], axis = 1)\n",
        "\n",
        "    return df_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
      "metadata": {
        "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
        "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "creating encodings...: 100%|██████████| 6770/6770 [02:35<00:00, 43.61it/s]\n"
          ]
        }
      ],
      "source": [
        "# per ricaricare il modello una volta allenato\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "# si creano gli embeddings che vengono memorizzati per non rifarlo ad ogni allenamento\n",
        "df_enc = get_encoding_csv(model, df[\"Anchor\"], real_data_dir)\n",
        "df_enc.to_csv(\"database.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
      "metadata": {
        "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
        "outputId": "171dab62-2058-470c-9abf-5ea9495da9b0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raffa\\AppData\\Local\\Temp\\ipykernel_10232\\2812054046.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_enc = pd.read_csv('database.csv')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anchor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/test2017/img021492.jpg</td>\n",
              "      <td>0.210612</td>\n",
              "      <td>0.172811</td>\n",
              "      <td>-0.032277</td>\n",
              "      <td>-0.015216</td>\n",
              "      <td>-0.018282</td>\n",
              "      <td>0.005794</td>\n",
              "      <td>-0.103214</td>\n",
              "      <td>0.016559</td>\n",
              "      <td>0.050845</td>\n",
              "      <td>...</td>\n",
              "      <td>0.058325</td>\n",
              "      <td>0.111922</td>\n",
              "      <td>0.082920</td>\n",
              "      <td>0.034675</td>\n",
              "      <td>-0.006594</td>\n",
              "      <td>-0.082917</td>\n",
              "      <td>-0.135906</td>\n",
              "      <td>0.052635</td>\n",
              "      <td>-0.087498</td>\n",
              "      <td>-0.030560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img086769.jpg</td>\n",
              "      <td>0.108900</td>\n",
              "      <td>-0.020698</td>\n",
              "      <td>0.043000</td>\n",
              "      <td>-0.013082</td>\n",
              "      <td>0.147749</td>\n",
              "      <td>0.128421</td>\n",
              "      <td>0.056875</td>\n",
              "      <td>0.023271</td>\n",
              "      <td>-0.016304</td>\n",
              "      <td>...</td>\n",
              "      <td>0.023715</td>\n",
              "      <td>0.100520</td>\n",
              "      <td>0.096159</td>\n",
              "      <td>0.008015</td>\n",
              "      <td>-0.022342</td>\n",
              "      <td>0.048572</td>\n",
              "      <td>0.044502</td>\n",
              "      <td>-0.023100</td>\n",
              "      <td>-0.025953</td>\n",
              "      <td>-0.067082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/train2017/img131066.jpg</td>\n",
              "      <td>0.094263</td>\n",
              "      <td>0.047014</td>\n",
              "      <td>0.010586</td>\n",
              "      <td>0.005190</td>\n",
              "      <td>0.079097</td>\n",
              "      <td>0.110496</td>\n",
              "      <td>0.008993</td>\n",
              "      <td>0.039684</td>\n",
              "      <td>0.014335</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009584</td>\n",
              "      <td>0.093602</td>\n",
              "      <td>0.081865</td>\n",
              "      <td>0.020606</td>\n",
              "      <td>-0.024171</td>\n",
              "      <td>0.023134</td>\n",
              "      <td>0.003913</td>\n",
              "      <td>0.009926</td>\n",
              "      <td>-0.064054</td>\n",
              "      <td>-0.082294</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/test2017/img031702.jpg</td>\n",
              "      <td>0.100440</td>\n",
              "      <td>-0.009643</td>\n",
              "      <td>0.018857</td>\n",
              "      <td>-0.018780</td>\n",
              "      <td>0.075334</td>\n",
              "      <td>0.081169</td>\n",
              "      <td>0.008256</td>\n",
              "      <td>-0.005822</td>\n",
              "      <td>0.013397</td>\n",
              "      <td>...</td>\n",
              "      <td>0.054586</td>\n",
              "      <td>0.135010</td>\n",
              "      <td>0.033176</td>\n",
              "      <td>0.044009</td>\n",
              "      <td>0.012364</td>\n",
              "      <td>0.039068</td>\n",
              "      <td>-0.043427</td>\n",
              "      <td>0.015620</td>\n",
              "      <td>-0.060722</td>\n",
              "      <td>-0.106457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/test2017/img023357.jpg</td>\n",
              "      <td>0.230011</td>\n",
              "      <td>0.782740</td>\n",
              "      <td>-0.013900</td>\n",
              "      <td>0.454633</td>\n",
              "      <td>-0.078151</td>\n",
              "      <td>-0.146744</td>\n",
              "      <td>-0.193938</td>\n",
              "      <td>0.072557</td>\n",
              "      <td>0.253341</td>\n",
              "      <td>...</td>\n",
              "      <td>0.068413</td>\n",
              "      <td>0.040207</td>\n",
              "      <td>0.023596</td>\n",
              "      <td>-0.067577</td>\n",
              "      <td>-0.047799</td>\n",
              "      <td>-0.024769</td>\n",
              "      <td>-0.430299</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.179303</td>\n",
              "      <td>-0.012277</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 513 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Anchor         0         1         2  \\\n",
              "0   coco/coco2017/test2017/img021492.jpg  0.210612  0.172811 -0.032277   \n",
              "1  coco/coco2017/train2017/img086769.jpg  0.108900 -0.020698  0.043000   \n",
              "2  coco/coco2017/train2017/img131066.jpg  0.094263  0.047014  0.010586   \n",
              "3   coco/coco2017/test2017/img031702.jpg  0.100440 -0.009643  0.018857   \n",
              "4   coco/coco2017/test2017/img023357.jpg  0.230011  0.782740 -0.013900   \n",
              "\n",
              "          3         4         5         6         7         8  ...       502  \\\n",
              "0 -0.015216 -0.018282  0.005794 -0.103214  0.016559  0.050845  ...  0.058325   \n",
              "1 -0.013082  0.147749  0.128421  0.056875  0.023271 -0.016304  ...  0.023715   \n",
              "2  0.005190  0.079097  0.110496  0.008993  0.039684  0.014335  ...  0.009584   \n",
              "3 -0.018780  0.075334  0.081169  0.008256 -0.005822  0.013397  ...  0.054586   \n",
              "4  0.454633 -0.078151 -0.146744 -0.193938  0.072557  0.253341  ...  0.068413   \n",
              "\n",
              "        503       504       505       506       507       508       509  \\\n",
              "0  0.111922  0.082920  0.034675 -0.006594 -0.082917 -0.135906  0.052635   \n",
              "1  0.100520  0.096159  0.008015 -0.022342  0.048572  0.044502 -0.023100   \n",
              "2  0.093602  0.081865  0.020606 -0.024171  0.023134  0.003913  0.009926   \n",
              "3  0.135010  0.033176  0.044009  0.012364  0.039068 -0.043427  0.015620   \n",
              "4  0.040207  0.023596 -0.067577 -0.047799 -0.024769 -0.430299  0.079165   \n",
              "\n",
              "        510       511  \n",
              "0 -0.087498 -0.030560  \n",
              "1 -0.025953 -0.067082  \n",
              "2 -0.064054 -0.082294  \n",
              "3 -0.060722 -0.106457  \n",
              "4 -0.179303 -0.012277  \n",
              "\n",
              "[5 rows x 513 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_enc = pd.read_csv('database.csv')\n",
        "df_enc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
      "metadata": {
        "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# approssimazione della distanza, senza la radice quadrata, per fare i primi allenamenti velocemente\n",
        "def euclidean_dist(img_enc, anc_enc_arr):\n",
        "    # dist = np.sqrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
        "    dist = np.dot(img_enc - anc_enc_arr, (img_enc - anc_enc_arr).T)\n",
        "    # dist = np.sqrt(dist)\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
      "metadata": {
        "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
        "outputId": "7ff19abf-6ff7-4f31-bd3e-a07d07ca90dd",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       coco/coco2017/train2017/img132965.jpg\n",
            "1       coco/coco2017/train2017/img050158.jpg\n",
            "2       coco/coco2017/train2017/img048933.jpg\n",
            "3       coco/coco2017/train2017/img122642.jpg\n",
            "4       coco/coco2017/train2017/img045822.jpg\n",
            "                        ...                  \n",
            "1349     coco/coco2017/test2017/img013078.jpg\n",
            "1350    coco/coco2017/train2017/img142556.jpg\n",
            "1351    coco/coco2017/train2017/img078365.jpg\n",
            "1352    coco/coco2017/train2017/img076725.jpg\n",
            "1353    coco/coco2017/train2017/img140844.jpg\n",
            "Name: real, Length: 1354, dtype: object\n",
            "2708\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real</th>\n",
              "      <th>fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/train2017/img132965.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/130/img00183...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img050158.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/174/img00421...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/train2017/img048933.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img036265.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/train2017/img122642.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/126/img00158...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/train2017/img045822.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img029006.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    real  \\\n",
              "0  coco/coco2017/train2017/img132965.jpg   \n",
              "1  coco/coco2017/train2017/img050158.jpg   \n",
              "2  coco/coco2017/train2017/img048933.jpg   \n",
              "3  coco/coco2017/train2017/img122642.jpg   \n",
              "4  coco/coco2017/train2017/img045822.jpg   \n",
              "\n",
              "                                                fake  \n",
              "0  tt-cc/cin_k600_p1.0_a0.05_fid5.20/130/img00183...  \n",
              "1  tt-cc/cin_k600_p1.0_a0.05_fid5.20/174/img00421...  \n",
              "2        tt-ffhq/ffhq_k300_p1.0_fid9.6/img036265.jpg  \n",
              "3  tt-cc/cin_k600_p1.0_a0.05_fid5.20/126/img00158...  \n",
              "4        tt-ffhq/ffhq_k300_p1.0_fid9.6/img029006.jpg  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = os.path.join(Path(os.getcwd()).parent, \"datasets\", \"testList.csv\")\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "print(df[\"real\"])\n",
        "print(df.size)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
      "metadata": {
        "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_image_embeddings(img, model):\n",
        "    if mode == \"rgb\":\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "    if mode == \"grey_scale\":\n",
        "        img = np.expand_dims(img, 0)\n",
        "        img = torch.from_numpy(img) / 255\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = img.to(device)\n",
        "        img_enc = model(img.unsqueeze(0))\n",
        "        img_enc = img_enc.detach().cpu().numpy()\n",
        "        img_enc = np.array(img_enc)\n",
        "\n",
        "    return img_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
      "metadata": {
        "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def search_in_database(img_enc, database):\n",
        "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
        "    anc_img_names = database[\"Anchor\"]\n",
        "\n",
        "    distance = []\n",
        "    for i in range(anc_enc_arr.shape[0]):\n",
        "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
        "        distance = np.append(distance, dist)\n",
        "\n",
        "    closest_idx = np.argsort(distance)\n",
        "\n",
        "    return database[\"Anchor\"][closest_idx[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
      "metadata": {
        "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
        "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1354, 2)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DataTestReal = 'C:/Users/polsi/Desktop/Lavori/DeepFake/Datasets/Artifact/cycle_gan/st/test/'\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "real_dataset_dir = os.path.join(path, \"artifact\", \"coco\")\n",
        "fake_dataset_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "temp_df = df\n",
        "temp_df.head()\n",
        "temp_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
      "metadata": {
        "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on fake images...: 1354it [05:19,  4.24it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i fake\n",
        "current_test = \"fake\"\n",
        "database = df_enc\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for index, row in tqdm(temp_df.iterrows(), desc=\"testing on fake images...\"):\n",
        "    path = os.path.join(fake_dataset_dir, row[current_test])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = get_image_embeddings(img, model)\n",
        "\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "\n",
        "    if mode == \"rgb\":\n",
        "        if str(closest_label).startswith(\"coco\"):\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n",
        "\n",
        "    if mode == \"grey_scale\": \n",
        "        if \"real\" in closest_label:\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
      "metadata": {
        "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1354\n",
            "['fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
      "metadata": {
        "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on real images...: 1354it [05:19,  4.24it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i real\n",
        "current_test = \"real\"\n",
        "database = df_enc\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for index, row in tqdm(temp_df.iterrows(), desc=\"testing on real images...\"):\n",
        "    path = os.path.join(real_dataset_dir, row[current_test])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = get_image_embeddings(img, model)\n",
        "\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "        if str(closest_label).startswith(\"coco\"):\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n",
        "\n",
        "    if mode == \"grey_scale\":\n",
        "        if \"real\" in closest_label:\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "4c465bfd-18ad-4750-b689-739b712185ab",
      "metadata": {
        "id": "4c465bfd-18ad-4750-b689-739b712185ab",
        "outputId": "e974c712-91fb-4fae-c589-85e08a50fb77",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2708\n",
            "['fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "85706e81-3068-4150-9773-320a8aa98c69",
      "metadata": {
        "id": "85706e81-3068-4150-9773-320a8aa98c69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1354,)\n",
            "(1354,)\n",
            "(2708,)\n",
            "[[ 219 1135]\n",
            " [ 185 1169]]\n"
          ]
        }
      ],
      "source": [
        "# creo i vettori di ground truth\n",
        "int(len(df) / 100 * 20)\n",
        "\n",
        "y_true = np.array([\"fake\"] * len(valid_df))\n",
        "print(y_true.shape)\n",
        "\n",
        "temp = np.array([\"real\"] * len(valid_df))\n",
        "print(temp.shape)\n",
        "\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "print(y_true.shape)\n",
        "\n",
        "# calcolo la matrice di confusione (quella di scikit-learn dispone i risultati come nella cella di sotto)\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
      "metadata": {
        "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Accuracy': 51.25999999999999, 'Precision': 50.739999999999995, 'Recall': 86.33999999999999, 'Specificity': 16.1743, 'F1 Score': 63.9173}\n"
          ]
        }
      ],
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# metriche\n",
        "accuracy = round((tp + tn) / (tp + tn + fp + fn), 4) * 100\n",
        "precision = round((tp) / (tp + fp), 4) * 100\n",
        "recall = round((tp) / (tp + fn), 4) * 100\n",
        "specificity = round((tn) / (tn + fp) * 100, 4)\n",
        "f1_score = round((2 * precision * recall) / (precision + recall), 4)\n",
        "\n",
        "print({\"Accuracy\":accuracy, \"Precision\":precision, \"Recall\":recall, \"Specificity\":specificity, \"F1 Score\":f1_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "eb6aac2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si salvano i risultati in un file .csv\n",
        "df_results = pd.DataFrame(columns=[\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1 Score\"])\n",
        "df_results.loc[0] = [accuracy, precision, recall, specificity, f1_score]\n",
        "\n",
        "# si differenziano i risultati in base al tipo di immagini e dataset usati\n",
        "dataset = fake_data_dir.split(\"\\\\\")[-1]\n",
        "path = os.path.join(\"..\", \"results\", \"rgb_mining\", \"siamese_\" + mode + \"_\" + \"pretrained_semi_hard_online_hard_\" + dataset + \"_results.csv\")\n",
        "\n",
        "df_results.to_csv(path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fvab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
