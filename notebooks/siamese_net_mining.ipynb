{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 139,
      "id": "7046cde1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# si aggiunge al path la cartella utils per avere visibilità del module\n",
        "module_path = Path(os.getcwd()).parent.parent\n",
        "module_path = os.path.join(module_path, \"project-detective\")\n",
        "\n",
        "sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import utils.mining as mining\n",
        "import utils.build_dataset as build\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
      "metadata": {
        "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "# serve per ricaricare automaticamente il codice modificato\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# configurazione\n",
        "BATCH_SIZE=32\n",
        "\n",
        "LR=0.001\n",
        "\n",
        "EPOCHS=30\n",
        "\n",
        "DEVICE=\"cuda\"\n",
        "\n",
        "# per far funzionare il modello su immagini rgb o in scala di grigi (per usare fourier)\n",
        "mode=\"rgb\"\n",
        "\n",
        "# semi-hard mining con modello pre-allenato\n",
        "semi_hard=\"pretrained\"\n",
        "\n",
        "# margin per il semi-hard\n",
        "margin=0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "id": "1bd2e0e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# directory da dove vengono prelevate le immagini\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
      "metadata": {
        "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# carica le immagini nel dataset\n",
        "class APN_Dataset(Dataset):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "      # le immagini Anchor sono memorizzate in due dataset diversi\n",
        "      if str(row.Anchor).startswith(\"coco\"):\n",
        "        A_img = io.imread(os.path.join(real_data_dir, row.Anchor))\n",
        "        P_img = io.imread(os.path.join(real_data_dir, row.Positive))\n",
        "        N_img = io.imread(os.path.join(fake_data_dir, row.Negative))\n",
        "\n",
        "      else:\n",
        "        A_img = io.imread(os.path.join(fake_data_dir, row.Anchor))\n",
        "        P_img = io.imread(os.path.join(fake_data_dir, row.Positive))\n",
        "        N_img = io.imread(os.path.join(real_data_dir, row.Negative))\n",
        "\n",
        "      # normalizzazione per immagini in rgb \n",
        "      A_img = torch.from_numpy(A_img).permute(2, 0, 1) / 255.0\n",
        "      P_img = torch.from_numpy(P_img).permute(2, 0, 1) / 255.0\n",
        "      N_img = torch.from_numpy(N_img).permute(2, 0, 1) / 255.0\n",
        "\n",
        "    if mode == \"grey_scale\":\n",
        "      A_img = np.expand_dims(A_img, 0)\n",
        "      P_img = np.expand_dims(P_img, 0)\n",
        "      N_img = np.expand_dims(N_img, 0)\n",
        "      \n",
        "      A_img = torch.from_numpy(A_img) / 255.0\n",
        "      P_img = torch.from_numpy(P_img) / 255.0\n",
        "      N_img = torch.from_numpy(N_img) / 255.0\n",
        "\n",
        "    # A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
        "    # P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
        "    # N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
        "\n",
        "    return A_img, P_img, N_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
      "metadata": {
        "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione per caricare il modello di rete neurale direttamente dalle repository online\n",
        "class APN_Model(nn.Module):\n",
        "\n",
        "  # size del vettore di embedding\n",
        "  def __init__(self, emb_size = 512):\n",
        "    super(APN_Model, self).__init__()\n",
        "\n",
        "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
        "    if semi_hard == \"not-pretrained\":\n",
        "      self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=False)\n",
        "    else:\n",
        "      self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=True)\n",
        "    \n",
        "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "  def forward(self, images):\n",
        "    embeddings = self.efficientnet(images)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "id": "3c37a66e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# funzione per creare embeddings che sarranno sottoposti a semi-hard mining\n",
        "def create_embeddings(model, dataloader, device): \n",
        "    # off dropout\n",
        "    model.eval()\n",
        "\n",
        "    list_df = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for A, P, N in tqdm(dataloader, desc=\"creating embeddings...\"):\n",
        "            A, P, N = A.to(device), P.to(device), N.to(device)\n",
        "\n",
        "            temp_df_embs = pd.DataFrame(columns=[\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"])\n",
        "\n",
        "            A_embs = model(A)\n",
        "            P_embs = model(P)\n",
        "            N_embs = model(N)\n",
        "            \n",
        "            # la batch size può variare \n",
        "            batch_size = len(A_embs)\n",
        "            \n",
        "            # ad ogni batch corrisponde un dataframe\n",
        "            for i in range(batch_size): \n",
        "                # si serializzano gli array np in stringhe in modo da memorizzarli nelle celle del datagrame\n",
        "                A, P, N = A_embs[i].cpu().numpy(), P_embs[i].cpu().numpy(), N_embs[i].cpu().numpy()\n",
        "                A, P, N = np.array2string(A, separator=','), np.array2string(P, separator=','), np.array2string(N, separator=',')\n",
        "                \n",
        "                temp_df_embs.loc[i] = [\n",
        "                    A, \n",
        "                    P, \n",
        "                    N\n",
        "                ]\n",
        "            \n",
        "            list_df.append(temp_df_embs)\n",
        "\n",
        "    # concatenazione di tutti i dataframe\n",
        "    df_embs = pd.concat(list_df)\n",
        "\n",
        "    return df_embs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "id": "4653903a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APN_Model(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model = APN_Model()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"grey_scale\":\n",
        "    emb_model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "if semi_hard == \"not-pretrained\":\n",
        "    # caricamento modello precedentemente allenato su immagini del dataset artifact\n",
        "    emb_model.load_state_dict(torch.load(\"emb_model.pt\"))\n",
        "\n",
        "emb_model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "id": "4c584653",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building (positive anchor) dataframe...: 100%|██████████| 25000/25000 [00:29<00:00, 853.30it/s] \n",
            "building (negative anchor) dataframe...: 100%|██████████| 25000/25000 [00:28<00:00, 882.01it/s] \n"
          ]
        }
      ],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_data_path = os.path.join(path, \"artifact\", \"taming_transformer\", \"metadata.csv\")\n",
        "real_data_path = os.path.join(path, \"artifact\", \"coco\", \"metadata.csv\")\n",
        "\n",
        "# creo il dataset di test\n",
        "df_out_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
        "build.train(fake_data_path, real_data_path, df_out_path, 50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "id": "012654d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_out = pd.read_csv(df_out_path)\n",
        "\n",
        "# si carica il dataset per creare gli embeddings\n",
        "apn_dataset = APN_Dataset(df_out)\n",
        "dataloader = DataLoader(apn_dataset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "id": "22b9da75",
      "metadata": {},
      "outputs": [],
      "source": [
        "emb_csv_path = os.path.join(\"..\", \"datasets\", \"embeddings.csv\")\n",
        "\n",
        "# si controlla che siano stati già creati gli embeddings\n",
        "if not Path(emb_csv_path).is_file():\n",
        "    df_emb = create_embeddings(emb_model, dataloader, DEVICE)\n",
        "    df_emb.to_csv(emb_csv_path, index=False)\n",
        "\n",
        "else:\n",
        "    df_emb = pd.read_csv(emb_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "id": "41b31e13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si concatenano i dataframe delle immagini e degli embeddings sulle colonne per poter filtrare le righe in logica di semi-hard mining\n",
        "df = pd.concat([df_out, df_emb], axis=1)\n",
        "\n",
        "# offline semi-hard mining dei triplets\n",
        "df = mining.offline_semi_hard_mining(df, margin)\n",
        "df = df.drop([\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
      "metadata": {
        "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di train\n",
        "def train_fn(model, dataloader, optimizer, criterion):\n",
        "  model.train()\n",
        "  # on dropout \n",
        "  total_loss = 0.0\n",
        "\n",
        "  for A, P, N in tqdm(dataloader, desc=\"model training...\"):\n",
        "    A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
        "    A_embs = model(A)\n",
        "    P_embs = model(P)\n",
        "    N_embs = model(N)\n",
        "\n",
        "    # online hard mining dei triplets\n",
        "    A_embs, P_embs, N_embs = mining.online_hard_mining(A_embs, P_embs, N_embs, BATCH_SIZE, DEVICE)\n",
        "\n",
        "    # criterion è la funzione di loss\n",
        "    loss = criterion(A_embs, P_embs, N_embs)\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "id": "19ec6d56-9168-4980-9164-62660537f1ff",
      "metadata": {
        "id": "19ec6d56-9168-4980-9164-62660537f1ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di evaluation\n",
        "def eval_fn(model, dataloader, criterion):\n",
        "  model.eval() \n",
        "  # off dropout\n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for A, P, N in tqdm(dataloader, desc=\"model validating...\"):\n",
        "      A, P, N = A.to(DEVICE), P.to(DEVICE), N.to(DEVICE)\n",
        "\n",
        "      A_embs = model(A)\n",
        "      P_embs = model(P)\n",
        "      N_embs = model(N)\n",
        "\n",
        "      loss = criterion(A_embs, P_embs, N_embs)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "id": "c2080916",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "APN_Model(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = APN_Model()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"grey_scale\":\n",
        "    model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "id": "311bed90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# split del nuovo dataframe\n",
        "train_df, valid_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "\n",
        "trainset = APN_Dataset(train_df)\n",
        "validset = APN_Dataset(valid_df)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
      "metadata": {
        "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# triplet loss e adam\n",
        "criterion = nn.TripletMarginLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
      "metadata": {
        "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [01:25<00:00,  2.09s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 1, train_loss: 0.006134969325153374, valid_loss: 0.932264416683011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:23<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 2, train_loss: 0.006134969325153374, valid_loss: 0.936309121003965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:22<00:00,  1.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 3, train_loss: 0.006134969325153374, valid_loss: 0.9388020314821383\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:22<00:00,  1.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 4, train_loss: 0.006134969325153374, valid_loss: 0.9415515733928215\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 5, train_loss: 0.006134969325153374, valid_loss: 0.9433592834123751\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 6, train_loss: 0.006134969325153374, valid_loss: 0.9391942736579151\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 7, train_loss: 0.006134969325153374, valid_loss: 0.9397630836905503\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 8, train_loss: 0.006134969325153374, valid_loss: 0.9398769910742597\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 9, train_loss: 0.006134969325153374, valid_loss: 0.9438222792090439\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 10, train_loss: 0.006134969325153374, valid_loss: 0.9417971314453497\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 11, train_loss: 0.006134969325153374, valid_loss: 0.942487556759904\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 12, train_loss: 0.006134969325153374, valid_loss: 0.9476875299360694\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 13, train_loss: 0.006134969325153374, valid_loss: 0.9523108165438582\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 14, train_loss: 0.006134969325153374, valid_loss: 0.953949915199745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 15, train_loss: 0.006134969325153374, valid_loss: 0.9545985780111174\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 16, train_loss: 0.006134969325153374, valid_loss: 0.9552416554311427\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 17, train_loss: 0.006134969325153374, valid_loss: 0.951366811263852\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 18, train_loss: 0.006134969325153374, valid_loss: 0.9504784418315422\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 19, train_loss: 0.006134969325153374, valid_loss: 0.9520932290612197\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 20, train_loss: 0.006134969325153374, valid_loss: 0.9515522863806748\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 21, train_loss: 0.006134969325153374, valid_loss: 0.9524332822822943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 22, train_loss: 0.006134969325153374, valid_loss: 0.9490751914861726\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 23, train_loss: 0.006134969325153374, valid_loss: 0.9481380305639128\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 24, train_loss: 0.006134969325153374, valid_loss: 0.9510960811521949\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 25, train_loss: 0.006134969325153374, valid_loss: 0.9489048661255255\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 26, train_loss: 0.006134969325153374, valid_loss: 0.9515116185676761\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 27, train_loss: 0.006134969325153374, valid_loss: 0.9530742182964231\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:02<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 28, train_loss: 0.006134969325153374, valid_loss: 0.9522335572940547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.88it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 29, train_loss: 0.006134969325153374, valid_loss: 0.9530967473983765\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:21<00:00,  1.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 30, train_loss: 0.006134969325153374, valid_loss: 0.9538444716755937\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "best_valid_loss = np.Inf\n",
        "\n",
        "training_epoch_loss = []\n",
        "validation_epoch_loss = []\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  train_loss = train_fn(model, trainloader, optimizer, criterion)\n",
        "  valid_loss = eval_fn(model, validloader, criterion)\n",
        "\n",
        "  training_epoch_loss.append(train_loss)\n",
        "  validation_epoch_loss.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    best_valid_loss = valid_loss\n",
        "    print(\"successful weights saving...\")\n",
        "\n",
        "  print(f\"epochs: {i+1}, train_loss: {train_loss}, valid_loss: {valid_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "id": "9ca40d35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 164,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot della training e validation loss\n",
        "plt.plot(training_epoch_loss, label=\"train_loss\")\n",
        "plt.plot(validation_epoch_loss, label=\"val_loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "id": "97cb5008",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building (real column) test dataframe...: 100%|██████████| 1298/1298 [00:01<00:00, 1118.69it/s]\n",
            "building (fake column) test dataframe...: 100%|██████████| 1298/1298 [00:00<00:00, 1556.94it/s]\n"
          ]
        }
      ],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_data_path = os.path.join(path, \"artifact\", \"taming_transformer\", \"metadata.csv\")\n",
        "real_data_path = os.path.join(path, \"artifact\", \"coco\", \"metadata.csv\")\n",
        "\n",
        "# creo il dataset di test\n",
        "testList_df_path = os.path.join(\"..\", \"datasets\", \"testList.csv\")\n",
        "build.test(fake_data_path, real_data_path, testList_df_path, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
      "metadata": {
        "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione per generare i vettori di encoding\n",
        "def get_encoding_csv(model, anc_img_names, dirFolder):\n",
        "  anc_img_names_arr = np.array(anc_img_names)\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in tqdm(anc_img_names_arr):\n",
        "\n",
        "      if mode == \"rgb\":\n",
        "        # serve per trovare correttamente l'immagine\n",
        "        if str(i).startswith(\"coco\"):\n",
        "          dirFolder = real_data_dir\n",
        "          A = io.imread(os.path.join(dirFolder,i))\n",
        "        else: \n",
        "          dirFolder = fake_data_dir\n",
        "          A = io.imread(os.path.join(dirFolder,i))\n",
        "\n",
        "        A = torch.from_numpy(A).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "      if mode == \"grey_scale\":\n",
        "        A = io.imread(os.path.join(dirFolder,i))\n",
        "\n",
        "        A = np.expand_dims(A, 0)\n",
        "        A = torch.from_numpy(A.astype(np.int32)) / 255.0\n",
        "        \n",
        "      A = A.to(DEVICE)\n",
        "      A_enc = model(A.unsqueeze(0))\n",
        "      encodings.append(A_enc.squeeze().cpu().detach().numpy())\n",
        "\n",
        "    encodings = np.array(encodings)\n",
        "    encodings = pd.DataFrame(encodings)\n",
        "    df_enc = pd.concat([anc_img_names, encodings], axis = 1)\n",
        "\n",
        "    return df_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
      "metadata": {
        "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
        "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 6491/6491 [03:21<00:00, 32.21it/s]\n"
          ]
        }
      ],
      "source": [
        "# per ricaricare il modello una volta allenato\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "# si creano gli embeddings che vengono memorizzati per non rifarlo ad ogni allenamento\n",
        "df_enc = get_encoding_csv(model, df[\"Anchor\"], real_data_dir)\n",
        "df_enc.to_csv(\"database.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
      "metadata": {
        "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
        "outputId": "171dab62-2058-470c-9abf-5ea9495da9b0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raffa\\AppData\\Local\\Temp\\ipykernel_14092\\2812054046.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_enc = pd.read_csv('database.csv')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anchor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/train2017/img058918.jpg</td>\n",
              "      <td>0.157157</td>\n",
              "      <td>0.203672</td>\n",
              "      <td>0.052145</td>\n",
              "      <td>0.217306</td>\n",
              "      <td>-0.139155</td>\n",
              "      <td>0.064487</td>\n",
              "      <td>0.173859</td>\n",
              "      <td>-0.057610</td>\n",
              "      <td>0.116458</td>\n",
              "      <td>...</td>\n",
              "      <td>0.304362</td>\n",
              "      <td>-0.401400</td>\n",
              "      <td>-0.215983</td>\n",
              "      <td>-0.295627</td>\n",
              "      <td>0.051768</td>\n",
              "      <td>0.141307</td>\n",
              "      <td>-0.022465</td>\n",
              "      <td>0.146743</td>\n",
              "      <td>-0.076202</td>\n",
              "      <td>0.013302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/test2017/img007018.jpg</td>\n",
              "      <td>-0.145857</td>\n",
              "      <td>-0.042815</td>\n",
              "      <td>-0.072213</td>\n",
              "      <td>0.110568</td>\n",
              "      <td>-0.096990</td>\n",
              "      <td>0.069175</td>\n",
              "      <td>0.063797</td>\n",
              "      <td>0.147337</td>\n",
              "      <td>0.068751</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.027794</td>\n",
              "      <td>0.044146</td>\n",
              "      <td>-0.151137</td>\n",
              "      <td>0.087140</td>\n",
              "      <td>0.025619</td>\n",
              "      <td>-0.053848</td>\n",
              "      <td>0.108014</td>\n",
              "      <td>-0.372928</td>\n",
              "      <td>0.102826</td>\n",
              "      <td>0.182472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/test2017/img028366.jpg</td>\n",
              "      <td>0.093521</td>\n",
              "      <td>0.113159</td>\n",
              "      <td>0.123613</td>\n",
              "      <td>-0.024587</td>\n",
              "      <td>0.034392</td>\n",
              "      <td>0.356136</td>\n",
              "      <td>0.170422</td>\n",
              "      <td>-0.380300</td>\n",
              "      <td>-0.108335</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.163030</td>\n",
              "      <td>0.019645</td>\n",
              "      <td>-0.021602</td>\n",
              "      <td>0.205957</td>\n",
              "      <td>-0.120609</td>\n",
              "      <td>-0.231020</td>\n",
              "      <td>-0.408108</td>\n",
              "      <td>0.110170</td>\n",
              "      <td>0.002949</td>\n",
              "      <td>0.272743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/test2017/img038402.jpg</td>\n",
              "      <td>-0.095759</td>\n",
              "      <td>0.070045</td>\n",
              "      <td>0.091000</td>\n",
              "      <td>-0.168104</td>\n",
              "      <td>0.310452</td>\n",
              "      <td>0.157226</td>\n",
              "      <td>0.281537</td>\n",
              "      <td>0.099278</td>\n",
              "      <td>-0.206242</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.007649</td>\n",
              "      <td>-0.099409</td>\n",
              "      <td>0.059086</td>\n",
              "      <td>0.085178</td>\n",
              "      <td>0.089127</td>\n",
              "      <td>-0.057004</td>\n",
              "      <td>-0.179769</td>\n",
              "      <td>0.018153</td>\n",
              "      <td>0.477837</td>\n",
              "      <td>0.131901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/train2017/img055818.jpg</td>\n",
              "      <td>-0.034106</td>\n",
              "      <td>0.000396</td>\n",
              "      <td>0.203221</td>\n",
              "      <td>-0.197754</td>\n",
              "      <td>0.620051</td>\n",
              "      <td>0.288229</td>\n",
              "      <td>0.173201</td>\n",
              "      <td>-0.119365</td>\n",
              "      <td>-0.234051</td>\n",
              "      <td>...</td>\n",
              "      <td>0.116703</td>\n",
              "      <td>-0.237340</td>\n",
              "      <td>0.176252</td>\n",
              "      <td>0.004607</td>\n",
              "      <td>-0.338591</td>\n",
              "      <td>-0.063987</td>\n",
              "      <td>-0.033237</td>\n",
              "      <td>0.095705</td>\n",
              "      <td>-0.199152</td>\n",
              "      <td>0.103919</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 513 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Anchor         0         1         2  \\\n",
              "0  coco/coco2017/train2017/img058918.jpg  0.157157  0.203672  0.052145   \n",
              "1   coco/coco2017/test2017/img007018.jpg -0.145857 -0.042815 -0.072213   \n",
              "2   coco/coco2017/test2017/img028366.jpg  0.093521  0.113159  0.123613   \n",
              "3   coco/coco2017/test2017/img038402.jpg -0.095759  0.070045  0.091000   \n",
              "4  coco/coco2017/train2017/img055818.jpg -0.034106  0.000396  0.203221   \n",
              "\n",
              "          3         4         5         6         7         8  ...       502  \\\n",
              "0  0.217306 -0.139155  0.064487  0.173859 -0.057610  0.116458  ...  0.304362   \n",
              "1  0.110568 -0.096990  0.069175  0.063797  0.147337  0.068751  ... -0.027794   \n",
              "2 -0.024587  0.034392  0.356136  0.170422 -0.380300 -0.108335  ... -0.163030   \n",
              "3 -0.168104  0.310452  0.157226  0.281537  0.099278 -0.206242  ... -0.007649   \n",
              "4 -0.197754  0.620051  0.288229  0.173201 -0.119365 -0.234051  ...  0.116703   \n",
              "\n",
              "        503       504       505       506       507       508       509  \\\n",
              "0 -0.401400 -0.215983 -0.295627  0.051768  0.141307 -0.022465  0.146743   \n",
              "1  0.044146 -0.151137  0.087140  0.025619 -0.053848  0.108014 -0.372928   \n",
              "2  0.019645 -0.021602  0.205957 -0.120609 -0.231020 -0.408108  0.110170   \n",
              "3 -0.099409  0.059086  0.085178  0.089127 -0.057004 -0.179769  0.018153   \n",
              "4 -0.237340  0.176252  0.004607 -0.338591 -0.063987 -0.033237  0.095705   \n",
              "\n",
              "        510       511  \n",
              "0 -0.076202  0.013302  \n",
              "1  0.102826  0.182472  \n",
              "2  0.002949  0.272743  \n",
              "3  0.477837  0.131901  \n",
              "4 -0.199152  0.103919  \n",
              "\n",
              "[5 rows x 513 columns]"
            ]
          },
          "execution_count": 168,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_enc = pd.read_csv('database.csv')\n",
        "df_enc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
      "metadata": {
        "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# approssimazione della distanza, senza la radice quadrata, per fare i primi allenamenti velocemente\n",
        "def euclidean_dist(img_enc, anc_enc_arr):\n",
        "    # dist = np.sqrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
        "    dist = np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T)\n",
        "    # dist = np.sqrt(dist)\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
      "metadata": {
        "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
        "outputId": "7ff19abf-6ff7-4f31-bd3e-a07d07ca90dd",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        coco/coco2017/test2017/img037005.jpg\n",
            "1       coco/coco2017/train2017/img149134.jpg\n",
            "2        coco/coco2017/test2017/img033973.jpg\n",
            "3         coco/coco2017/val2017/img163195.jpg\n",
            "4        coco/coco2017/test2017/img022399.jpg\n",
            "                        ...                  \n",
            "1293     coco/coco2017/test2017/img002844.jpg\n",
            "1294     coco/coco2017/test2017/img001583.jpg\n",
            "1295     coco/coco2017/test2017/img036315.jpg\n",
            "1296     coco/coco2017/test2017/img012010.jpg\n",
            "1297    coco/coco2017/train2017/img110290.jpg\n",
            "Name: real, Length: 1298, dtype: object\n",
            "2596\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real</th>\n",
              "      <th>fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/test2017/img037005.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/806/img03931...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img149134.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img048247.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/test2017/img033973.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img038256.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/val2017/img163195.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img027204.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/test2017/img022399.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/955/img04756...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    real  \\\n",
              "0   coco/coco2017/test2017/img037005.jpg   \n",
              "1  coco/coco2017/train2017/img149134.jpg   \n",
              "2   coco/coco2017/test2017/img033973.jpg   \n",
              "3    coco/coco2017/val2017/img163195.jpg   \n",
              "4   coco/coco2017/test2017/img022399.jpg   \n",
              "\n",
              "                                                fake  \n",
              "0  tt-cc/cin_k600_p1.0_a0.05_fid5.20/806/img03931...  \n",
              "1        tt-ffhq/ffhq_k300_p1.0_fid9.6/img048247.jpg  \n",
              "2        tt-ffhq/ffhq_k300_p1.0_fid9.6/img038256.jpg  \n",
              "3        tt-ffhq/ffhq_k300_p1.0_fid9.6/img027204.jpg  \n",
              "4  tt-cc/cin_k600_p1.0_a0.05_fid5.20/955/img04756...  "
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = os.path.join(Path(os.getcwd()).parent, \"datasets\", \"testList.csv\")\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "print(df[\"real\"])\n",
        "print(df.size)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
      "metadata": {
        "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def getImageEmbeddings(img, model):\n",
        "    if mode == \"rgb\":\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "    if mode == \"grey_scale\":\n",
        "        img = np.expand_dims(img, 0)\n",
        "        img = torch.from_numpy(img) / 255\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = img.to(DEVICE)\n",
        "        img_enc = model(img.unsqueeze(0))\n",
        "        img_enc = img_enc.detach().cpu().numpy()\n",
        "        img_enc = np.array(img_enc)\n",
        "\n",
        "    return img_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
      "metadata": {
        "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def searchInDatabase(img_enc, database):\n",
        "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
        "    anc_img_names = database[\"Anchor\"]\n",
        "\n",
        "    distance = []\n",
        "    for i in range(anc_enc_arr.shape[0]):\n",
        "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
        "        distance = np.append(distance, dist)\n",
        "\n",
        "    closest_idx = np.argsort(distance)\n",
        "\n",
        "    return database[\"Anchor\"][closest_idx[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
      "metadata": {
        "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
        "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1298, 2)"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DataTestReal = 'C:/Users/polsi/Desktop/Lavori/DeepFake/Datasets/Artifact/cycle_gan/st/test/'\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "tempDf = df\n",
        "tempDf.head()\n",
        "tempDf.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
      "metadata": {
        "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on fake images...: 1298it [05:53,  3.67it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i fake\n",
        "currentTest = \"fake\"\n",
        "database = df_enc\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for index, row in tqdm(tempDf.iterrows(), desc=\"testing on fake images...\"):\n",
        "    path = os.path.join(fake_data_dir, row[currentTest])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = getImageEmbeddings(img, model)\n",
        "\n",
        "    closestLabel = searchInDatabase(img_enc, database)\n",
        "\n",
        "    if mode == \"rgb\":\n",
        "        if str(closestLabel).startswith(\"coco\"):\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n",
        "\n",
        "    if mode == \"grey_scale\": \n",
        "        if \"real\" in closestLabel:\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
      "metadata": {
        "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1298\n",
            "['fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
      "metadata": {
        "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on real images...: 1298it [05:45,  3.76it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i real\n",
        "currentTest = \"real\"\n",
        "database = df_enc\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for index, row in tqdm(tempDf.iterrows(), desc=\"testing on real images...\"):\n",
        "    path = os.path.join(real_data_dir, row[currentTest])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = getImageEmbeddings(img, model)\n",
        "\n",
        "    closestLabel = searchInDatabase(img_enc, database)\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "        if str(closestLabel).startswith(\"coco\"):\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n",
        "\n",
        "    if mode == \"grey_scale\":\n",
        "        if \"real\" in closestLabel:\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "id": "4c465bfd-18ad-4750-b689-739b712185ab",
      "metadata": {
        "id": "4c465bfd-18ad-4750-b689-739b712185ab",
        "outputId": "e974c712-91fb-4fae-c589-85e08a50fb77",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2596\n",
            "['fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "id": "85706e81-3068-4150-9773-320a8aa98c69",
      "metadata": {
        "id": "85706e81-3068-4150-9773-320a8aa98c69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1298,)\n",
            "(1298,)\n",
            "(2596,)\n",
            "[[ 166 1132]\n",
            " [ 181 1117]]\n"
          ]
        }
      ],
      "source": [
        "# creo i vettori di ground truth\n",
        "int(len(df) / 100 * 20)\n",
        "\n",
        "y_true = np.array([\"fake\"] * (len(valid_df) - 1))\n",
        "print(y_true.shape)\n",
        "\n",
        "temp = np.array([\"real\"] * (len(valid_df) - 1))\n",
        "print(temp.shape)\n",
        "\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "print(y_true.shape)\n",
        "\n",
        "# calcolo la matrice di confusione (quella di scikit-learn dispone i risultati come nella cella di sotto)\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
      "metadata": {
        "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Accuracy': 49.419999999999995, 'Precision': 49.669999999999995, 'Recall': 86.06, 'Specificity': 12.7889, 'F1 Score': 62.9868}\n"
          ]
        }
      ],
      "source": [
        "TN, FP, FN, TP = cm.ravel()\n",
        "\n",
        "# metriche\n",
        "accuracy = round((TP + TN) / (TP + TN + FP + FN), 4) * 100\n",
        "precision = round((TP) / (TP + FP), 4) * 100\n",
        "recall = round((TP) / (TP + FN), 4) * 100\n",
        "specificity = round((TN) / (TN + FP) * 100, 4)\n",
        "f1_score = round((2 * precision * recall) / (precision + recall), 4)\n",
        "\n",
        "print({\"Accuracy\":accuracy, \"Precision\":precision, \"Recall\":recall, \"Specificity\":specificity, \"F1 Score\":f1_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "id": "eb6aac2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si salvano i risultati in un file .csv\n",
        "df_results = pd.DataFrame(columns=[\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1 Score\"])\n",
        "df_results.loc[0] = [accuracy, precision, recall, specificity, f1_score]\n",
        "\n",
        "# si differenziano i risultati in base al tipo di immagini e dataset usati\n",
        "dataset = fake_data_dir.split(\"\\\\\")[-1]\n",
        "path = os.path.join(\"..\", \"results\", \"rgb_semi_hard\", \"siamese_\" + mode + \"_\" + \"semi_hard_\" + semi_hard + \"_\" + dataset + \"_results.csv\")\n",
        "\n",
        "df_results.to_csv(path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fvab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
