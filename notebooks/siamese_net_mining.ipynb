{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7046cde1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# si aggiunge al path la cartella utils per avere visibilità del module\n",
        "module_path = Path(os.getcwd()).parent.parent\n",
        "module_path = os.path.join(module_path, \"project-detective\")\n",
        "\n",
        "sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import utils.mining as mining\n",
        "import utils.datasets as build\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
      "metadata": {
        "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# serve per ricaricare automaticamente il codice modificato\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# configurazione\n",
        "batch_size=32\n",
        "lr=0.001\n",
        "epochs=30\n",
        "device=\"cuda\"\n",
        "\n",
        "# per far funzionare il modello su immagini rgb o in scala di grigi (per usare fourier)\n",
        "mode=\"rgb\"\n",
        "\n",
        "# semi-hard mining con modello pre-allenato\n",
        "margin=0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1bd2e0e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# directory da dove vengono prelevate le immagini\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
      "metadata": {
        "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# carica le immagini nel dataset\n",
        "class ApnDataset(Dataset):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "      # le immagini Anchor sono memorizzate in due dataset diversi\n",
        "      if str(row.Anchor).startswith(\"coco\"):\n",
        "        a_img = io.imread(os.path.join(real_data_dir, row.Anchor))\n",
        "        p_img = io.imread(os.path.join(real_data_dir, row.Positive))\n",
        "        n_img = io.imread(os.path.join(fake_data_dir, row.Negative))\n",
        "\n",
        "      else:\n",
        "        a_img = io.imread(os.path.join(fake_data_dir, row.Anchor))\n",
        "        p_img = io.imread(os.path.join(fake_data_dir, row.Positive))\n",
        "        n_img = io.imread(os.path.join(real_data_dir, row.Negative))\n",
        "\n",
        "      # normalizzazione per immagini in rgb \n",
        "      a_img = torch.from_numpy(a_img).permute(2, 0, 1) / 255.0\n",
        "      p_img = torch.from_numpy(p_img).permute(2, 0, 1) / 255.0\n",
        "      n_img = torch.from_numpy(n_img).permute(2, 0, 1) / 255.0\n",
        "\n",
        "    if mode == \"grey_scale\":\n",
        "      a_img = np.expand_dims(a_img, 0)\n",
        "      p_img = np.expand_dims(p_img, 0)\n",
        "      n_img = np.expand_dims(n_img, 0)\n",
        "      \n",
        "      a_img = torch.from_numpy(a_img) / 255.0\n",
        "      p_img = torch.from_numpy(p_img) / 255.0\n",
        "      n_img = torch.from_numpy(n_img) / 255.0\n",
        "\n",
        "    # A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
        "    # P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
        "    # N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
        "\n",
        "    return a_img, p_img, n_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
      "metadata": {
        "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# classe per caricare il modello di rete neurale direttamente dalle repository online\n",
        "class ApnModel(nn.Module):\n",
        "\n",
        "  # size del vettore di embedding\n",
        "  def __init__(self, emb_size=512):\n",
        "    super(ApnModel, self).__init__()\n",
        "\n",
        "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
        "    self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=False)\n",
        "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "  def forward(self, images):\n",
        "    embeddings = self.efficientnet(images)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "53d21354",
      "metadata": {},
      "outputs": [],
      "source": [
        "# classe il modello che genera gli embedding per applicare il semi-hard mining\n",
        "class EmbModel(nn.Module):\n",
        "\n",
        "    # size del vettore di embedding\n",
        "    def __init__(self, emb_size = 512):\n",
        "        super(EmbModel, self).__init__()\n",
        "\n",
        "        # gli embedding vengono creati con un modello preallenato (risultato più efficace in test precedenti)\n",
        "        self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=True)\n",
        "        self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "    def forward(self, images):\n",
        "        embeddings = self.efficientnet(images)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3c37a66e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# funzione per creare embeddings che sarranno sottoposti a semi-hard mining\n",
        "def create_embeddings(model, dataloader, device): \n",
        "    # off dropout\n",
        "    model.eval()\n",
        "\n",
        "    list_df = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a, p, n in tqdm(dataloader, desc=\"creating embeddings...\"):\n",
        "            a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "\n",
        "            temp_df_embs = pd.DataFrame(columns=[\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"])\n",
        "\n",
        "            a_embs = model(a)\n",
        "            p_embs = model(p)\n",
        "            n_embs = model(n)\n",
        "            \n",
        "            # la batch size può variare \n",
        "            batch_size = len(a_embs)\n",
        "            \n",
        "            # ad ogni batch corrisponde un dataframe\n",
        "            for i in range(batch_size): \n",
        "                # si serializzano gli array np in stringhe in modo da memorizzarli nelle celle del datagrame\n",
        "                a, p, n = a_embs[i].cpu().numpy(), p_embs[i].cpu().numpy(), n_embs[i].cpu().numpy()\n",
        "                a, p, n = np.array2string(a, separator=','), np.array2string(p, separator=','), np.array2string(n, separator=',')\n",
        "                \n",
        "                temp_df_embs.loc[i] = [\n",
        "                    a, \n",
        "                    p, \n",
        "                    n\n",
        "                ]\n",
        "            \n",
        "            list_df.append(temp_df_embs)\n",
        "\n",
        "    # concatenazione di tutti i dataframe\n",
        "    df_embs = pd.concat(list_df)\n",
        "\n",
        "    return df_embs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4653903a",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EmbModel(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_model = EmbModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"grey_scale\":\n",
        "    emb_model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "emb_model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4c584653",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building (positive anchor) dataframe...: 100%|██████████| 25000/25000 [00:28<00:00, 863.57it/s] \n",
            "building (negative anchor) dataframe...: 100%|██████████| 25000/25000 [00:26<00:00, 946.88it/s] \n"
          ]
        }
      ],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_dataset_path = os.path.join(path, \"artifact\", \"taming_transformer\", \"metadata.csv\")\n",
        "real_dataset_path = os.path.join(path, \"artifact\", \"coco\", \"metadata.csv\")\n",
        "\n",
        "# creo il dataset di triplet iniziale (i triplet sono scelti casualmente)\n",
        "df_out_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
        "build.train(fake_dataset_path, real_dataset_path, df_out_path, 50000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "012654d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "df_out = pd.read_csv(df_out_path)\n",
        "\n",
        "apn_dataset = ApnDataset(df_out)\n",
        "dataloader = DataLoader(apn_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "22b9da75",
      "metadata": {},
      "outputs": [],
      "source": [
        "emb_csv_path = os.path.join(\"..\", \"notebooks\", \"embeddings.csv\")\n",
        "\n",
        "# si controlla che siano stati già creati gli embeddings\n",
        "if not Path(emb_csv_path).is_file():\n",
        "    df_emb = create_embeddings(emb_model, dataloader, device)\n",
        "    df_emb.to_csv(emb_csv_path, index=False)\n",
        "\n",
        "df_emb = pd.read_csv(emb_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "41b31e13",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si concatenano i dataframe delle immagini e degli embeddings sulle colonne per poter filtrare le righe in logica di semi-hard mining\n",
        "df = pd.concat([df_out, df_emb], axis=1)\n",
        "\n",
        "# offline semi-hard mining dei triplets\n",
        "df = mining.offline_semi_hard_mining(df, margin)\n",
        "df = df.drop([\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
      "metadata": {
        "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di train\n",
        "def train_fn(model, dataloader, optimizer, criterion):\n",
        "  # on dropout \n",
        "  model.train()\n",
        "  \n",
        "  total_loss = 0.0\n",
        "\n",
        "  for a, p, n in tqdm(dataloader, desc=\"model training...\"):\n",
        "    a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
        "    a_embs = model(a)\n",
        "    p_embs = model(p)\n",
        "    n_embs = model(n)\n",
        "\n",
        "    # criterion è la funzione di loss\n",
        "    loss = criterion(a_embs, p_embs, n_embs)\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "19ec6d56-9168-4980-9164-62660537f1ff",
      "metadata": {
        "id": "19ec6d56-9168-4980-9164-62660537f1ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di evaluation\n",
        "def eval_fn(model, dataloader, criterion):\n",
        "  # off dropout\n",
        "  model.eval() \n",
        "  \n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for a, p, n in tqdm(dataloader, desc=\"model validating...\"):\n",
        "      a, p, n = a.to(device), p.to(device), n.to(device)\n",
        "\n",
        "      a_embs = model(a)\n",
        "      p_embs = model(p)\n",
        "      n_embs = model(n)\n",
        "\n",
        "      loss = criterion(a_embs, p_embs, n_embs)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "c2080916",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ApnModel(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ApnModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"grey_scale\":\n",
        "    model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "311bed90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# split del nuovo dataframe\n",
        "train_df, valid_df = train_test_split(df, test_size=0.20, random_state=42)\n",
        "\n",
        "trainset = ApnDataset(train_df)\n",
        "validset = ApnDataset(valid_df)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
      "metadata": {
        "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# triplet loss e adam\n",
        "criterion = nn.TripletMarginLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
      "metadata": {
        "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...:  98%|█████████▊| 40/41 [00:31<00:00,  1.36it/s]c:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "model validating...: 100%|██████████| 41/41 [00:31<00:00,  1.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 1, train_loss: 0.00960153889802336, valid_loss: 1.0000603286231435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 2, train_loss: 0.011181097089147276, valid_loss: 1.0000967732289943\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.85it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 3, train_loss: 0.009553027299284204, valid_loss: 1.0001918266459209\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 4, train_loss: 0.0077397428407259515, valid_loss: 1.0003861959387617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.90it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 5, train_loss: 0.007482740045325157, valid_loss: 1.000768946438301\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 6, train_loss: 0.0067792831023046575, valid_loss: 1.0011223990742752\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:13<00:00,  2.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 7, train_loss: 0.006379423697301947, valid_loss: 1.001490073960002\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 8, train_loss: 0.008861671927516445, valid_loss: 1.004000518380142\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 9, train_loss: 0.007952504362796714, valid_loss: 1.0084667045895646\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.87it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 10, train_loss: 0.008376403820295275, valid_loss: 1.0127589935209693\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 11, train_loss: 0.009480295737096868, valid_loss: 1.0146530459566814\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 12, train_loss: 0.007655810724738185, valid_loss: 1.0167319600175067\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 13, train_loss: 0.008298840259481792, valid_loss: 1.0526702854691483\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.63it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 14, train_loss: 0.006038898339300799, valid_loss: 1.0681826704885902\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 15, train_loss: 0.0050165335093539185, valid_loss: 1.081986104569784\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 16, train_loss: 0.006386405119866681, valid_loss: 1.152367873889644\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:13<00:00,  2.96it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 17, train_loss: 0.00719581644959245, valid_loss: 1.3051417586280079\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:13<00:00,  2.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 18, train_loss: 0.006741683175958739, valid_loss: 1.4644429480157248\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:13<00:00,  2.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 19, train_loss: 0.007989516287493559, valid_loss: 1.4015923084282293\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 20, train_loss: 0.008184612894350766, valid_loss: 1.284757105315604\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 21, train_loss: 0.00573321500438854, valid_loss: 1.4418230870874917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 22, train_loss: 0.00571149807034826, valid_loss: 1.8590231814035556\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 23, train_loss: 0.009883741659620788, valid_loss: 1.617442199369756\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:15<00:00,  2.71it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 24, train_loss: 0.00661287205350911, valid_loss: 1.4970084501475822\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.91it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 25, train_loss: 0.009529858279081942, valid_loss: 1.3154153009740317\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:13<00:00,  2.95it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 26, train_loss: 0.00784220139673151, valid_loss: 1.3664291646422408\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:01<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:13<00:00,  2.94it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 27, train_loss: 0.008230431679567676, valid_loss: 1.3903168832383506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.81it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 28, train_loss: 0.00706108216127735, valid_loss: 1.4386128041802384\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 29, train_loss: 0.005275441093678855, valid_loss: 1.371986397882787\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...:   0%|          | 0/163 [00:00<?, ?it/s]\n",
            "model validating...: 100%|██████████| 41/41 [00:14<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 30, train_loss: 0.005874795782054128, valid_loss: 1.3518698477163547\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "best_valid_loss = np.Inf\n",
        "\n",
        "training_epoch_loss = []\n",
        "validation_epoch_loss = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  train_loss = train_fn(model, trainloader, optimizer, criterion)\n",
        "  valid_loss = eval_fn(model, validloader, criterion)\n",
        "\n",
        "  training_epoch_loss.append(train_loss)\n",
        "  validation_epoch_loss.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    best_valid_loss = valid_loss\n",
        "    print(\"successful weights saving...\")\n",
        "\n",
        "  print(f\"epochs: {i+1}, train_loss: {train_loss}, valid_loss: {valid_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "9ca40d35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi4AAAGdCAYAAAA1/PiZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABNWklEQVR4nO3de1yUZf7/8dfMAIMn8IByKDzlIQ+IZkrYOVG0cjU7qPnNQ2lbW21FR/e3aafNsl3XSsvtaO6W2kFtt4NbUWoaampkmblq5BHwUIKggMzcvz9uGBgFZXBguOH9fDzux9xz39fc85lhYN5c93Xft80wDAMRERERC7AHugARERGRqlJwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREcsICnQB/uB2u9m3bx/NmjXDZrMFuhwRERGpAsMwOHLkCDExMdjtVetLqRfBZd++fcTGxga6DBEREamG3bt3c/bZZ1epbb0ILs2aNQPMFx4WFhbgakRERKQqcnNziY2N9XyPV0W9CC6lu4fCwsIUXERERCzGl2EeGpwrIiIilqHgIiIiIpah4CIiIiKWUS/GuIiISP1jGAbFxcW4XK5AlyJnwOFwEBQU5LfTlSi4iIhInVNUVERmZiZHjx4NdCniB40bNyY6OpqQkJAz3paCi4iI1Clut5uMjAwcDgcxMTGEhITo5KIWZRgGRUVFHDhwgIyMDDp37lzlE81VRsFFRETqlKKiItxuN7GxsTRu3DjQ5cgZatSoEcHBwezcuZOioiJCQ0PPaHsanCsiInXSmf5nLnWHP3+W+lSIiIiIZSi4iIiIiGUouIiIiNRB7du3Z9asWX7Z1vLly7HZbBw+fNgv2wskDc4VERHxk8suu4zevXv7JXB88803NGnS5MyLqmfU4yIiIr4pyIFVf4f8g4GuxHJKT6pXFa1bt9ZRVRVQcBEREd98/QJ8/ih88lCtPaVhGBwtKg7IZBhGlWqcMGECK1as4LnnnsNms2Gz2Zg3bx42m41PPvmEvn374nQ6WbVqFTt27GD48OFERkbStGlT+vXrx+eff+61vRN3FdlsNl599VWuueYaGjduTOfOnfn3v/9d7ff0/fffp0ePHjidTtq3b8/f/vY3r/UvvvginTt3JjQ0lMjISK677jrPuvfee4+4uDgaNWpEq1atSEpKIj8/v9q1+EK7ikRExDe715q3P30EhUfA2azGn/LYcRfdp/63xp+nIj8+nkzjkNN/XT733HP873//o2fPnjz++OMAbN68GYCHH36Yv/71r3Ts2JEWLVqwe/durrzySv7yl7/gdDqZP38+w4YNY+vWrbRt27bS53jssceYMWMGzz77LC+88AJjx45l586dtGzZ0qfXtGHDBm644QYeffRRRo0axddff80f/vAHWrVqxYQJE1i/fj1//OMf+ec//8mAAQP49ddf+eqrrwDIzMxkzJgxzJgxg2uuuYYjR47w1VdfVTngnSkFFxERqTq3G/Z9Z84XHzPDS/zowNZUR4SHhxMSEkLjxo2JiooC4KeffgLg8ccfZ9CgQZ62LVu2JD4+3nP/iSeeYMmSJfz73//mzjvvrPQ5JkyYwJgxYwB46qmneP7551m3bh1DhgzxqdaZM2cycOBAHnnkEQC6dOnCjz/+yLPPPsuECRPYtWsXTZo04eqrr6ZZs2a0a9eOPn36AGZwKS4uZuTIkbRr1w6AuLg4n57/TCi4iIhI1f36MxTmlN3//t1aCS6Ngh38+HhyjT9PZc99ps4//3yv+3l5eTz66KN89NFHniBw7Ngxdu3adcrt9OrVyzPfpEkTwsLC2L9/v8/1bNmyheHDh3stu/DCC5k1axYul4tBgwbRrl07OnbsyJAhQxgyZIhnF1V8fDwDBw4kLi6O5ORkBg8ezHXXXUeLFi18rqM6NMZFRESqbt9G8zbsbPN2x5eQd6DGn9Zms9E4JCggkz+uk3Ti0UH3338/S5Ys4amnnuKrr74iPT2duLg4ioqKTrmd4ODgk94Xt9t9xvWdqFmzZmzcuJEFCxYQHR3N1KlTiY+P5/DhwzgcDj777DM++eQTunfvzgsvvEDXrl3JyMjwex0VUXAREZGq2/etedvtaog5DwwXbF4c2JrqkJCQEFwu12nbrV69mgkTJnDNNdcQFxdHVFQUv/zyS80XWKJbt26sXr36pJq6dOmCw2H2MAUFBZGUlMSMGTPYtGkTv/zyC1988QVgBqYLL7yQxx57jG+//ZaQkBCWLFlSK7VrV5GIiFTd3pIel5jzoEV7swdm0zuQ8PuAllVXtG/fnrVr1/LLL7/QtGnTSntDOnfuzOLFixk2bBg2m41HHnmkRnpOKnPffffRr18/nnjiCUaNGkVaWhqzZ8/mxRdfBODDDz/k559/5pJLLqFFixZ8/PHHuN1uunbtytq1a0lNTWXw4MG0adOGtWvXcuDAAbp161YrtavHRUREqsZVDJklA3Nj+kCPkWCzw971cGhHYGurI+6//34cDgfdu3endevWlY5ZmTlzJi1atGDAgAEMGzaM5ORkzjvvvFqr87zzzuOdd95h4cKF9OzZk6lTp/L4448zYcIEAJo3b87ixYu54oor6NatG3PnzmXBggX06NGDsLAwVq5cyZVXXkmXLl3485//zN/+9jeGDh1aK7XbjNo6fqkG5ebmEh4eTk5ODmFhYYEuR0SkfsreDC8NAGcYPLQT7Hb45zWw4wu47E9wmX/O61JQUEBGRgYdOnQgNDTUL9uUwKrsZ1qd72/1uIiISNWU7iaKjjdDC0DcDebt9++A9f8PFgtQcBERkaopPaIopk/Zsm5XQ1AjOLS9bOCu1LrbbruNpk2bVjjddtttgS7PrzQ4V0REqqY0mJxVbiyGsxl0HWoeWfT9u97rpNY8/vjj3H///RWuq29DKBRcRETk9IoLIesHc758jwtArxvM4PLD+zD4SbCf+QnbxDdt2rShTZs2gS6jVmhXkYiInF72ZnAfh0YtoXk773XnDIRGLSAvGzJWBKY+aTAUXERE5PRKx7ecdR6ceCbZoBDoPsKc3/RurZYlDY+Ci4iInN7ekvEtJ+4mKtWr5OiiLf+B48dqpyZpkHwOLitXrmTYsGHExMRgs9lYunTpKdtPmDABm8120tSjRw9Pm0cfffSk9eeee67PL0ZERGpI6cDcmEoG38ZeAOGxUHQE/res9uqSBsfn4JKfn098fDxz5sypUvvnnnuOzMxMz7R7925atmzJ9ddf79WuR48eXu1WrVrla2kiIlITivLhwBZzvrIeF7sd4q4z57W7SGqQz8Fl6NChPPnkk1xzzTVVah8eHk5UVJRnWr9+Pb/99hsTJ070ahcUFOTVLiIiwtfSRESkJmRuAsMNzaIhLLrydqUno9v2KRz9tXZqq2fat2/PrFmzqtS2Kns96qNaH+Py2muvkZSURLt23qPSt23bRkxMDB07dmTs2LGVXt8BoLCwkNzcXK9JRERqyOl2E5WK7A6RPc2jj378oObrkgapVoPLvn37+OSTT5g0aZLX8oSEBObNm8eyZct46aWXyMjI4OKLL+bIkSMVbmf69OmEh4d7ptjY2NooX0SkYfIcUVTJbqLy4kqGAXyv3UVSM2o1uLz55ps0b96cESNGeC0fOnQo119/Pb169SI5OZmPP/6Yw4cP884771S4nSlTppCTk+OZdu/eXQvVi4g0UHsrONV/ZeKuA2ywczUc9uPfZsMwx9oEYqriNZhefvllYmJicLvdXsuHDx/OzTffzI4dOxg+fDiRkZE0bdqUfv368fnnn/vtLfr++++54ooraNSoEa1ateLWW28lLy/Ps3758uX079+fJk2a0Lx5cy688EJ27twJwHfffcfll19Os2bNCAsLo2/fvqxfv95vtflTrZ051zAMXn/9dW666SZCQkJO2bZ58+Z06dKF7du3V7je6XTidDprokwRESnv2GH4dYc5f7pdRQDhZ0O7C2HnKvjhPbjoXv/UcfwoPBXjn2356k/7IKTJaZtdf/313HXXXXz55ZcMHDgQgF9//ZVly5bx8ccfk5eXx5VXXslf/vIXnE4n8+fPZ9iwYWzdupW2bdueUYn5+fkkJyeTmJjIN998w/79+5k0aRJ33nkn8+bNo7i4mBEjRjB58mQWLFhAUVER69atw1ZyTp6xY8fSp08fXnrpJRwOB+np6QQHB59RTTWl1oLLihUr2L59O7fccstp2+bl5bFjxw5uuummWqhMREQqlZlu3jZvB41bVu0xva43g8umd/0XXCygRYsWDB06lLffftsTXN577z0iIiK4/PLLsdvtxMfHe9o/8cQTLFmyhH//+9/ceeedZ/Tcb7/9NgUFBcyfP58mTcyQNXv2bIYNG8YzzzxDcHAwOTk5XH311ZxzzjkAdOvWzfP4Xbt28cADD3hORdK5c+czqqcm+Rxc8vLyvHpCMjIySE9Pp2XLlrRt25YpU6awd+9e5s+f7/W41157jYSEBHr27HnSNu+//36GDRtGu3bt2LdvH9OmTcPhcDBmzJhqvCQREfGbveXOmFtV3YfDxw/A/s3mpQIie5z+MacT3Njs+QiE4MZVbjp27FgmT57Miy++iNPp5K233mL06NHY7Xby8vJ49NFH+eijj8jMzKS4uJhjx46d8mCUqtqyZQvx8fGe0AJw4YUX4na72bp1K5dccgkTJkwgOTmZQYMGkZSUxA033EB0tHmUWEpKCpMmTeKf//wnSUlJXH/99Z6AU9f4PMZl/fr19OnThz59zH2dKSkp9OnTh6lTpwKQmZl50g8hJyeH999/v9Lelj179jBmzBi6du3KDTfcQKtWrVizZg2tW7f2tTwREfGnqh5RVF6jFtB5sDm/qeKxij6z2czdNYGYTrzEwSkMGzYMwzD46KOP2L17N1999RVjx44FzH/SlyxZwlNPPcVXX31Feno6cXFxFBUV+ec9Oo033niDtLQ0BgwYwKJFi+jSpQtr1qwBzBPBbt68mauuuoovvviC7t27s2TJklqpy1c+97hcdtllGKcYqDRv3ryTloWHh3P06NFKH7Nw4UJfyxARkdqw7zSn+q9M3PXw04fw/XswcJp5groGIDQ0lJEjR/LWW2+xfft2unbtynnnmaFv9erVTJgwwXMetLy8PH755Re/PG+3bt2YN28e+fn5nl6X1atXY7fb6dq1q6ddacfDlClTSExM5O233+aCCy4AoEuXLnTp0oV7772XMWPG8MYbb1T5nG21qWF8kkRExHd5ByBnN2CDmN6+PbZLMoQ0g9w9sHtNTVRXZ40dO5aPPvqI119/3dPbAua4kcWLF5Oens53333HjTfeeNIRSGfynKGhoYwfP54ffviBL7/8krvuuoubbrqJyMhIMjIymDJlCmlpaezcuZNPP/2Ubdu20a1bN44dO8add97J8uXL2blzJ6tXr+abb77xGgNTl9Ta4FwREbGY0t6WiC7gbObbY4MbQfffQfpb5u6idgP8X18ddcUVV9CyZUu2bt3KjTfe6Fk+c+ZMbr75ZgYMGEBERAQPPfSQ306g2rhxY/773/9y9913069fPxo3bsy1117LzJkzPet/+ukn3nzzTQ4dOkR0dDR33HEHv//97ykuLubQoUOMGzeO7OxsIiIiGDlyJI899phfavM3m3Gq/T4WkZubS3h4ODk5OYSFhQW6HBGR+mH507B8OvQaDSP/4fvjd3wJ/xxhjnm5738QdOpTYZQqKCggIyODDh06EBoa6vvzSp1T2c+0Ot/f2lUkIiIVq84RReV1uASaRsGx32C7/060Jg2bgouIiJzMMKo/MLeU3QE9rzXnv/fT0UUNxFtvvUXTpk0rnHr08MPh5RamMS4iInKy3L2Qvx/sQRAVV/3t9Loe1syBrZ9AQS6Eand+Vfzud78jISGhwnV19Yy2tUXBRURETla6m6hNN3OgbXVF94ZWneHQNvPw6N43nvYhAs2aNaNZMx8HRDcQ2lUkIiInO9PdRKVsNuh1gznv48no6sGxI1LCnz9LBRcRETnZvtIrQldzYG55cdeZtxkr4Ej2aZuX7go51YlLxVpKf5b+2M2lXUUiIuKt/MDc6h5RVF7LjnB2P9jzDfzwPiT+4ZTNHQ4HzZs3Z//+/YB5DhKbD6fdl7rDMAyOHj3K/v37ad68OQ6H44y3qeAiIiLefv0ZCnLA4YQ23f2zzbgbzODy/TunDS4AUVFRAJ7wItbWvHlzz8/0TCm4iIiIt9Lelqg4cPjpCJYe18Cyh81tH9wOEZ1O2dxmsxEdHU2bNm04fvy4f2qQgAgODvZLT0spBRcREfF2pieeq0jT1nDO5eaJ6L5/Fy6fUqWHORwOv37pifVpcK6IiHjz1xFFJ4orObro+3fMcTQi1aDgIiIiZdwuyPzOnPfHEUXlnXsVBDc2x9CU9uqI+EjBRUREyhz8HxzPh+AmENHZv9t2NoWuV5rzugSAVJOCi4iIlCntCYnpbV5ryN9KT0b3w/tQXOT/7Uu9p+AiIiJlPCee8/P4llLnXAFNIyH/AHz5ZM08h9RrCi4iIlKmpgbmlnIEw1UzzfnVz8PPK2rmeaTeUnARERFTcRFkfW/O+/NQ6BN1uxr6TgAMWHIbHP215p5L6h0FFxERMe3fDK4iCG0OLTrU7HMlP2VeNfrIPvjP3To8WqpMwUVEREzldxPV9LWBQprAta+CPRi2/Bu+/WfNPp/UGwouIiJiqokz5p5KTG+44s/m/CcPmZcCEDkNBRcRETHV9MDcigz4I7S/GI4fhcWTdIi0nJaCi4iIQNFR2L/FnPf3GXNPxW6Ha/5hjqvZ9y0sn157zy2WpOAiIiLm0USGyzzHSlhM7T53+Fnwu+fN+VV/h19W1e7zi6UouIiIiPeJ52p6YG5Fug+HPjcBBiy+FY79Vvs1iCUouIiISLnxLbW4m+hEQ56Glh0hdy/85x4dIi0VUnAREZHaP6KoIs6mJYdIB8GPS+G7BYGrReosBRcRkYauIAcObTPna/OIooqc1Rcu/5M5//EDcGhHYOuROkfBRUSkocv8zrwNbwtNIgJbC8CF90C7i6Aozxzv4joe6IqkDlFwERFp6Dy7iQLc21LK7oCR/4DQcNi7HlY8E+iKpA5RcBERaejKH1FUV4SfDVfPMue/+hvs/Dqg5UjdoeAiItLQ1YUjiirScyTE3wiGu+QQ6cOBrkjqAJ+Dy8qVKxk2bBgxMTHYbDaWLl16yvbLly/HZrOdNGVlZXm1mzNnDu3btyc0NJSEhATWrVvna2kiIuKr/INweJc5Hx0f2FoqcuUMaNEecnbDR/fpEGnxPbjk5+cTHx/PnDlzfHrc1q1byczM9Ext2rTxrFu0aBEpKSlMmzaNjRs3Eh8fT3JyMvv37/e1PBER8UVpb0urTtCoeUBLqZCzGYx8FWwO+OE92PROoCuSAPM5uAwdOpQnn3ySa665xqfHtWnThqioKM9kt5c99cyZM5k8eTITJ06ke/fuzJ07l8aNG/P666/7Wp6IiPiiru4mKi+2H1z2sDn/0X3w2y8BLUcCq9bGuPTu3Zvo6GgGDRrE6tWrPcuLiorYsGEDSUlJZUXZ7SQlJZGWllZb5YmINEx76+DA3IpcfB+0TYSiI/D+ZHAVB7oiCZAaDy7R0dHMnTuX999/n/fff5/Y2Fguu+wyNm40f1kOHjyIy+UiMjLS63GRkZEnjYMpVVhYSG5urtckIiI+MoyyI4oCecbcqrA7zKtIO8NgzzpYPSvQFUmA1Hhw6dq1K7///e/p27cvAwYM4PXXX2fAgAH8/e9/r/Y2p0+fTnh4uGeKjY31Y8UiIg3EkUzIywabHaJ6Bbqa02vRDobOMOe/fh4K9E9rQxSQw6H79+/P9u3bAYiIiMDhcJCdne3VJjs7m6ioqAofP2XKFHJycjzT7t27a7xmEZF6p3Q3UetuENI4sLVUVa9R0KqzeZmCDW8EuhoJgIAEl/T0dKKjowEICQmhb9++pKameta73W5SU1NJTEys8PFOp5OwsDCvSUREfLSvjp0xtyrsdrjoHnM+bQ4cLwhoOVL7gnx9QF5enqe3BCAjI4P09HRatmxJ27ZtmTJlCnv37mX+/PkAzJo1iw4dOtCjRw8KCgp49dVX+eKLL/j0008920hJSWH8+PGcf/759O/fn1mzZpGfn8/EiRP98BJFRKRCniOKLBRcAOJugC+fgty98N3bcP7Nga5IapHPwWX9+vVcfvnlnvspKSkAjB8/nnnz5pGZmcmuXbs864uKirjvvvvYu3cvjRs3plevXnz++ede2xg1ahQHDhxg6tSpZGVl0bt3b5YtW3bSgF0RkTrHMMBmC3QVvjMMaxwKXZGgEBhwFyx7GFY/B33GgcPnrzOxKJthWP80hLm5uYSHh5OTk6PdRiJSe1bMgK9fgEvuh8S7zN0YVvFrBjzfGxwhMGUPBDkDXZFvivLh7z3h2K9w7WsQd12gK5JqqM73t4V+y0RE6pBDO8yrFhfmwmdT4a3rIM9CZ/suHd8S2cN6oQUgpAlccLs5v+rvuhRAA6LgIiJSHV88Ce5iiOgKQY1gRyq8dCHs+CLQlVWN58RzFttNVF7/yRDSFLJ/gG2fBboaqSUKLiIivtq7ETYvBmxw3Wtw65fmIcX5++GfI+HzR8F1PNBVntq+dPO2rp947lQatYDzSw7iWDUzsLVIrVFwERHxhWHA59PM+V43QFQctOlmhpfzbwYMc9fFG0Pht50BLbVSxUWQmW7OW+2IohNdcIc5TmdXGuysx5eJMQz4ebk5NqmBU3AREfHFji8gY6X5ZXn5/ytbHtwIrv473DAfnOGw5xuYezFsXhK4Wiuz4Q0oyoOmkeauLisLi4beN5rz9bXXZfc6eG0QzB8OLybCd4sCXVFAKbiIiFSV213W29JvknkK+hN1Hw63fQVn94fCHHh3Avznbig6WqulVqogxxxUDOYVl+vDYcQX3m1etmDbp5D1faCr8Z/fdsK7E83QsucbwAbFx2DJreZVsouLAl1hQCi4iIhU1Q/vm1+MIc3g4vsrb9eiHUz8GC5KAWywYR68cgXs31JblVZu9XNw9JB52vw+4wJdjX+07Ag9rjHnV1X/Onh1RkGuOU5qdr+ysVR9boKUH+GSB80237xq7o7M2RPISgNCwUVEpCqKi+CLJ8z5i+6GJq1O3d4RDEnT4KYl5i6ZA1vg5ctg/RuBO3Q3dx+kvWjOD3qsfvS2lLrwHvN28xLzUHUrchXD+tfh+T5mAHMVQodLzB684bMhLAau+H9w4zsQGg5718M/LjHHvjQgCi4iIlWx4Q04vNMMIRf8oeqPO+dyuG01dEqC4gL48B5z99GxwzVU6Cl8+ZS5q6FtInS9svafvyZF94JOg8Bwm1eOtprtn8Pci+DDe+HoQbNHbMwiGPdvcwB4eV2S4dYV5vKjh+Cf18BXfzN3ZTYACi4iIqdTkOs9LiSkiW+Pb9oabnwXBj0B9iD4cak5cHf3N34vtVLZP0L6W+b8oCeseZmC07nYvAQN6W9DbmZga6mq/VvgX9ea04Et5iHeQ2fAH9Kg65DKf04tO8Atn0Hv/zPDWurjsGhsYAJxLVNwERE5nbTZJeNCOpljDarDbocL/wg3fwot2kPOLng9GdbM9Wuplfr8UfMLrtvvILZf7TxnbWs3AGIvAFcRrJkT6GpOLe+A2bvy0gCzt8UeDIl3wh+/hYTfm7saTye4EYyYA8OeB4cTtn5s7o7M+qHGyw8kBRcRkVM5kg1fzzbnB06t2hfKqZzdF36/EnpeC4YLlj1kfnHVpIyVsO2/Zm/PwGk1+1yBVtrrsv4NOPZbYGupyPECc/zK833M8SyGG7oNgzvWQvJfzB4XX/UdD7f8F8Lbwm8Z8GoSpC/wf+11hIKLiMiprJwBx/PhrL5mb4U/hIabFwbsN8m8v/j3cCTLP9s+kdttXksJoO9EiOhUM89TV3QeDJE9zfPUrHsl0NWYDMPcJfT1bJjTz+z9KjoC0b1hwscw6l/Q6pwze46YPvD7FSVjqY7B0tvMHp3iQn+8gjpFwUVEpDKHdpiHMgMkPebfcSE2Gwz+i/kle/QgLL61ZgZXbl4M+741r+lz6UP+335dY7PBRfea82teMq8iHQjHfjOPcPrgTvh7D3jxAvj0/8HhXdAsBq75B0z+Etpf6L/nbNzSHEt16cOAzezReWMoHN7tv+eoAxRcREQq88UT5oUUOw2CDhf7f/vBoXDdGxDcGDJWwGo/n4OkuNActAnm4cJNW/t3+3VV9xHmOKJjv8LG+bXznG6XOdh6+dPw6iCY0dE8euzbf0LuXggKhXMGmgNv71oP8aPNcU/+ZrfD5VNg7LsQ2hz2bjAPmbbKxT+rwGYY1r8WeG5uLuHh4eTk5BAWFhbockSkPti7EV65HLCZ59E48ZBUf/r2LfjgD2BzwMRPoG2Cf7a75iVY9jA0jYI/bvT9aCgrW/+6uask7Cz4YzoEhfj/OXL3wfZUc4zSz8uh4LD3+tbnmmGl0xXQ7kJzMG1t+m0nvHMTZH4H2ODyP5m7Jxu3rN06TqE6398KLiIiJzIMmP87c1Brr9Ew8h81/3yLb4Xv34HwWDMoVWeQZnnHDpsDQI/9CsOeg74T/FGpdRwvgOd6QV42DJ8Dff7vzLdpGPDLKvjfMjOwHDjhTMih4dDxspKwMhDCzz7z5zxTxwvgkwe8e55ad4O2F5jn82l7ATRvG7DD4xVcFFxExB+2p8K/RpoXUrxzfcXXJPK3wiNml/6vP5tHmdzwzzP7Mvn8UfPolYiucPvX9essuVW1+jlzYHKrzuZRO3ZH9bd1YCt88qD3WWptdog5zxwQ22mgOV9X3+f0t83Pw8H/nbyuWYx3kInscWbvlQ8UXBRcRORMud3w8iXmNYkuuAOGPFV7z73vW3N8hPs4XPW3sqOOfJWzB17oa56pd8xC6DrUv3VaReERc2BsQY4ZBLtX46iwwiPmyQfXvGSOd3I4Ie46M6x0vKxO7XapkvyDsHst7EqDXWvMz5y72LtNSDOI7V8WZM7qCyGNa6QcBRcFFxE5U5vehcWTwBlmjo043TWJ/C3tRfjvFPMLcvIXENXT920svQPS/2WOq5jwUf08S25VffEkrHzWPFx48pdVfy8MA75/Fz59BPJKDlXveiUkP2Wetba+KDoK+zaWBZnd66Aw17uNPcg8dLvtBXDpg+YuMT9RcFFwEZEzUVwEs883r0l0xSNwySmuAF1TDAMWjDbHUUR0gVuX+zaoNnszvHQhYMCkL8wT3jVk+Qfh7z3Nc5vctNS8dtTpZP0AHz8Au74277fsCEOegS6Da7TUOsHtgv0/miFmVxrsTIMj+8x1wU3g4V1+3R1Wne/vOrozTkQkADwXUoyCC24PTA02Gwx/EeZeaI5H+ORBc3BpVX02DTDMQ4IbemgBaBJhnll27VxYNfPUweXYYfNClN+8Yp7RNrixGV4T74QgZ62VHFB2h3kEXVQc9J9sBumc3WaQyT9QJ8bw6DwuIiJw5hdS9KcmreDaV83Bn9/+y9x9VRU/L4ftn5Wc2n9qjZZoKYl3mu9JxkrYs+Hk9W63+T6/0BfW/cMMLd1HwB3r4OL7Gk5oqYjNZh511OsGSLwj0NUACi4iIiZ/XEjRn9pfBJc8aM5/eK95Ft9TKX9q//NvOfNTyNcnzWMh7gZzftVM73V7N8Jrg+CDO8wzGEd0hXEfwA1vmo+TOkfBRUTkpAspBr47HIBLHjAH2BYdgfduNsfgVGbzYvNEYyHNzAGU4u2iewAb/PQh7P8J8g/Bf+6GV66AvevNSyIMfhJuX20eLSR1loKLiEhNXEjRHxxBMPIV82R0memQ+ljF7YoLy9ZddI85rkO8te4K515lzi+9HWb3LbkOlQG9RsFdG2DAXWd+9W+pcQouItKwlb+Q4qDH696hw+FnwYiXzPm02fC//57c5ptXSy7eFw0X/KF267OSi1PM230bzYsgRvY0L7Ew8mVoFhXY2qTKFFxEpGErvZBi58HmuJK6qOtQSCg5ymnp7eY1ckod+w1WzDDnL/9TjZ0orF44qy/E32geNTb0Wbh1BbQbEOiqxEd1ZEeuiEgA7N0Am5cANhg4LdDVnNqgx2DnasjaZF7XaNwH5qGrq/5uXtyvdTfzS1lO7ZqXAl2BnCH1uIhIw2QY8N//Z87Hj67eGWprU5ATrp9nDiL95Sv46m9weDesmWuuH/RY3RlULFKDFFxEpGHa8m/zzKBBjaxzzpNW58BVJYfzLp9uHmnkKoT2F5u7ukQaAAUXEWl4igvLznly4R8hLCaw9fgifpS5S8hww5515rJBj9W9QcUiNUTBRUQannUvw2+/mIM0B/wx0NX47spnzRPlAfQYaQ46FWkgtENURBqW/EOw4llzfuAj4Gwa2Hqqw9kUxr5nnqZehz9LA6PgIiINy4pnoDAHIuMgfkygq6m+lh3M4CXSwPi8q2jlypUMGzaMmJgYbDYbS5cuPWX7xYsXM2jQIFq3bk1YWBiJiYn897/eJ1B69NFHsdlsXtO5557ra2kiIqd24H/mydoAkp80DycWEUvxObjk5+cTHx/PnDlVu8z6ypUrGTRoEB9//DEbNmzg8ssvZ9iwYXz77bde7Xr06EFmZqZnWrVqla+liYic2mdTwXBBl6G6Ho2IRfm8q2jo0KEMHTq0yu1nzZrldf+pp57igw8+4D//+Q99+vQpKyQoiKgonXJZRGrIzyvgf5+APQgGPxHoakSkmmr9qCK3282RI0do2bKl1/Jt27YRExNDx44dGTt2LLt27ap0G4WFheTm5npNIiKVcrvg05KTzZ1/M0R0Dmw9IlJttR5c/vrXv5KXl8cNN9zgWZaQkMC8efNYtmwZL730EhkZGVx88cUcOXKkwm1Mnz6d8PBwzxQbG1tb5YuIFX23ALK+B2c4XPpwoKsRkTNgMwzDqPaDbTaWLFnCiBEjqtT+7bffZvLkyXzwwQckJSVV2u7w4cO0a9eOmTNncsstt5y0vrCwkMLCQs/93NxcYmNjycnJISwszOfXISL1WGEevNAX8rJg8JMw4K5AVyQiJXJzcwkPD/fp+7vWDodeuHAhkyZN4t133z1laAFo3rw5Xbp0Yfv27RWudzqdOJ3OmihTROqbr18wQ0uL9tD/1kBXIyJnqFZ2FS1YsICJEyeyYMECrrrqqtO2z8vLY8eOHURHR9dCdSJSb+Xug9XPmfNJj5kXKhQRS/O5xyUvL8+rJyQjI4P09HRatmxJ27ZtmTJlCnv37mX+/PmAuXto/PjxPPfccyQkJJCVlQVAo0aNCA8PB+D+++9n2LBhtGvXjn379jFt2jQcDgdjxlj45FAiEnipT0DxMYi9ALoPD3Q1IuIHPve4rF+/nj59+ngOZU5JSaFPnz5MnWpesCwzM9PriKCXX36Z4uJi7rjjDqKjoz3T3Xff7WmzZ88exowZQ9euXbnhhhto1aoVa9asoXXr1mf6+kSkodr3LXz3tjmf/JQuQihST5zR4Ny6ojqDe0SkHjMMmHc17FwFcdfDta8GuiIRqUB1vr91dWgRqX+2fmyGlqBQGDgt0NWIiB8puIhI/VJcBJ+WXHww8Q5orvM8idQnCi4iUr+sfw1+3QFNWsNF9wa6GhHxMwUXEak/jv4Ky5825y//f+BsFth6RMTvFFxEpP5Y+VcoOAxtukOfmwJdjYjUAAUXEakfDu2AdS+b84OfBEetnRhcRGqRgouI1A+fTQX3ceg0CDoNDHQ1IlJDFFxExPp+WQU/fQg2Owx+ItDViEgNUnAREWtzu+G/fzLn+06ANt0CWo6I1CwFFxGxtk0LIfM7CGkGl/0p0NWISA1TcBER6/r2LfhPyXXPLrkPmur6ZiL1nYbdi4j1uIrNwbhr5pj3z70aLvhDYGsSkVqh4CIi1nLsN3jvZtjxhXn/0ofh0ofArg5kkYZAwUVErOPgNlgwGg5th+DGMOIl6DEi0FWJSC1ScBERa9j2Gbx3CxTmQHgsjH4bonsFuioRqWUKLiJStxkGpM02x7QYboi9AEb9SwNxRRooBRcRqbuOF5hHDW1aaN7vcxNcNROCQgJbl4gEjIKLiNRNuZmwaCzs3QA2BwyZDv1vBZst0JWJSAApuIhI3bN3AywcC0cyIbQ5XD8Pzrk80FWJSB2g4CIidcumd+CDO8FVCBFdYcwCaHVOoKsSkTpCwUVE6ga3C1Ifh9WzzPudk+HaVyE0LKBliUjdouAiIoFXkAvvT4Jt/zXvX3QvXPEI2B2BrUtE6hwFFxGpffkH4cBPcGArHPwfbPsUfv0ZgkLhd7Oh1/WBrlBE6igFFxGpGW435O6BA/+Dg1vLQsqBrXDs15PbN4uB0W/BWefVfq0iYhkKLiJyZtxu+C0D9v/oHU4OboPj+ZU8yAbN20LrrhDRxbw992po3LJWSxcR61FwEZGqO3YYsjeXTD+Yt/t/hONHK25vD4JWncrCSURXaN0FWnWGkMa1WrqI1A8KLiJyMrcLDu0oCyeltzm7K24fFGoGk9bneoeUlh3AEVy7tYtIvabgIiKQdwB+XAqZ6SW9KFuguKDituGxENmjZOppTi07gkN/TkSk5ukvjUhDZRiw5xtY94oZWlxF3uuDG0ObbmXhpDSsNGoeiGpFRAAFF5GG5/gx+P49+OYVyPyubPlZfeGcgRBVElRatNd5VESkzlFwEWkofv0ZvnkNvv0XFBw2lzmcEHcd9Jukw5BFxBIUXETqM7cbtn9u9q5s+wwwzOXN20G/W6DPTToEWUQsRcFFpD46+iukvwXfvAq//VK2vFMS9JsMnQdpN5CIWJKCi0h9si/d7F35/r2yo4JCw82elfNv1lWWRcTyfA4uK1eu5Nlnn2XDhg1kZmayZMkSRowYccrHLF++nJSUFDZv3kxsbCx//vOfmTBhglebOXPm8Oyzz5KVlUV8fDwvvPAC/fv397U8kdpXXAiFeVB0BIry4XiBeYSO+7h56zpeMpXMV7TcXVyyrKhc25L54sKTl7kKT2h73Awq+QfK6oqKM3tX4q7Xyd5EpN7wObjk5+cTHx/PzTffzMiRI0/bPiMjg6uuuorbbruNt956i9TUVCZNmkR0dDTJyckALFq0iJSUFObOnUtCQgKzZs0iOTmZrVu30qZNG99flcipuIrNkFGYB0V5UHjEnIryzGWFR8pCSPk2RXkVLMs3g0hdYQ+GHiPMwBLbH2y2QFckIuJXNsMwjGo/2GY7bY/LQw89xEcffcQPP/zgWTZ69GgOHz7MsmXLAEhISKBfv37Mnj0bALfbTWxsLHfddRcPP/zwaevIzc0lPDycnJwcwsLCqvtyGjbDAMNt3mJU7dZwl1uGb4+loucrtw23y+xVKC4yexJchWbPQ3FBuWVFJ9wvbVNoBoqTQklJWCk+VjPvYVAjcDY1bx3B4AgxT8rmCDEne7n50y53lttGSNl8UPnl5deXTGExGmwrIpZRne/vGh/jkpaWRlJSktey5ORk7rnnHgCKiorYsGEDU6ZM8ay32+0kJSWRlpZW4TYLCwspLCz03M/NzfV/4WB+Ic6KO02j0+S+k3KhUY31xgltjXI3Faw7af5UYaHaudX6HCEQ0tQMG86wsnnPbbMT7leyLqSJeaszx4qI1Lga/0ublZVFZGSk17LIyEhyc3M5duwYv/32Gy6Xq8I2P/30U4XbnD59Oo899liN1ewlL6t2nqdespXsqqjk1mavZB1gc5i9C0FOs/ehdD4otKTnIRSCQiq57zTHdIQ0BWczc/LMlwsdQc4AvjciIlIdlvwXccqUKaSkpHju5+bmEhsb6/8nsgfBbav8sKFy4wy8xhxUtryidbYT2p14/4R1J82XBIVKg4S97DGnChunDR02NK5CRERqSo0Hl6ioKLKzs72WZWdnExYWRqNGjXA4HDgcjgrbREVFVbhNp9OJ01kL/y3b7eaRGSIiIlIn2Gv6CRITE0lNTfVa9tlnn5GYmAhASEgIffv29WrjdrtJTU31tBERERGBagSXvLw80tPTSU9PB8zDndPT09m1axdg7sYZN26cp/1tt93Gzz//zIMPPshPP/3Eiy++yDvvvMO9997raZOSksIrr7zCm2++yZYtW7j99tvJz89n4sSJZ/jyREREpD7xeVfR+vXrufzyyz33S8eajB8/nnnz5pGZmekJMQAdOnTgo48+4t577+W5557j7LPP5tVXX/WcwwVg1KhRHDhwgKlTp5KVlUXv3r1ZtmzZSQN2RUREpGE7o/O41BU6j4uIiIj1VOf7u8bHuIiIiIj4i4KLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYRrWCy5w5c2jfvj2hoaEkJCSwbt26Sttedtll2Gy2k6arrrrK02bChAknrR8yZEh1ShMREZF6LMjXByxatIiUlBTmzp1LQkICs2bNIjk5ma1bt9KmTZuT2i9evJiioiLP/UOHDhEfH8/111/v1W7IkCG88cYbnvtOp9PX0kRERKSe87nHZebMmUyePJmJEyfSvXt35s6dS+PGjXn99dcrbN+yZUuioqI802effUbjxo1PCi5Op9OrXYsWLar3ikRERKTe8im4FBUVsWHDBpKSkso2YLeTlJREWlpalbbx2muvMXr0aJo0aeK1fPny5bRp04auXbty++23c+jQoUq3UVhYSG5urtckIiIi9Z9PweXgwYO4XC4iIyO9lkdGRpKVlXXax69bt44ffviBSZMmeS0fMmQI8+fPJzU1lWeeeYYVK1YwdOhQXC5XhduZPn064eHhnik2NtaXlyEiIiIW5fMYlzPx2muvERcXR//+/b2Wjx492jMfFxdHr169OOecc1i+fDkDBw48aTtTpkwhJSXFcz83N1fhRUREpAHwqcclIiICh8NBdna21/Ls7GyioqJO+dj8/HwWLlzILbfcctrn6dixIxEREWzfvr3C9U6nk7CwMK9JRERE6j+fgktISAh9+/YlNTXVs8ztdpOamkpiYuIpH/vuu+9SWFjI//3f/532efbs2cOhQ4eIjo72pTwRERGp53w+qiglJYVXXnmFN998ky1btnD77beTn5/PxIkTARg3bhxTpkw56XGvvfYaI0aMoFWrVl7L8/LyeOCBB1izZg2//PILqampDB8+nE6dOpGcnFzNlyUiIiL1kc9jXEaNGsWBAweYOnUqWVlZ9O7dm2XLlnkG7O7atQu73TsPbd26lVWrVvHpp5+etD2Hw8GmTZt48803OXz4MDExMQwePJgnnnhC53IRERERLzbDMIxAF3GmcnNzCQ8PJycnR+NdRERELKI639+6VpGIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWIaCi4iIiFiGgouIiIhYhoKLiIiIWEa1gsucOXNo3749oaGhJCQksG7dukrbzps3D5vN5jWFhoZ6tTEMg6lTpxIdHU2jRo1ISkpi27Zt1SlNRERE6jGfg8uiRYtISUlh2rRpbNy4kfj4eJKTk9m/f3+ljwkLCyMzM9Mz7dy502v9jBkzeP7555k7dy5r166lSZMmJCcnU1BQ4PsrEhERkXrL5+Ayc+ZMJk+ezMSJE+nevTtz586lcePGvP7665U+xmazERUV5ZkiIyM96wzDYNasWfz5z39m+PDh9OrVi/nz57Nv3z6WLl1arRclIiIi9ZNPwaWoqIgNGzaQlJRUtgG7naSkJNLS0ip9XF5eHu3atSM2Npbhw4ezefNmz7qMjAyysrK8thkeHk5CQkKl2ywsLCQ3N9drEhERkfrPp+By8OBBXC6XV48JQGRkJFlZWRU+pmvXrrz++ut88MEH/Otf/8LtdjNgwAD27NkD4HmcL9ucPn064eHhnik2NtaXlyEiIiIWVeNHFSUmJjJu3Dh69+7NpZdeyuLFi2ndujX/+Mc/qr3NKVOmkJOT45l2797tx4pFRESkrvIpuEREROBwOMjOzvZanp2dTVRUVJW2ERwcTJ8+fdi+fTuA53G+bNPpdBIWFuY1iYiISP3nU3AJCQmhb9++pKamepa53W5SU1NJTEys0jZcLhfff/890dHRAHTo0IGoqCivbebm5rJ27doqb1NEREQahiBfH5CSksL48eM5//zz6d+/P7NmzSI/P5+JEycCMG7cOM466yymT58OwOOPP84FF1xAp06dOHz4MM8++yw7d+5k0qRJgHnE0T333MOTTz5J586d6dChA4888ggxMTGMGDHCf69URERELM/n4DJq1CgOHDjA1KlTycrKonfv3ixbtswzuHbXrl3Y7WUdOb/99huTJ08mKyuLFi1a0LdvX77++mu6d+/uafPggw+Sn5/PrbfeyuHDh7noootYtmzZSSeqExERkYbNZhiGEegizlRubi7h4eHk5ORovIuIiIhFVOf7W9cqEhEREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREcuoVnCZM2cO7du3JzQ0lISEBNatW1dp21deeYWLL76YFi1a0KJFC5KSkk5qP2HCBGw2m9c0ZMiQ6pQmIiIi9ZjPwWXRokWkpKQwbdo0Nm7cSHx8PMnJyezfv7/C9suXL2fMmDF8+eWXpKWlERsby+DBg9m7d69XuyFDhpCZmemZFixYUL1XJCIiIvWWzTAMw5cHJCQk0K9fP2bPng2A2+0mNjaWu+66i4cffvi0j3e5XLRo0YLZs2czbtw4wOxxOXz4MEuXLvX9FQC5ubmEh4eTk5NDWFhYtbYhIiIitas6398+9bgUFRWxYcMGkpKSyjZgt5OUlERaWlqVtnH06FGOHz9Oy5YtvZYvX76cNm3a0LVrV26//XYOHTpU6TYKCwvJzc31mkRERKT+8ym4HDx4EJfLRWRkpNfyyMhIsrKyqrSNhx56iJiYGK/wM2TIEObPn09qairPPPMMK1asYOjQobhcrgq3MX36dMLDwz1TbGysLy9DRERELCqoNp/s6aefZuHChSxfvpzQ0FDP8tGjR3vm4+Li6NWrF+eccw7Lly9n4MCBJ21nypQppKSkeO7n5uYqvIiIiDQAPvW4RERE4HA4yM7O9lqenZ1NVFTUKR/717/+laeffppPP/2UXr16nbJtx44diYiIYPv27RWudzqdhIWFeU0iIiJS//kUXEJCQujbty+pqameZW63m9TUVBITEyt93IwZM3jiiSdYtmwZ559//mmfZ8+ePRw6dIjo6GhfyhMREZF6zufDoVNSUnjllVd488032bJlC7fffjv5+flMnDgRgHHjxjFlyhRP+2eeeYZHHnmE119/nfbt25OVlUVWVhZ5eXkA5OXl8cADD7BmzRp++eUXUlNTGT58OJ06dSI5OdlPL1NERETqA5/HuIwaNYoDBw4wdepUsrKy6N27N8uWLfMM2N21axd2e1keeumllygqKuK6667z2s60adN49NFHcTgcbNq0iTfffJPDhw8TExPD4MGDeeKJJ3A6nWf48kRERKQ+8fk8LnWRzuMiIiJiPTV+HhcRERGRQFJwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy1BwEREREctQcBERERHLUHARERERy6hWcJkzZw7t27cnNDSUhIQE1q1bd8r27777Lueeey6hoaHExcXx8ccfe603DIOpU6cSHR1No0aNSEpKYtu2bdUpTUREROqxIF8fsGjRIlJSUpg7dy4JCQnMmjWL5ORktm7dSps2bU5q//XXXzNmzBimT5/O1Vdfzdtvv82IESPYuHEjPXv2BGDGjBk8//zzvPnmm3To0IFHHnmE5ORkfvzxR0JDQ8/8VVZTscvN+xv3cNxlUOxyU+w2zMnl5rjLwOU2OO52U1w67zLnzXZlyx12Gw67jSCHjWC73bx12CtcFlTSNthh96wLDrIRZLcTXNrGUW6+pG1w+WUlt8F2OzY72Epej81mwwbYShbYsHnmKVleusxW0t5uM2/rCsMwOO4yKHK5KTzuKrl1U+RyU1TsprDYRWGxGwyw223YbTYcdrDbSufL35ptHCXr7HY86w0DDAzchvmchmE+v7tk3iipxXPrWQYut4HbMH/2xeXm3SX3XYY57yqdjLJ5twHBDvPnHeSwEVL+5+ko/RxU8LMumXfYbLiNsrrdBiX3zRpL17ndZfcNz+syCLLbCQkyp2CHHWeQnRCHHbu97nwGrKb051DsduN2m7cut/fP3Pwp4PmclX6uyi/zXl+2MKTkZxQSZMcZ5CDYYQvo76xhGBQWu8kvLOZokYu8wmKOFhWTX+giv7CY/CIXR4uKKXYZNApx0CjYQWiwg9BgO42CHTQKMe+fuDzIUfn/2aV/FwqKXRQed1Nw3EVhsYuC427PrbnMvC12G+V+n8p+30r/pgaV+30LCTp5PZT9vhuYv/ylP0evvw9GWZvS5QAOmw1Hye9r6feD53ui5G9QkN2m37tK2Ayj/K/F6SUkJNCvXz9mz54NgNvtJjY2lrvuuouHH374pPajRo0iPz+fDz/80LPsggsuoHfv3sydOxfDMIiJieG+++7j/vvvByAnJ4fIyEjmzZvH6NGjT1tTbm4u4eHh5OTkEBYW5svLOaWC4y7OfWSZ37ZnZXab+aVeGmZKg4DNM3/y+tLwA3jalQ9FNgCvtmXByTAoF0bMPz6l81L7SgNyaagp/aIMKbcsqNwfX3v5P8ilQdFuw1EuLJYtM+fdRkmwKwn/LnfJPwsn3C8NhKW3xS63Jyx6glpJIHC5DU9wcBnl5kvbl7SDcp/Rknlbuc+317IT2gJe4bN8baVhtbaFBNlxOuw4g71/Rs4gh9fPLcju/c+LLwwDjpaEkDyvkOLCVQOvOdhhKwkyZpgpdhkUHC8LJwF4m2tFaYAJKvldCXKUBCu7jeAg739eT/nPbsnvoydwGd6/M6Vhy+3G65+f0n9s3AYE2228NqGfX19fdb6/fepxKSoqYsOGDUyZMsWzzG63k5SURFpaWoWPSUtLIyUlxWtZcnIyS5cuBSAjI4OsrCySkpI868PDw0lISCAtLa3C4FJYWEhhYaHnfm5uri8vo8qCHXaSurUp6Rkp/cGXJPHSlF4unXt6Ssr1mpT+QS7fa+PVM3PCsuMl/40Vu0qWlazzrC/p7SldV1Tspthdtqz8tv3JbYDbZQB1669DcEmvhNcf5SA7Nsp+2cp/SbnK9TiUftmU9pKUfrG53Ea5kGUrCVdlocpeLnTZML+Iy4ex8l/GZV/kEGQ3ey4cdrzW20v+GJWGQZfb7FEqdp3wc3UbHC92c7xcr1/putP9uMsHzJPCJ2VfysUus/fquMt7g2Yvootjx1018WNssEoDP5R81swZz0353lHAE/zN+dK/LSf/vIqKzdB/pJCAahTsoInTQRNnEI1DgmjqdJTcBmG320qCh4tjReZn69hxs8fkWLllpczPezFHCopP+7zOILsn4DiDzNvQYIdnucNu8/obW/r7VNpTXtqT7rXMVRacyzsp3Jb8YbBRyT9rnBx0T6XYTBYU+fbW14iQoLoxLNan4HLw4EFcLheRkZFeyyMjI/npp58qfExWVlaF7bOysjzrS5dV1uZE06dP57HHHvOl9Gpx2G28Ot6/6bK2lHadust1qHm6NT3z5bqjS5ZRrk353Q0n7nYoS+WVrz+x29T8/Sxb5nYblXa32rCV+y/xhFuHw/OfpLpSTaW7Kt2G4Qkknp6vauzuc5fsBi39AixyuTlebFDkMrvbi4rNP/TmOpfnvtsovwvEwOXGa9eYZ71nWdl6z3+VJ96W+28xyGH+83Biu9KendLdg6W7Ae02c3npl0tpiLSV311Y8t6cuHuw/Oe1/G6A0t1ugOf3y+FVj937v+TSIOs44b7df7t03CVht7Dcz6t0V2ppT2Xpz7J0d2phsRv3Gf6D0yjEQZOQIJo4gzwBxbxvBhTHGf5+lu52KigJNaVhpuC4m5CSHqXQoLKA4gw2/07U5K6y0r+Z/nyO8v9IndhbV9oTWXq/fMgqDa3FJ/6D41lerk1Jj6UN778NJ/ac28r9/bCdcP9Mf57+4vMYl7pgypQpXr04ubm5xMbGBrCiusdmsxESVDc+ZFLzzC9Oh9+2Z7fbcNodOIP8t02pOXa7jVC7uRulPrHZynYPNQ90MSVqIhTZ7Tbs2KhnP74a41O/T0REBA6Hg+zsbK/l2dnZREVFVfiYqKioU7YvvfVlm06nk7CwMK9JRERE6j+fgktISAh9+/YlNTXVs8ztdpOamkpiYmKFj0lMTPRqD/DZZ5952nfo0IGoqCivNrm5uaxdu7bSbYqIiEjD5POuopSUFMaPH8/5559P//79mTVrFvn5+UycOBGAcePGcdZZZzF9+nQA7r77bi699FL+9re/cdVVV7Fw4ULWr1/Pyy+/DJjdbvfccw9PPvkknTt39hwOHRMTw4gRI/z3SkVERMTyfA4uo0aN4sCBA0ydOpWsrCx69+7NsmXLPINrd+3ahd1e1pEzYMAA3n77bf785z/zpz/9ic6dO7N06VLPOVwAHnzwQfLz87n11ls5fPgwF110EcuWLQvoOVxERESk7vH5PC51UU2dx0VERERqTnW+v+vGQdkiIiIiVaDgIiIiIpah4CIiIiKWoeAiIiIilqHgIiIiIpah4CIiIiKWoeAiIiIilqHgIiIiIpZhyatDn6j0HHq5ubkBrkRERESqqvR725dz4daL4HLkyBEAYmNjA1yJiIiI+OrIkSOEh4dXqW29OOW/2+1m3759NGvWDJvN5tdt5+bmEhsby+7du3U5AR/ofasevW++03tWPXrfqkfvm+9O9Z4ZhsGRI0eIiYnxus7hqdSLHhe73c7ZZ59do88RFhamD2k16H2rHr1vvtN7Vj1636pH75vvKnvPqtrTUkqDc0VERMQyFFxERETEMhRcTsPpdDJt2jScTmegS7EUvW/Vo/fNd3rPqkfvW/XoffOdv9+zejE4V0RERBoG9biIiIiIZSi4iIiIiGUouIiIiIhlKLiIiIiIZSi4nMacOXNo3749oaGhJCQksG7dukCXVGc9+uij2Gw2r+ncc88NdFl1zsqVKxk2bBgxMTHYbDaWLl3qtd4wDKZOnUp0dDSNGjUiKSmJbdu2BabYOuR079uECRNO+vwNGTIkMMXWEdOnT6dfv340a9aMNm3aMGLECLZu3erVpqCggDvuuINWrVrRtGlTrr32WrKzswNUcd1QlfftsssuO+nzdttttwWo4rrhpZdeolevXp4TzSUmJvLJJ5941vvrs6bgcgqLFi0iJSWFadOmsXHjRuLj40lOTmb//v2BLq3O6tGjB5mZmZ5p1apVgS6pzsnPzyc+Pp45c+ZUuH7GjBk8//zzzJ07l7Vr19KkSROSk5MpKCio5UrrltO9bwBDhgzx+vwtWLCgFiuse1asWMEdd9zBmjVr+Oyzzzh+/DiDBw8mPz/f0+bee+/lP//5D++++y4rVqxg3759jBw5MoBVB15V3jeAyZMne33eZsyYEaCK64azzz6bp59+mg0bNrB+/XquuOIKhg8fzubNmwE/ftYMqVT//v2NO+64w3Pf5XIZMTExxvTp0wNYVd01bdo0Iz4+PtBlWApgLFmyxHPf7XYbUVFRxrPPPutZdvjwYcPpdBoLFiwIQIV104nvm2EYxvjx443hw4cHpB6r2L9/vwEYK1asMAzD/GwFBwcb7777rqfNli1bDMBIS0sLVJl1zonvm2EYxqWXXmrcfffdgSvKIlq0aGG8+uqrfv2sqcelEkVFRWzYsIGkpCTPMrvdTlJSEmlpaQGsrG7btm0bMTExdOzYkbFjx7Jr165Al2QpGRkZZGVleX3uwsPDSUhI0OeuCpYvX06bNm3o2rUrt99+O4cOHQp0SXVKTk4OAC1btgRgw4YNHD9+3Ovzdu6559K2bVt93so58X0r9dZbbxEREUHPnj2ZMmUKR48eDUR5dZLL5WLhwoXk5+eTmJjo189avbjIYk04ePAgLpeLyMhIr+WRkZH89NNPAaqqbktISGDevHl07dqVzMxMHnvsMS6++GJ++OEHmjVrFujyLCErKwugws9d6Tqp2JAhQxg5ciQdOnRgx44d/OlPf2Lo0KGkpaXhcDgCXV7Aud1u7rnnHi688EJ69uwJmJ+3kJAQmjdv7tVWn7cyFb1vADfeeCPt2rUjJiaGTZs28dBDD7F161YWL14cwGoD7/vvvycxMZGCggKaNm3KkiVL6N69O+np6X77rCm4iN8MHTrUM9+rVy8SEhJo164d77zzDrfccksAK5OGYPTo0Z75uLg4evXqxTnnnMPy5csZOHBgACurG+644w5++OEHjTvzUWXv26233uqZj4uLIzo6moEDB7Jjxw7OOeec2i6zzujatSvp6enk5OTw3nvvMX78eFasWOHX59CuokpERETgcDhOGvGcnZ1NVFRUgKqylubNm9OlSxe2b98e6FIso/Szpc/dmevYsSMRERH6/AF33nknH374IV9++SVnn322Z3lUVBRFRUUcPnzYq70+b6bK3reKJCQkADT4z1tISAidOnWib9++TJ8+nfj4eJ577jm/ftYUXCoREhJC3759SU1N9Sxzu92kpqaSmJgYwMqsIy8vjx07dhAdHR3oUiyjQ4cOREVFeX3ucnNzWbt2rT53PtqzZw+HDh1q0J8/wzC48847WbJkCV988QUdOnTwWt+3b1+Cg4O9Pm9bt25l165dDfrzdrr3rSLp6ekADfrzVhG3201hYaF/P2v+HT9cvyxcuNBwOp3GvHnzjB9//NG49dZbjebNmxtZWVmBLq1Ouu+++4zly5cbGRkZxurVq42kpCQjIiLC2L9/f6BLq1OOHDlifPvtt8a3335rAMbMmTONb7/91ti5c6dhGIbx9NNPG82bNzc++OADY9OmTcbw4cONDh06GMeOHQtw5YF1qvftyJEjxv3332+kpaUZGRkZxueff26cd955RufOnY2CgoJAlx4wt99+uxEeHm4sX77cyMzM9ExHjx71tLntttuMtm3bGl988YWxfv16IzEx0UhMTAxg1YF3uvdt+/btxuOPP26sX7/eyMjIMD744AOjY8eOxiWXXBLgygPr4YcfNlasWGFkZGQYmzZtMh5++GHDZrMZn376qWEY/vusKbicxgsvvGC0bdvWCAkJMfr372+sWbMm0CXVWaNGjTKio6ONkJAQ46yzzjJGjRplbN++PdBl1TlffvmlAZw0jR8/3jAM85DoRx55xIiMjDScTqcxcOBAY+vWrYEtug441ft29OhRY/DgwUbr1q2N4OBgo127dsbkyZMb/D8ZFb1fgPHGG2942hw7dsz4wx/+YLRo0cJo3Lixcc011xiZmZmBK7oOON37tmvXLuOSSy4xWrZsaTidTqNTp07GAw88YOTk5AS28AC7+eabjXbt2hkhISFG69atjYEDB3pCi2H477NmMwzDqGYPkIiIiEit0hgXERERsQwFFxEREbEMBRcRERGxDAUXERERsQwFFxEREbEMBRcRERGxDAUXERERsQwFFxEREbEMBRcRERGxDAUXERERsQwFFxEREbEMBRcRERGxjP8PUcoJovllrG8AAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot della training e validation loss\n",
        "plt.plot(training_epoch_loss, label=\"train_loss\")\n",
        "plt.plot(validation_epoch_loss, label=\"val_loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "97cb5008",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building (real column) test dataframe...: 100%|██████████| 1299/1299 [00:01<00:00, 1079.86it/s]\n",
            "building (fake column) test dataframe...: 100%|██████████| 1299/1299 [00:00<00:00, 1540.97it/s]\n"
          ]
        }
      ],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_dataset_path = os.path.join(path, \"artifact\", \"taming_transformer\", \"metadata.csv\")\n",
        "real_dataset_path = os.path.join(path, \"artifact\", \"coco\", \"metadata.csv\")\n",
        "\n",
        "# creo il dataset di test\n",
        "testList_df_path = os.path.join(\"..\", \"datasets\", \"testList.csv\")\n",
        "build.test(fake_dataset_path, real_dataset_path, testList_df_path, df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
      "metadata": {
        "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione per generare i vettori di encoding\n",
        "def get_encoding_csv(model, anc_img_names, dirFolder):\n",
        "  anc_img_names_arr = np.array(anc_img_names)\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in tqdm(anc_img_names_arr, desc=\"creating encodings...\"):\n",
        "\n",
        "      if mode == \"rgb\":\n",
        "        # serve per trovare correttamente l'immagine\n",
        "        if str(i).startswith(\"coco\"):\n",
        "          dir_folder = real_data_dir\n",
        "          a = io.imread(os.path.join(dir_folder, i))\n",
        "        else: \n",
        "          dir_folder = fake_data_dir\n",
        "          a = io.imread(os.path.join(dir_folder, i))\n",
        "\n",
        "        a = torch.from_numpy(a).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "      if mode == \"grey_scale\":\n",
        "        a = io.imread(os.path.join(dir_folder,i))\n",
        "\n",
        "        a = np.expand_dims(a, 0)\n",
        "        a = torch.from_numpy(a.astype(np.int32)) / 255.0\n",
        "        \n",
        "      a = a.to(device)\n",
        "      a_enc = model(a.unsqueeze(0))\n",
        "      encodings.append(a_enc.squeeze().cpu().detach().numpy())\n",
        "\n",
        "    encodings = np.array(encodings)\n",
        "    encodings = pd.DataFrame(encodings)\n",
        "    df_enc = pd.concat([anc_img_names, encodings], axis = 1)\n",
        "\n",
        "    return df_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
      "metadata": {
        "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
        "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "creating encodings...: 100%|██████████| 6495/6495 [02:10<00:00, 49.59it/s]\n"
          ]
        }
      ],
      "source": [
        "# per ricaricare il modello una volta allenato\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "# si creano gli embeddings che vengono memorizzati per non rifarlo ad ogni allenamento\n",
        "df_enc = get_encoding_csv(model, df[\"Anchor\"], real_data_dir)\n",
        "df_enc.to_csv(\"database.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
      "metadata": {
        "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
        "outputId": "171dab62-2058-470c-9abf-5ea9495da9b0",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\raffa\\AppData\\Local\\Temp\\ipykernel_22672\\2812054046.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  df_enc = pd.read_csv('database.csv')\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anchor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/test2017/img039109.jpg</td>\n",
              "      <td>-0.012092</td>\n",
              "      <td>0.056528</td>\n",
              "      <td>0.009512</td>\n",
              "      <td>-0.036683</td>\n",
              "      <td>-0.069287</td>\n",
              "      <td>0.009498</td>\n",
              "      <td>0.024783</td>\n",
              "      <td>-0.047827</td>\n",
              "      <td>0.080516</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012047</td>\n",
              "      <td>-0.053167</td>\n",
              "      <td>0.059217</td>\n",
              "      <td>0.068004</td>\n",
              "      <td>0.004429</td>\n",
              "      <td>0.084504</td>\n",
              "      <td>0.016910</td>\n",
              "      <td>-0.010120</td>\n",
              "      <td>-0.084367</td>\n",
              "      <td>-0.002581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img077154.jpg</td>\n",
              "      <td>-0.012305</td>\n",
              "      <td>0.056467</td>\n",
              "      <td>0.009476</td>\n",
              "      <td>-0.036752</td>\n",
              "      <td>-0.069242</td>\n",
              "      <td>0.009486</td>\n",
              "      <td>0.024863</td>\n",
              "      <td>-0.047969</td>\n",
              "      <td>0.080485</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012341</td>\n",
              "      <td>-0.053262</td>\n",
              "      <td>0.059070</td>\n",
              "      <td>0.067847</td>\n",
              "      <td>0.004716</td>\n",
              "      <td>0.084545</td>\n",
              "      <td>0.016569</td>\n",
              "      <td>-0.009919</td>\n",
              "      <td>-0.084188</td>\n",
              "      <td>-0.002534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/val2017/img159748.jpg</td>\n",
              "      <td>-0.012212</td>\n",
              "      <td>0.056655</td>\n",
              "      <td>0.009466</td>\n",
              "      <td>-0.036690</td>\n",
              "      <td>-0.069364</td>\n",
              "      <td>0.009524</td>\n",
              "      <td>0.024830</td>\n",
              "      <td>-0.047877</td>\n",
              "      <td>0.080589</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012181</td>\n",
              "      <td>-0.053162</td>\n",
              "      <td>0.059199</td>\n",
              "      <td>0.067977</td>\n",
              "      <td>0.004623</td>\n",
              "      <td>0.084466</td>\n",
              "      <td>0.016769</td>\n",
              "      <td>-0.009969</td>\n",
              "      <td>-0.084225</td>\n",
              "      <td>-0.002514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/train2017/img100036.jpg</td>\n",
              "      <td>-0.012209</td>\n",
              "      <td>0.056685</td>\n",
              "      <td>0.009573</td>\n",
              "      <td>-0.036688</td>\n",
              "      <td>-0.069461</td>\n",
              "      <td>0.009470</td>\n",
              "      <td>0.024785</td>\n",
              "      <td>-0.047900</td>\n",
              "      <td>0.080583</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012088</td>\n",
              "      <td>-0.053067</td>\n",
              "      <td>0.059193</td>\n",
              "      <td>0.068000</td>\n",
              "      <td>0.004551</td>\n",
              "      <td>0.084512</td>\n",
              "      <td>0.016887</td>\n",
              "      <td>-0.009938</td>\n",
              "      <td>-0.084210</td>\n",
              "      <td>-0.002604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/train2017/img096322.jpg</td>\n",
              "      <td>-0.012248</td>\n",
              "      <td>0.056526</td>\n",
              "      <td>0.009488</td>\n",
              "      <td>-0.036712</td>\n",
              "      <td>-0.069248</td>\n",
              "      <td>0.009492</td>\n",
              "      <td>0.024789</td>\n",
              "      <td>-0.047884</td>\n",
              "      <td>0.080484</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012212</td>\n",
              "      <td>-0.053245</td>\n",
              "      <td>0.059161</td>\n",
              "      <td>0.067884</td>\n",
              "      <td>0.004620</td>\n",
              "      <td>0.084550</td>\n",
              "      <td>0.016745</td>\n",
              "      <td>-0.009958</td>\n",
              "      <td>-0.084238</td>\n",
              "      <td>-0.002575</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 513 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Anchor         0         1         2  \\\n",
              "0   coco/coco2017/test2017/img039109.jpg -0.012092  0.056528  0.009512   \n",
              "1  coco/coco2017/train2017/img077154.jpg -0.012305  0.056467  0.009476   \n",
              "2    coco/coco2017/val2017/img159748.jpg -0.012212  0.056655  0.009466   \n",
              "3  coco/coco2017/train2017/img100036.jpg -0.012209  0.056685  0.009573   \n",
              "4  coco/coco2017/train2017/img096322.jpg -0.012248  0.056526  0.009488   \n",
              "\n",
              "          3         4         5         6         7         8  ...       502  \\\n",
              "0 -0.036683 -0.069287  0.009498  0.024783 -0.047827  0.080516  ...  0.012047   \n",
              "1 -0.036752 -0.069242  0.009486  0.024863 -0.047969  0.080485  ...  0.012341   \n",
              "2 -0.036690 -0.069364  0.009524  0.024830 -0.047877  0.080589  ...  0.012181   \n",
              "3 -0.036688 -0.069461  0.009470  0.024785 -0.047900  0.080583  ...  0.012088   \n",
              "4 -0.036712 -0.069248  0.009492  0.024789 -0.047884  0.080484  ...  0.012212   \n",
              "\n",
              "        503       504       505       506       507       508       509  \\\n",
              "0 -0.053167  0.059217  0.068004  0.004429  0.084504  0.016910 -0.010120   \n",
              "1 -0.053262  0.059070  0.067847  0.004716  0.084545  0.016569 -0.009919   \n",
              "2 -0.053162  0.059199  0.067977  0.004623  0.084466  0.016769 -0.009969   \n",
              "3 -0.053067  0.059193  0.068000  0.004551  0.084512  0.016887 -0.009938   \n",
              "4 -0.053245  0.059161  0.067884  0.004620  0.084550  0.016745 -0.009958   \n",
              "\n",
              "        510       511  \n",
              "0 -0.084367 -0.002581  \n",
              "1 -0.084188 -0.002534  \n",
              "2 -0.084225 -0.002514  \n",
              "3 -0.084210 -0.002604  \n",
              "4 -0.084238 -0.002575  \n",
              "\n",
              "[5 rows x 513 columns]"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_enc = pd.read_csv('database.csv')\n",
        "df_enc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
      "metadata": {
        "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# approssimazione della distanza, senza la radice quadrata, per fare i primi allenamenti velocemente\n",
        "def euclidean_dist(img_enc, anc_enc_arr):\n",
        "    # dist = np.sqrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
        "    dist = np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T)\n",
        "    # dist = np.sqrt(dist)\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
      "metadata": {
        "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
        "outputId": "7ff19abf-6ff7-4f31-bd3e-a07d07ca90dd",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       coco/coco2017/train2017/img041598.jpg\n",
            "1       coco/coco2017/train2017/img046852.jpg\n",
            "2       coco/coco2017/train2017/img079805.jpg\n",
            "3       coco/coco2017/train2017/img146891.jpg\n",
            "4       coco/coco2017/train2017/img106948.jpg\n",
            "                        ...                  \n",
            "1294    coco/coco2017/train2017/img138878.jpg\n",
            "1295     coco/coco2017/test2017/img026299.jpg\n",
            "1296    coco/coco2017/train2017/img044314.jpg\n",
            "1297    coco/coco2017/train2017/img068873.jpg\n",
            "1298    coco/coco2017/train2017/img076049.jpg\n",
            "Name: real, Length: 1299, dtype: object\n",
            "2598\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real</th>\n",
              "      <th>fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/train2017/img041598.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/458/img01999...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img046852.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img048677.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/train2017/img079805.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img000449.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/train2017/img146891.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img026921.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/train2017/img106948.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/982/img04907...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    real  \\\n",
              "0  coco/coco2017/train2017/img041598.jpg   \n",
              "1  coco/coco2017/train2017/img046852.jpg   \n",
              "2  coco/coco2017/train2017/img079805.jpg   \n",
              "3  coco/coco2017/train2017/img146891.jpg   \n",
              "4  coco/coco2017/train2017/img106948.jpg   \n",
              "\n",
              "                                                fake  \n",
              "0  tt-cc/cin_k600_p1.0_a0.05_fid5.20/458/img01999...  \n",
              "1        tt-ffhq/ffhq_k300_p1.0_fid9.6/img048677.jpg  \n",
              "2        tt-ffhq/ffhq_k300_p1.0_fid9.6/img000449.jpg  \n",
              "3        tt-ffhq/ffhq_k300_p1.0_fid9.6/img026921.jpg  \n",
              "4  tt-cc/cin_k600_p1.0_a0.05_fid5.20/982/img04907...  "
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = os.path.join(Path(os.getcwd()).parent, \"datasets\", \"testList.csv\")\n",
        "df = pd.read_csv(path)\n",
        "\n",
        "print(df[\"real\"])\n",
        "print(df.size)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
      "metadata": {
        "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_image_embeddings(img, model):\n",
        "    if mode == \"rgb\":\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "    if mode == \"grey_scale\":\n",
        "        img = np.expand_dims(img, 0)\n",
        "        img = torch.from_numpy(img) / 255\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = img.to(device)\n",
        "        img_enc = model(img.unsqueeze(0))\n",
        "        img_enc = img_enc.detach().cpu().numpy()\n",
        "        img_enc = np.array(img_enc)\n",
        "\n",
        "    return img_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
      "metadata": {
        "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def search_in_database(img_enc, database):\n",
        "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
        "    anc_img_names = database[\"Anchor\"]\n",
        "\n",
        "    distance = []\n",
        "    for i in range(anc_enc_arr.shape[0]):\n",
        "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
        "        distance = np.append(distance, dist)\n",
        "\n",
        "    closest_idx = np.argsort(distance)\n",
        "\n",
        "    return database[\"Anchor\"][closest_idx[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
      "metadata": {
        "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
        "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1299, 2)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# DataTestReal = 'C:/Users/polsi/Desktop/Lavori/DeepFake/Datasets/Artifact/cycle_gan/st/test/'\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "real_dataset_dir = os.path.join(path, \"artifact\", \"coco\")\n",
        "fake_dataset_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "temp_df = df\n",
        "temp_df.head()\n",
        "temp_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
      "metadata": {
        "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on fake images...: 1299it [04:41,  4.61it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i fake\n",
        "current_test = \"fake\"\n",
        "database = df_enc\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for index, row in tqdm(temp_df.iterrows(), desc=\"testing on fake images...\"):\n",
        "    path = os.path.join(fake_dataset_dir, row[current_test])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = get_image_embeddings(img, model)\n",
        "\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "\n",
        "    if mode == \"rgb\":\n",
        "        if str(closest_label).startswith(\"coco\"):\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n",
        "\n",
        "    if mode == \"grey_scale\": \n",
        "        if \"real\" in closest_label:\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
      "metadata": {
        "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1299\n",
            "['fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
      "metadata": {
        "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on real images...: 1299it [04:51,  4.46it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i real\n",
        "current_test = \"real\"\n",
        "database = df_enc\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for index, row in tqdm(temp_df.iterrows(), desc=\"testing on real images...\"):\n",
        "    path = os.path.join(real_dataset_dir, row[current_test])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "\n",
        "    img_enc = get_image_embeddings(img, model)\n",
        "\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "        if str(closest_label).startswith(\"coco\"):\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n",
        "\n",
        "    if mode == \"grey_scale\":\n",
        "        if \"real\" in closest_label:\n",
        "            y_pred.append(\"real\")\n",
        "        else:\n",
        "            y_pred.append(\"fake\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "4c465bfd-18ad-4750-b689-739b712185ab",
      "metadata": {
        "id": "4c465bfd-18ad-4750-b689-739b712185ab",
        "outputId": "e974c712-91fb-4fae-c589-85e08a50fb77",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2598\n",
            "['fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "85706e81-3068-4150-9773-320a8aa98c69",
      "metadata": {
        "id": "85706e81-3068-4150-9773-320a8aa98c69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1299,)\n",
            "(1299,)\n",
            "(2598,)\n",
            "[[ 183 1116]\n",
            " [ 159 1140]]\n"
          ]
        }
      ],
      "source": [
        "# creo i vettori di ground truth\n",
        "int(len(df) / 100 * 20)\n",
        "\n",
        "y_true = np.array([\"fake\"] * len(valid_df))\n",
        "print(y_true.shape)\n",
        "\n",
        "temp = np.array([\"real\"] * len(valid_df))\n",
        "print(temp.shape)\n",
        "\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "print(y_true.shape)\n",
        "\n",
        "# calcolo la matrice di confusione (quella di scikit-learn dispone i risultati come nella cella di sotto)\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
      "metadata": {
        "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Accuracy': 50.92, 'Precision': 50.529999999999994, 'Recall': 87.76, 'Specificity': 14.0878, 'F1 Score': 64.1335}\n"
          ]
        }
      ],
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# metriche\n",
        "accuracy = round((tp + tn) / (tp + tn + fp + fn), 4) * 100\n",
        "precision = round((tp) / (tp + fp), 4) * 100\n",
        "recall = round((tp) / (tp + fn), 4) * 100\n",
        "specificity = round((tn) / (tn + fp) * 100, 4)\n",
        "f1_score = round((2 * precision * recall) / (precision + recall), 4)\n",
        "\n",
        "print({\"Accuracy\":accuracy, \"Precision\":precision, \"Recall\":recall, \"Specificity\":specificity, \"F1 Score\":f1_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb6aac2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si salvano i risultati in un file .csv\n",
        "df_results = pd.DataFrame(columns=[\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1 Score\"])\n",
        "df_results.loc[0] = [accuracy, precision, recall, specificity, f1_score]\n",
        "\n",
        "# si differenziano i risultati in base al tipo di immagini e dataset usati\n",
        "dataset = fake_data_dir.split(\"\\\\\")[-1]\n",
        "path = os.path.join(\"..\", \"results\", \"rgb_semi_hard\", \"siamese_\" + mode + \"_\" + \"semi_hard_online\" + dataset + \"_results.csv\")\n",
        "\n",
        "df_results.to_csv(path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fvab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
