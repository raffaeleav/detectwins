{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "7046cde1",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "# si aggiunge al path la cartella utils per avere visibilità del module\n",
        "module_path = Path(os.getcwd()).parent.parent\n",
        "module_path = os.path.join(module_path, \"project-detective\")\n",
        "\n",
        "sys.path.append(module_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
      "metadata": {
        "id": "629f9a2a-51d3-4851-b6f2-a542601bb67e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "import timm\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import utils.mining as mining\n",
        "import utils.datasets as build\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torch import nn\n",
        "from tqdm import tqdm\n",
        "from skimage import io\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_metric_learning import miners, losses\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
      "metadata": {
        "id": "0fb6e0d0-b8cc-44b8-a8ac-17934de905f6",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# serve per ricaricare il codice modificato\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f02ae726-f601-4b51-a949-71a5464ec779",
      "metadata": {
        "id": "f02ae726-f601-4b51-a949-71a5464ec779",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# configurazione\n",
        "batch_size=32\n",
        "lr=0.001\n",
        "epochs=30\n",
        "device=\"cuda\"\n",
        "\n",
        "# per far funzionare il modello su immagini rgb o in scala di grigi (per usare fourier)\n",
        "mode=\"fourier\"\n",
        "\n",
        "# margin per semi-hard mining con modello pre-allenato\n",
        "margin=0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "1bd2e0e4",
      "metadata": {},
      "outputs": [],
      "source": [
        "# directory da dove vengono prelevate le immagini\n",
        "path = Path(os.getcwd()).parent.parent\n",
        "\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
      "metadata": {
        "id": "aa3dfd88-2685-4ef3-8cac-2e2c85c6f0fe",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# carica le immagini nel dataset\n",
        "class ApnDataset(Dataset):\n",
        "\n",
        "  def __init__(self, df):\n",
        "    self.df = df\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.df)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    row = self.df.iloc[idx]\n",
        "\n",
        "    # le immagini Anchor sono memorizzate in due dataset diversi\n",
        "    if str(row.Anchor).startswith(\"coco\"):\n",
        "      a_img = io.imread(os.path.join(real_data_dir, row.Anchor))\n",
        "      p_img = io.imread(os.path.join(real_data_dir, row.Positive))\n",
        "      n_img = io.imread(os.path.join(fake_data_dir, row.Negative))\n",
        "\n",
        "      a_label = 0\n",
        "      p_label = 0\n",
        "      n_label = 1\n",
        "\n",
        "    else:\n",
        "      a_img = io.imread(os.path.join(fake_data_dir, row.Anchor))\n",
        "      p_img = io.imread(os.path.join(fake_data_dir, row.Positive))\n",
        "      n_img = io.imread(os.path.join(real_data_dir, row.Negative))\n",
        "\n",
        "      a_label = 1\n",
        "      p_label = 1\n",
        "      n_label = 0\n",
        "    \n",
        "    if mode == \"rgb\":\n",
        "      # normalizzazione per immagini in rgb \n",
        "      a_img = torch.from_numpy(a_img).permute(2, 0, 1) / 255.0\n",
        "      p_img = torch.from_numpy(p_img).permute(2, 0, 1) / 255.0\n",
        "      n_img = torch.from_numpy(n_img).permute(2, 0, 1) / 255.0\n",
        "\n",
        "      a_label = torch.tensor(a_label)\n",
        "      p_label = torch.tensor(p_label)\n",
        "      n_label = torch.tensor(n_label)\n",
        "\n",
        "    if mode == \"fourier\":\n",
        "      a_img = rgb2gray(a_img)\n",
        "      p_img = rgb2gray(p_img)\n",
        "      n_img = rgb2gray(n_img)\n",
        "\n",
        "      a_img = np.expand_dims(a_img, 0)\n",
        "      p_img = np.expand_dims(p_img, 0)\n",
        "      n_img = np.expand_dims(n_img, 0)\n",
        "      \n",
        "      a_img = torch.from_numpy(a_img) / 255.0\n",
        "      p_img = torch.from_numpy(p_img) / 255.0\n",
        "      n_img = torch.from_numpy(n_img) / 255.0\n",
        "      \n",
        "      \"\"\"\n",
        "      # trasformata di fourier\n",
        "      a_img = np.fft.fft2(a_img)\n",
        "      p_img = np.fft.fft2(p_img)\n",
        "      n_img = np.fft.fft2(n_img)\n",
        "\n",
        "      fft_img = np.log(np.abs(fft_img))\n",
        "      \"\"\"\n",
        "\n",
        "    # A_img = torch.from_numpy(A_img.astype(np.int32)) / 65536.0\n",
        "    # P_img = torch.from_numpy(P_img.astype(np.int32)) / 65536.0\n",
        "    # N_img = torch.from_numpy(N_img.astype(np.int32)) / 65536.0\n",
        "\n",
        "    return a_img, p_img, n_img, a_label, p_label, n_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
      "metadata": {
        "id": "477f08a1-15bb-471f-974c-23c6bef4ece3",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# classe per caricare il modello di rete neurale direttamente dalle repository online\n",
        "class ApnModel(nn.Module):\n",
        "\n",
        "  # size del vettore di embedding\n",
        "  def __init__(self, emb_size=512):\n",
        "    super(ApnModel, self).__init__()\n",
        "\n",
        "    # caricamento del modello, in questo caso efficientnet b0 (architettura più leggera della famiglia)\n",
        "    self.efficientnet = timm.create_model(\"tf_efficientnetv2_b1\", pretrained=False)\n",
        "    self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "  def forward(self, images):\n",
        "    embeddings = self.efficientnet(images)\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "53d21354",
      "metadata": {},
      "outputs": [],
      "source": [
        "# classe del modello che genera gli embedding per applicare il semi-hard mining\n",
        "class EmbModel(nn.Module):\n",
        "\n",
        "    # size del vettore di embedding\n",
        "    def __init__(self, emb_size = 512):\n",
        "        super(EmbModel, self).__init__()\n",
        "\n",
        "        # gli embedding vengono creati con un modello preallenato (risultato più efficace in test precedenti)\n",
        "        self.efficientnet = timm.create_model(\"tf_efficientnetv2_b0\", pretrained=True)\n",
        "        self.efficientnet.classifier = nn.Linear(in_features=self.efficientnet.classifier.in_features, out_features=emb_size)\n",
        "\n",
        "    def forward(self, images):\n",
        "        embeddings = self.efficientnet(images)\n",
        "        return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3c37a66e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# funzione per creare embeddings che sarranno sottoposti a semi-hard mining\n",
        "def create_embeddings(model, dataloader, device): \n",
        "    # off dropout\n",
        "    model.eval()\n",
        "\n",
        "    list_df = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for a, p, n, al, pl, nl in tqdm(dataloader, desc=\"creating embeddings...\"):\n",
        "            a, p, n = a.float().to(device), p.float().to(device), n.float().to(device)\n",
        "\n",
        "            temp_df_embs = pd.DataFrame(columns=[\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"])\n",
        "\n",
        "            a_embs = model(a)\n",
        "            p_embs = model(p)\n",
        "            n_embs = model(n)\n",
        "            \n",
        "            # la batch size può variare, perciò ci si basa sulla lunghezza del tensore\n",
        "            batch_size = len(a_embs)\n",
        "            \n",
        "            # ad ogni batch corrisponde un dataframe\n",
        "            for i in range(batch_size): \n",
        "                # si serializzano gli array np in stringhe in modo da memorizzarli nelle celle del datagrame\n",
        "                a, p, n = a_embs[i].cpu().numpy(), p_embs[i].cpu().numpy(), n_embs[i].cpu().numpy()\n",
        "                a, p, n = np.array2string(a, separator=','), np.array2string(p, separator=','), np.array2string(n, separator=',')\n",
        "                \n",
        "                temp_df_embs.loc[i] = [\n",
        "                    a, \n",
        "                    p, \n",
        "                    n\n",
        "                ]\n",
        "            \n",
        "            list_df.append(temp_df_embs)\n",
        "\n",
        "    # concatenazione di tutti i dataframe\n",
        "    df_embs = pd.concat(list_df)\n",
        "\n",
        "    return df_embs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "4653903a",
      "metadata": {},
      "outputs": [],
      "source": [
        "emb_model = EmbModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"fourier\":\n",
        "    emb_model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "emb_model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4c584653",
      "metadata": {},
      "outputs": [],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_dataset_path = os.path.join(path, \"artifact\", \"taming_transformer\", \"metadata.csv\")\n",
        "real_dataset_path = os.path.join(path, \"artifact\", \"coco\", \"metadata.csv\")\n",
        "\n",
        "df_out_path = os.path.join(\"..\", \"datasets\", \"out.csv\")\n",
        "df_out = pd.read_csv(df_out_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "012654d0",
      "metadata": {},
      "outputs": [],
      "source": [
        "apn_dataset = ApnDataset(df_out)\n",
        "dataloader = DataLoader(apn_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "22b9da75",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "creating embeddings...:   0%|          | 0/1563 [00:00<?, ?it/s]c:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "creating embeddings...: 100%|█████████▉| 1562/1563 [1:26:46<00:01,  1.95s/it]c:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "creating embeddings...: 100%|██████████| 1563/1563 [1:26:47<00:00,  3.33s/it]\n"
          ]
        }
      ],
      "source": [
        "emb_csv_path = os.path.join(\"..\", \"notebooks\", \"embeddings.csv\")\n",
        "\n",
        "# si controlla che siano stati già creati gli embeddings\n",
        "if not Path(emb_csv_path).is_file():\n",
        "    df_emb = create_embeddings(emb_model, dataloader, device)\n",
        "    df_emb.to_csv(emb_csv_path, index=False)\n",
        "\n",
        "df_emb = pd.read_csv(emb_csv_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "41b31e13",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dataset size after semi-hard mining: 25090\n"
          ]
        }
      ],
      "source": [
        "# si concatenano i dataframe delle immagini e degli embeddings sulle colonne per poter filtrare le righe in logica di semi-hard mining\n",
        "df_out = pd.concat([df_out, df_emb], axis=1)\n",
        "\n",
        "# offline semi-hard mining dei triplets\n",
        "df_out = mining.offline_semi_hard_mining(df_out, margin)\n",
        "df_out = df_out.drop([\"Anchor_embs\", \"Positive_embs\", \"Negative_embs\"], axis=1)\n",
        "\n",
        "print(f\"dataset size after semi-hard mining: {len(df_out)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
      "metadata": {
        "id": "28f6fa06-7584-4e35-844b-a1831a13c172",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di train\n",
        "def train_fn(model, dataloader, optimizer, criterion, miner):\n",
        "  # on dropout \n",
        "  model.train()\n",
        "  \n",
        "  total_loss = 0.0\n",
        "\n",
        "  for a, p, n, al, pl, nl in tqdm(dataloader, desc=\"model training...\"):\n",
        "    a, p, n = a.float().to(device), p.float().to(device), n.float().to(device)\n",
        "    al, pl, nl = al.to(device), pl.to(device), nl.to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # qui vengono creati gli embeddings, le cui distanze verranno calcolate dopo\n",
        "    a_embs = model(a)\n",
        "    p_embs = model(p)\n",
        "    n_embs = model(n)\n",
        "\n",
        "    # per usare l'ohm si devono concatenare tutti i tipi di immagine, i triplet verranno creati nella funzione di loss\n",
        "    embeddings = torch.cat((a_embs, p_embs, n_embs), axis=0)\n",
        "    labels = torch.cat((al, pl, nl), axis=0)\n",
        "\n",
        "    # online hard mining prima del calcolo della loss\n",
        "    miner_output = miner(embeddings, labels)\n",
        "    loss = criterion(embeddings, labels, miner_output)\n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "  return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "19ec6d56-9168-4980-9164-62660537f1ff",
      "metadata": {
        "id": "19ec6d56-9168-4980-9164-62660537f1ff",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione di evaluation\n",
        "def eval_fn(model, dataloader, criterion, miner):\n",
        "  # off dropout\n",
        "  model.eval() \n",
        "  \n",
        "  total_loss = 0.0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for a, p, n, al, pl, nl in tqdm(dataloader, desc=\"model validating...\"):\n",
        "      a, p, n = a.float().to(device), p.float().to(device), n.float().to(device)\n",
        "      al, pl, nl = al.to(device), pl.to(device), nl.to(device)\n",
        "\n",
        "      a_embs = model(a)\n",
        "      p_embs = model(p)\n",
        "      n_embs = model(n)\n",
        "      \n",
        "      embeddings = torch.cat((a_embs, p_embs, n_embs), axis=0)\n",
        "      labels = torch.cat((al, pl, nl), axis=0)\n",
        "      \n",
        "      miner_output = miner(embeddings, labels)\n",
        "      loss = criterion(embeddings, labels, miner_output)\n",
        "\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "c2080916",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ApnModel(\n",
              "  (efficientnet): EfficientNet(\n",
              "    (conv_stem): Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNormAct2d(\n",
              "      32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (blocks): Sequential(\n",
              "      (0): Sequential(\n",
              "        (0): ConvBnAct(\n",
              "          (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): ConvBnAct(\n",
              "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (1): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(16, 64, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): EdgeResidual(\n",
              "          (conv_exp): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (2): Sequential(\n",
              "        (0): EdgeResidual(\n",
              "          (conv_exp): Conv2dSame(32, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): EdgeResidual(\n",
              "          (conv_exp): Conv2d(48, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): Identity()\n",
              "          (conv_pwl): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(48, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(192, 192, kernel_size=(3, 3), stride=(2, 2), groups=192, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(192, 12, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(12, 192, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(384, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 384, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (4): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            576, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(576, 24, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(24, 576, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(576, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "      (5): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2dSame(672, 672, kernel_size=(3, 3), stride=(2, 2), groups=672, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (1): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (2): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (3): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (4): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (5): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (6): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (7): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "        (8): InvertedResidual(\n",
              "          (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn1): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
              "          (bn2): BatchNormAct2d(\n",
              "            1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): SiLU(inplace=True)\n",
              "          )\n",
              "          (se): SqueezeExcite(\n",
              "            (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (act1): SiLU(inplace=True)\n",
              "            (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
              "            (gate): Sigmoid()\n",
              "          )\n",
              "          (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (bn3): BatchNormAct2d(\n",
              "            192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "            (drop): Identity()\n",
              "            (act): Identity()\n",
              "          )\n",
              "          (drop_path): Identity()\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (conv_head): Conv2d(192, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (bn2): BatchNormAct2d(\n",
              "      1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True\n",
              "      (drop): Identity()\n",
              "      (act): SiLU(inplace=True)\n",
              "    )\n",
              "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Flatten(start_dim=1, end_dim=-1))\n",
              "    (classifier): Linear(in_features=1280, out_features=512, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = ApnModel()\n",
        "\n",
        "# per processare le immagini in scala di grigi per fare fourier serve una CNN 2D\n",
        "if mode == \"fourier\":\n",
        "    model.efficientnet.conv_stem = nn.Conv2d(1, 32, 3, 2, 1, bias=False)\n",
        "\n",
        "model.to(device);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "311bed90",
      "metadata": {},
      "outputs": [],
      "source": [
        "# split del nuovo dataframe\n",
        "train_df, valid_df = train_test_split(df_out, test_size=0.20, random_state=42)\n",
        "\n",
        "trainset = ApnDataset(train_df)\n",
        "validset = ApnDataset(valid_df)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
        "validloader = DataLoader(validset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
      "metadata": {
        "id": "f270e395-4b3f-4907-8ae7-a33043da0f80",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# triplet loss, miner (per online hard mining) e adam\n",
        "criterion = losses.TripletMarginLoss(triplets_per_anchor=\"all\")\n",
        "miner = miners.TripletMarginMiner(margin=margin, type_of_triplets=\"hard\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
      "metadata": {
        "id": "ac5b64b5-d28c-47bc-bbbf-acd4960e34ef",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|█████████▉| 627/628 [25:01<00:02,  2.27s/it]c:\\Users\\raffa\\anaconda3\\envs\\fvab\\lib\\site-packages\\torch\\nn\\modules\\conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ..\\aten\\src\\ATen\\native\\cudnn\\Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "model training...: 100%|██████████| 628/628 [25:02<00:00,  2.39s/it]\n",
            "model validating...: 100%|██████████| 157/157 [03:30<00:00,  1.34s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 1, train_loss: 0.052693037304339135, valid_loss: 0.049941900476908226\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:28<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:12<00:00,  2.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 2, train_loss: 0.05011539342131015, valid_loss: 0.049971405013351684\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:25<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:09<00:00,  2.26it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 3, train_loss: 0.050068830756862075, valid_loss: 0.049974700163124476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:24<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 4, train_loss: 0.050064718949899174, valid_loss: 0.049973285074826256\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:28<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:28<00:00,  1.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 5, train_loss: 0.05006518052404473, valid_loss: 0.049965964025183086\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:26<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:11<00:00,  2.19it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 6, train_loss: 0.05006702070474435, valid_loss: 0.04995967922316995\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:25<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:09<00:00,  2.25it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 7, train_loss: 0.0500688411912341, valid_loss: 0.0499550716559978\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:24<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:07<00:00,  2.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 8, train_loss: 0.05007156055824012, valid_loss: 0.04995291205538306\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:21<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:29<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 9, train_loss: 0.050073952835266757, valid_loss: 0.0499233155256244\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:24<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:11<00:00,  2.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 10, train_loss: 0.0500770041090288, valid_loss: 0.04993265561142545\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:19<00:00,  1.65s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:08<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 11, train_loss: 0.05007959162567262, valid_loss: 0.04990066469285139\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:21<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:07<00:00,  2.32it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 12, train_loss: 0.050082212420785505, valid_loss: 0.049863678610818404\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:22<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:31<00:00,  1.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 13, train_loss: 0.0500849436339774, valid_loss: 0.04984023467085923\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:22<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:12<00:00,  2.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 14, train_loss: 0.050087849111266576, valid_loss: 0.049814678277749165\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:22<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:08<00:00,  2.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 15, train_loss: 0.05009073026739298, valid_loss: 0.04987489548363504\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:23<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:07<00:00,  2.31it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 16, train_loss: 0.05009197733798035, valid_loss: 0.04984222233864912\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:24<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:31<00:00,  1.72it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 17, train_loss: 0.05009326222500983, valid_loss: 0.049830150689668715\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:24<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:13<00:00,  2.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 18, train_loss: 0.0500952966902761, valid_loss: 0.04983195695717623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:23<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:08<00:00,  2.28it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 19, train_loss: 0.05009633984274355, valid_loss: 0.049767085653581435\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:25<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:07<00:00,  2.34it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 20, train_loss: 0.050098391967546785, valid_loss: 0.04982695768877959\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:24<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:28<00:00,  1.77it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 21, train_loss: 0.050099381714299986, valid_loss: 0.049766629886854985\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:28<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:12<00:00,  2.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 22, train_loss: 0.050099679061276894, valid_loss: 0.04974562871702917\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:26<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:08<00:00,  2.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 23, train_loss: 0.05010108631934709, valid_loss: 0.04965402494380428\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:29<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:06<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 24, train_loss: 0.05010193419660543, valid_loss: 0.04966116319321523\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:30<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:29<00:00,  1.75it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 25, train_loss: 0.050103206163758685, valid_loss: 0.049643391114511305\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:27<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:11<00:00,  2.21it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 26, train_loss: 0.0501026465990551, valid_loss: 0.04964625833045905\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:27<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:08<00:00,  2.29it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "successful weights saving...\n",
            "epochs: 27, train_loss: 0.05010453000024056, valid_loss: 0.0495700440636486\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:28<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:06<00:00,  2.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 28, train_loss: 0.05010323145183598, valid_loss: 0.04957973631988665\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:23<00:00,  1.66s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:30<00:00,  1.73it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 29, train_loss: 0.05010577788351068, valid_loss: 0.049623602206350134\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "model training...: 100%|██████████| 628/628 [17:27<00:00,  1.67s/it]\n",
            "model validating...: 100%|██████████| 157/157 [01:11<00:00,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs: 30, train_loss: 0.05010809881055051, valid_loss: 0.049570569519404396\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# training\n",
        "best_valid_loss = np.Inf\n",
        "\n",
        "training_epoch_loss = []\n",
        "validation_epoch_loss = []\n",
        "\n",
        "for i in range(epochs):\n",
        "  train_loss = train_fn(model, trainloader, optimizer, criterion, miner)\n",
        "  valid_loss = eval_fn(model, validloader, criterion)\n",
        "\n",
        "  training_epoch_loss.append(train_loss)\n",
        "  validation_epoch_loss.append(valid_loss)\n",
        "\n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), \"best_model.pt\")\n",
        "    best_valid_loss = valid_loss\n",
        "    print(\"successful weights saving...\")\n",
        "\n",
        "  print(f\"epochs: {i+1}, train_loss: {train_loss}, valid_loss: {valid_loss}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "9ca40d35",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function matplotlib.pyplot.show(close=None, block=None)>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plot della training e validation loss\n",
        "plt.plot(training_epoch_loss, label=\"train_loss\")\n",
        "plt.plot(validation_epoch_loss, label=\"val_loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.show"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
      "metadata": {
        "id": "9fe76305-8f2d-4159-a8e0-a57cb85b525e",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# funzione per generare i vettori di encoding\n",
        "def get_encoding_csv(model, anc_img_names, dir_folder):\n",
        "  anc_img_names_arr = np.array(anc_img_names)\n",
        "  encodings = []\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for i in tqdm(anc_img_names_arr, desc=\"creating encodings...\"):\n",
        "      if str(i).startswith(\"coco\"):\n",
        "        dir_folder = real_data_dir\n",
        "      else: \n",
        "        dir_folder = fake_data_dir\n",
        "      \n",
        "      a = io.imread(os.path.join(dir_folder, i))\n",
        "\n",
        "      if mode == \"rgb\":\n",
        "        a = torch.from_numpy(a).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "      if mode == \"fourier\":\n",
        "        a = rgb2gray(a)\n",
        "        a = np.expand_dims(a, 0)\n",
        "        a = torch.from_numpy(a.astype(np.int32)) / 255.0\n",
        "        \n",
        "      a = a.to(device)\n",
        "      a_enc = model(a.unsqueeze(0))\n",
        "      encodings.append(a_enc.squeeze().cpu().detach().numpy())\n",
        "\n",
        "    encodings = np.array(encodings)\n",
        "    encodings = pd.DataFrame(encodings)\n",
        "    anc_img_names_df = pd.DataFrame(anc_img_names_arr, columns=['Anchor'])\n",
        "    df_enc = pd.concat([anc_img_names_df, encodings], axis=1)\n",
        "\n",
        "    return df_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
      "metadata": {
        "id": "087c6f6f-3d8d-437f-ab31-ce2c3a1c239c",
        "outputId": "10e29b3a-1d0f-41bb-e9a2-21aec49dac69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "creating encodings...: 100%|██████████| 25090/25090 [13:49<00:00, 30.25it/s]\n"
          ]
        }
      ],
      "source": [
        "# per ricaricare il modello una volta allenato\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "\n",
        "# si creano gli embeddings che vengono memorizzati per non rifarlo ad ogni allenamento\n",
        "df_enc = get_encoding_csv(model, df_out[\"Anchor\"], real_data_dir)\n",
        "df_enc.to_csv(\"database.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
      "metadata": {
        "id": "5a1096d8-a3dc-46bd-bb54-ed3debea3c57",
        "outputId": "171dab62-2058-470c-9abf-5ea9495da9b0",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Anchor</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>...</th>\n",
              "      <th>502</th>\n",
              "      <th>503</th>\n",
              "      <th>504</th>\n",
              "      <th>505</th>\n",
              "      <th>506</th>\n",
              "      <th>507</th>\n",
              "      <th>508</th>\n",
              "      <th>509</th>\n",
              "      <th>510</th>\n",
              "      <th>511</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/train2017/img087583.jpg</td>\n",
              "      <td>-5.097686</td>\n",
              "      <td>9.781346</td>\n",
              "      <td>-20.147896</td>\n",
              "      <td>-11.339385</td>\n",
              "      <td>-15.215671</td>\n",
              "      <td>6.559587</td>\n",
              "      <td>3.023787</td>\n",
              "      <td>26.299604</td>\n",
              "      <td>-23.619465</td>\n",
              "      <td>...</td>\n",
              "      <td>9.677806</td>\n",
              "      <td>-5.655154</td>\n",
              "      <td>-6.344949</td>\n",
              "      <td>-14.255855</td>\n",
              "      <td>13.303577</td>\n",
              "      <td>5.884014</td>\n",
              "      <td>-3.186222</td>\n",
              "      <td>6.744554</td>\n",
              "      <td>-16.202831</td>\n",
              "      <td>-3.234488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img058154.jpg</td>\n",
              "      <td>-5.116282</td>\n",
              "      <td>9.795825</td>\n",
              "      <td>-20.226665</td>\n",
              "      <td>-11.389508</td>\n",
              "      <td>-15.259982</td>\n",
              "      <td>6.601694</td>\n",
              "      <td>3.051465</td>\n",
              "      <td>26.386526</td>\n",
              "      <td>-23.716133</td>\n",
              "      <td>...</td>\n",
              "      <td>9.717127</td>\n",
              "      <td>-5.676010</td>\n",
              "      <td>-6.346604</td>\n",
              "      <td>-14.313428</td>\n",
              "      <td>13.369785</td>\n",
              "      <td>5.898062</td>\n",
              "      <td>-3.216838</td>\n",
              "      <td>6.772049</td>\n",
              "      <td>-16.266815</td>\n",
              "      <td>-3.238270</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/train2017/img109565.jpg</td>\n",
              "      <td>-5.129780</td>\n",
              "      <td>9.824825</td>\n",
              "      <td>-20.268770</td>\n",
              "      <td>-11.419039</td>\n",
              "      <td>-15.299984</td>\n",
              "      <td>6.612909</td>\n",
              "      <td>3.061139</td>\n",
              "      <td>26.449583</td>\n",
              "      <td>-23.758470</td>\n",
              "      <td>...</td>\n",
              "      <td>9.738164</td>\n",
              "      <td>-5.695026</td>\n",
              "      <td>-6.368527</td>\n",
              "      <td>-14.353375</td>\n",
              "      <td>13.408033</td>\n",
              "      <td>5.914445</td>\n",
              "      <td>-3.220373</td>\n",
              "      <td>6.778273</td>\n",
              "      <td>-16.303568</td>\n",
              "      <td>-3.251514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/test2017/img012686.jpg</td>\n",
              "      <td>-5.111303</td>\n",
              "      <td>9.820746</td>\n",
              "      <td>-20.225628</td>\n",
              "      <td>-11.388514</td>\n",
              "      <td>-15.258848</td>\n",
              "      <td>6.589541</td>\n",
              "      <td>3.044367</td>\n",
              "      <td>26.401842</td>\n",
              "      <td>-23.705994</td>\n",
              "      <td>...</td>\n",
              "      <td>9.720070</td>\n",
              "      <td>-5.674737</td>\n",
              "      <td>-6.362050</td>\n",
              "      <td>-14.311926</td>\n",
              "      <td>13.370272</td>\n",
              "      <td>5.900932</td>\n",
              "      <td>-3.202605</td>\n",
              "      <td>6.769156</td>\n",
              "      <td>-16.270447</td>\n",
              "      <td>-3.245677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/test2017/img009328.jpg</td>\n",
              "      <td>-5.097686</td>\n",
              "      <td>9.781346</td>\n",
              "      <td>-20.147896</td>\n",
              "      <td>-11.339385</td>\n",
              "      <td>-15.215671</td>\n",
              "      <td>6.559587</td>\n",
              "      <td>3.023787</td>\n",
              "      <td>26.299604</td>\n",
              "      <td>-23.619465</td>\n",
              "      <td>...</td>\n",
              "      <td>9.677806</td>\n",
              "      <td>-5.655154</td>\n",
              "      <td>-6.344949</td>\n",
              "      <td>-14.255855</td>\n",
              "      <td>13.303577</td>\n",
              "      <td>5.884014</td>\n",
              "      <td>-3.186222</td>\n",
              "      <td>6.744554</td>\n",
              "      <td>-16.202831</td>\n",
              "      <td>-3.234488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 513 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Anchor         0         1          2  \\\n",
              "0  coco/coco2017/train2017/img087583.jpg -5.097686  9.781346 -20.147896   \n",
              "1  coco/coco2017/train2017/img058154.jpg -5.116282  9.795825 -20.226665   \n",
              "2  coco/coco2017/train2017/img109565.jpg -5.129780  9.824825 -20.268770   \n",
              "3   coco/coco2017/test2017/img012686.jpg -5.111303  9.820746 -20.225628   \n",
              "4   coco/coco2017/test2017/img009328.jpg -5.097686  9.781346 -20.147896   \n",
              "\n",
              "           3          4         5         6          7          8  ...  \\\n",
              "0 -11.339385 -15.215671  6.559587  3.023787  26.299604 -23.619465  ...   \n",
              "1 -11.389508 -15.259982  6.601694  3.051465  26.386526 -23.716133  ...   \n",
              "2 -11.419039 -15.299984  6.612909  3.061139  26.449583 -23.758470  ...   \n",
              "3 -11.388514 -15.258848  6.589541  3.044367  26.401842 -23.705994  ...   \n",
              "4 -11.339385 -15.215671  6.559587  3.023787  26.299604 -23.619465  ...   \n",
              "\n",
              "        502       503       504        505        506       507       508  \\\n",
              "0  9.677806 -5.655154 -6.344949 -14.255855  13.303577  5.884014 -3.186222   \n",
              "1  9.717127 -5.676010 -6.346604 -14.313428  13.369785  5.898062 -3.216838   \n",
              "2  9.738164 -5.695026 -6.368527 -14.353375  13.408033  5.914445 -3.220373   \n",
              "3  9.720070 -5.674737 -6.362050 -14.311926  13.370272  5.900932 -3.202605   \n",
              "4  9.677806 -5.655154 -6.344949 -14.255855  13.303577  5.884014 -3.186222   \n",
              "\n",
              "        509        510       511  \n",
              "0  6.744554 -16.202831 -3.234488  \n",
              "1  6.772049 -16.266815 -3.238270  \n",
              "2  6.778273 -16.303568 -3.251514  \n",
              "3  6.769156 -16.270447 -3.245677  \n",
              "4  6.744554 -16.202831 -3.234488  \n",
              "\n",
              "[5 rows x 513 columns]"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_enc = pd.read_csv('database.csv')\n",
        "df_enc.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
      "metadata": {
        "id": "ea4d49ef-7e4b-4a09-a188-d6afa1fc273d",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# approssimazione della distanza, senza la radice quadrata, per fare i primi allenamenti velocemente\n",
        "def euclidean_dist(img_enc, anc_enc_arr):\n",
        "    # dist = np.sqrt(np.dot(img_enc-anc_enc_arr, (img_enc- anc_enc_arr).T))\n",
        "    dist = np.dot(img_enc - anc_enc_arr, (img_enc - anc_enc_arr).T)\n",
        "    # dist = np.sqrt(dist)\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
      "metadata": {
        "id": "38e0d751-6559-43b8-94f1-eab11f754bdd",
        "outputId": "7ff19abf-6ff7-4f31-bd3e-a07d07ca90dd",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "building (real column) test dataframe...:   2%|▏         | 3188/163846 [00:00<00:00, 1273106.84it/s]\n",
            "building (fake column) test dataframe...:   4%|▎         | 3732/105000 [00:00<00:00, 1242312.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       coco/coco2017/train2017/img046597.jpg\n",
            "1       coco/coco2017/train2017/img158236.jpg\n",
            "2       coco/coco2017/train2017/img149153.jpg\n",
            "3       coco/coco2017/train2017/img070305.jpg\n",
            "4       coco/coco2017/train2017/img051465.jpg\n",
            "                        ...                  \n",
            "2504     coco/coco2017/test2017/img002430.jpg\n",
            "2505     coco/coco2017/test2017/img016017.jpg\n",
            "2506    coco/coco2017/train2017/img092974.jpg\n",
            "2507     coco/coco2017/test2017/img017391.jpg\n",
            "2508     coco/coco2017/test2017/img005564.jpg\n",
            "Name: real, Length: 2509, dtype: object\n",
            "5018\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>real</th>\n",
              "      <th>fake</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>coco/coco2017/train2017/img046597.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/797/img03877...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>coco/coco2017/train2017/img158236.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/118/img00113...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>coco/coco2017/train2017/img149153.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img033485.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>coco/coco2017/train2017/img070305.jpg</td>\n",
              "      <td>tt-ffhq/ffhq_k300_p1.0_fid9.6/img000918.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>coco/coco2017/train2017/img051465.jpg</td>\n",
              "      <td>tt-cc/cin_k600_p1.0_a0.05_fid5.20/461/img02018...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    real  \\\n",
              "0  coco/coco2017/train2017/img046597.jpg   \n",
              "1  coco/coco2017/train2017/img158236.jpg   \n",
              "2  coco/coco2017/train2017/img149153.jpg   \n",
              "3  coco/coco2017/train2017/img070305.jpg   \n",
              "4  coco/coco2017/train2017/img051465.jpg   \n",
              "\n",
              "                                                fake  \n",
              "0  tt-cc/cin_k600_p1.0_a0.05_fid5.20/797/img03877...  \n",
              "1  tt-cc/cin_k600_p1.0_a0.05_fid5.20/118/img00113...  \n",
              "2        tt-ffhq/ffhq_k300_p1.0_fid9.6/img033485.jpg  \n",
              "3        tt-ffhq/ffhq_k300_p1.0_fid9.6/img000918.jpg  \n",
              "4  tt-cc/cin_k600_p1.0_a0.05_fid5.20/461/img02018...  "
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "fake_data_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "real_data_dir = os.path.join(path, \"artifact\", \"coco\")\n",
        "fake_dataset_path = os.path.join(fake_data_dir, \"metadata.csv\")\n",
        "real_dataset_path = os.path.join(real_data_dir, \"metadata.csv\")\n",
        "\n",
        "test_df_path = os.path.join(\"..\", \"datasets\", \"testList.csv\")\n",
        "build.test(fake_dataset_path, real_dataset_path, df_out, test_df_path)\n",
        "test_df = pd.read_csv(test_df_path)\n",
        "\n",
        "print(test_df[\"real\"])\n",
        "print(test_df.size)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
      "metadata": {
        "id": "2262d0bc-a58d-4663-8515-bccbdf870608",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def get_image_embeddings(img, model):\n",
        "    if mode == \"rgb\":\n",
        "        img = torch.from_numpy(img).permute(2, 0, 1) / 255.0\n",
        "      \n",
        "    if mode == \"fourier\":\n",
        "        img = rgb2gray(img)\n",
        "        img = np.expand_dims(img, 0)\n",
        "        img = torch.from_numpy(img) / 255\n",
        "        img = img.float()\n",
        "    \n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        img = img.to(device)\n",
        "        img_enc = model(img.unsqueeze(0))\n",
        "        img_enc = img_enc.detach().cpu().numpy()\n",
        "        img_enc = np.array(img_enc)\n",
        "\n",
        "    return img_enc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
      "metadata": {
        "id": "0b4b5bd4-222b-44a3-b32d-2aa1f9b3d405",
        "tags": []
      },
      "outputs": [],
      "source": [
        "def search_in_database(img_enc, database):\n",
        "    anc_enc_arr = database.iloc[:, 1:].to_numpy()\n",
        "    anc_img_names = database[\"Anchor\"]\n",
        "\n",
        "    distance = []\n",
        "    for i in range(anc_enc_arr.shape[0]):\n",
        "        dist = euclidean_dist(img_enc, anc_enc_arr[i : i+1, :])\n",
        "        distance = np.append(distance, dist)\n",
        "\n",
        "    closest_idx = np.argsort(distance)\n",
        "\n",
        "    return database[\"Anchor\"][closest_idx[0]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
      "metadata": {
        "id": "ddd32725-5e2d-42a7-8998-4920f05ed143",
        "outputId": "888e6f94-a62a-46e1-cf29-d11664da20b7",
        "tags": []
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2509, 2)"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "path = Path(os.getcwd()).parent.parent\n",
        "real_dataset_dir = os.path.join(path, \"artifact\", \"coco\")\n",
        "fake_dataset_dir = os.path.join(path, \"artifact\", \"taming_transformer\")\n",
        "\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "temp_df = test_df\n",
        "temp_df.head()\n",
        "temp_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
      "metadata": {
        "id": "ca7392f6-109f-4a96-92b1-e85600be8d8a",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on fake images...: 2509it [21:15,  1.97it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i fake\n",
        "current_test = \"fake\"\n",
        "database = df_enc\n",
        "\n",
        "# prendo i primi 500 Fake\n",
        "for index, row in tqdm(temp_df.iterrows(), desc=\"testing on fake images...\"):\n",
        "    path = os.path.join(fake_dataset_dir, row[current_test])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "    img_enc = get_image_embeddings(img, model)\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "\n",
        "    if str(closest_label).startswith(\"coco\"):\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
      "metadata": {
        "id": "fe3af5ae-b8c2-419e-b5a5-9d17609797f5",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "2509\n",
            "['fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
      "metadata": {
        "id": "46b8f2c1-a3ca-4bbd-8326-02685fc44cf8",
        "tags": []
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "testing on real images...: 2509it [23:10,  1.80it/s]\n"
          ]
        }
      ],
      "source": [
        "# testo i real\n",
        "current_test = \"real\"\n",
        "database = df_enc\n",
        "\n",
        "for index, row in tqdm(temp_df.iterrows(), desc=\"testing on real images...\"):\n",
        "    path = os.path.join(real_dataset_dir, row[current_test])\n",
        "    img_name = path\n",
        "\n",
        "    img = io.imread(img_name)\n",
        "    img_enc = get_image_embeddings(img, model)\n",
        "    closest_label = search_in_database(img_enc, database)\n",
        "    \n",
        "    if str(closest_label).startswith(\"coco\"):\n",
        "        y_pred.append(\"real\")\n",
        "    else:\n",
        "        y_pred.append(\"fake\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "4c465bfd-18ad-4750-b689-739b712185ab",
      "metadata": {
        "id": "4c465bfd-18ad-4750-b689-739b712185ab",
        "outputId": "e974c712-91fb-4fae-c589-85e08a50fb77",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "5018\n",
            "['fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real']\n"
          ]
        }
      ],
      "source": [
        "print(len(y_true))\n",
        "print(len(y_pred))\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "85706e81-3068-4150-9773-320a8aa98c69",
      "metadata": {
        "id": "85706e81-3068-4150-9773-320a8aa98c69",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'fake', 'real', 'real', 'real', 'real', 'fake', 'fake', 'real', 'fake', 'fake', 'real', 'real', 'real', 'real', 'real', 'real', 'real', 'fake', 'real', 'fake', 'real', 'fake', 'real', 'real', 'real', 'fake', 'fake', 'fake', 'real', 'real', 'fake', 'fake', 'real', 'real', 'fake', 'real', 'fake', 'fake', 'real']\n",
            "[[1599  910]\n",
            " [1808  701]]\n"
          ]
        }
      ],
      "source": [
        "# creo i vettori di ground truth\n",
        "y_true = np.array([\"fake\"] * len(temp_df))\n",
        "temp = np.array([\"real\"] * len(temp_df))\n",
        "y_true = np.concatenate([y_true, temp])\n",
        "\n",
        "print(y_pred)\n",
        "\n",
        "# calcolo la matrice di confusione (quella di scikit-learn dispone i risultati come nella cella di sotto)\n",
        "cm = confusion_matrix(y_true, y_pred, labels=[\"real\", \"fake\"])\n",
        "print(cm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
      "metadata": {
        "id": "28d903d0-38e3-4dc7-af71-f091c78a00e7",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Accuracy': 45.83, 'Precision': 43.51, 'Recall': 27.939999999999998, 'Specificity': 63.7306, 'F1 Score': 34.0285}\n"
          ]
        }
      ],
      "source": [
        "tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "# metriche\n",
        "accuracy = round((tp + tn) / (tp + tn + fp + fn), 4) * 100\n",
        "precision = round((tp) / (tp + fp), 4) * 100\n",
        "recall = round((tp) / (tp + fn), 4) * 100\n",
        "specificity = round((tn) / (tn + fp) * 100, 4)\n",
        "f1_score = round((2 * precision * recall) / (precision + recall), 4)\n",
        "\n",
        "print({\"Accuracy\":accuracy, \"Precision\":precision, \"Recall\":recall, \"Specificity\":specificity, \"F1 Score\":f1_score})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "eb6aac2a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# si salvano i risultati in un file .csv\n",
        "df_results = pd.DataFrame(columns=[\"Accuracy\", \"Precision\", \"Recall\", \"Specificity\", \"F1 Score\"])\n",
        "df_results.loc[0] = [accuracy, precision, recall, specificity, f1_score]\n",
        "\n",
        "# si differenziano i risultati in base al tipo di immagini e dataset usati\n",
        "dataset = fake_data_dir.split(\"\\\\\")[-1]\n",
        "path = os.path.join(\"..\", \"results\", \"rgb_mining\", \"siamese_\" + mode + \"_\" + \"pretrained_semi_hard_online_hard_\" + dataset + \"_results.csv\")\n",
        "\n",
        "df_results.to_csv(path, index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "fvab",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
